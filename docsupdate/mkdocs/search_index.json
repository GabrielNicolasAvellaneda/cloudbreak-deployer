{
    "docs": [
        {
            "location": "/", 
            "text": "Overview\n\n\nCloudbreak is a cloud agnostic Hadoop as a Service API. Abstracts the provisioning and ease management and monitoring of on-demand HDP clusters in different virtual environments. Once it is deployed in your favorite servlet container exposes a REST API allowing to span up Hadoop clusters of arbitrary sizes on your selected cloud provider. Provisioning Hadoop has never been easier.\nCloudbreak is built on the foundation of cloud providers API (Microsoft Azure, Amazon AWS, Google Cloud Platform, OpenStack), Apache Ambari, Docker containers, Swarm and Consul.\n\n\nFor a detailed overview please follow this \nlink\n\n\nCloudbreak has two main components - the \nCloudbreak deployer\n and the \nCloudbreak application\n. Cloudbreak deployer helps you to deploy the Cloudbreak application automatically in environments with Docker support. Once the Cloudbreak application is deployed you can use it to provision HDP clusters in different cloud environments.\n\n\nTechnology\n\n\nFor an architectural overview of the \nCloudbreak deployer\n and the \nCloudbreak application\n please follow this \nlink\n.\n\n\nInstallation\n\n\nCurrently only \nLinux\n and \nOSX\n 64 bit binaries are released for Cloudbreak Deployer. For anything else we can create a special Docker container - please contact us. The deployment itself needs only \nDocker 1.7.0\n or later. You can install the Cloudbreak installation anywhere (on-prem or cloud VMs), however we suggest to installed it as close to the desired HDP clusters as possible. For further information check the \nProvider\n section of the documentation.\n\n\nOn-prem installation\n\n\nFor on premise installations of the Cloudbreak application please follow the \nlink\n\n\nAWS based installation\n\n\nWe have pre-built custom cloud images with Cloudbreak deployer pre-configured. Following the steps will guide you through the provider specific configuration and launching clusters using that provider.\n\n\nYou can follow the AWS provider specific documentation using this \nlink\n\n\nAzure based installation\n\n\nWe have pre-built custom cloud images with Cloudbreak deployer pre-configured. Following the steps will guide you through the provider specific configuration and launching clusters using that provider.\n\n\nYou can follow the Azure provider specific documentation using this \nlink\n\n\nGCP based installation\n\n\nWe have pre-built custom cloud images with Cloudbreak deployer pre-configured. Following the steps will guide you through the provider specific configuration and launching clusters using that provider.\n\n\nYou can follow the GCP provider specific documentation using this \nlink\n\n\nOpenStack based installation\n\n\nWe have pre-built custom cloud images with Cloudbreak deployer pre-configured. Following the steps will guide you through the provider specific configuration and launching clusters using that provider.\n\n\nYou can follow the OpenStack provider specific documentation using this \nlink\n\n\nRelease notes - 1.1.0\n\n\n\n\n\n\n\n\nComponents\n\n\nGA\n\n\nTech preview\n\n\n\n\n\n\n\n\n\n\nAWS\n\n\nyes\n\n\n\n\n\n\n\n\nAzure ARM\n\n\nyes\n\n\n\n\n\n\n\n\nAzure ARM\n\n\nyes\n\n\n\n\n\n\n\n\nGCP\n\n\nyes\n\n\n\n\n\n\n\n\nOpenStack Juno\n\n\n\n\nyes\n\n\n\n\n\n\nSPI interface\n\n\n\n\nyes\n\n\n\n\n\n\nCLI/shell\n\n\nyes\n\n\n\n\n\n\n\n\nRecipes\n\n\n\n\nyes\n\n\n\n\n\n\nKerberos\n\n\n\n\nyes\n\n\n\n\n\n\n\n\nCredits\n\n\nThis tool, and the PR driven release, is inspired from \nglidergun\n. Actually it\ncould be a fork of it. The reason it\u2019s not a fork, because we wanted to have our own binary with all modules\nbuilt in, so only a single binary is needed.", 
            "title": "Overview"
        }, 
        {
            "location": "/#overview", 
            "text": "Cloudbreak is a cloud agnostic Hadoop as a Service API. Abstracts the provisioning and ease management and monitoring of on-demand HDP clusters in different virtual environments. Once it is deployed in your favorite servlet container exposes a REST API allowing to span up Hadoop clusters of arbitrary sizes on your selected cloud provider. Provisioning Hadoop has never been easier.\nCloudbreak is built on the foundation of cloud providers API (Microsoft Azure, Amazon AWS, Google Cloud Platform, OpenStack), Apache Ambari, Docker containers, Swarm and Consul.  For a detailed overview please follow this  link  Cloudbreak has two main components - the  Cloudbreak deployer  and the  Cloudbreak application . Cloudbreak deployer helps you to deploy the Cloudbreak application automatically in environments with Docker support. Once the Cloudbreak application is deployed you can use it to provision HDP clusters in different cloud environments.", 
            "title": "Overview"
        }, 
        {
            "location": "/#technology", 
            "text": "For an architectural overview of the  Cloudbreak deployer  and the  Cloudbreak application  please follow this  link .", 
            "title": "Technology"
        }, 
        {
            "location": "/#installation", 
            "text": "Currently only  Linux  and  OSX  64 bit binaries are released for Cloudbreak Deployer. For anything else we can create a special Docker container - please contact us. The deployment itself needs only  Docker 1.7.0  or later. You can install the Cloudbreak installation anywhere (on-prem or cloud VMs), however we suggest to installed it as close to the desired HDP clusters as possible. For further information check the  Provider  section of the documentation.  On-prem installation  For on premise installations of the Cloudbreak application please follow the  link  AWS based installation  We have pre-built custom cloud images with Cloudbreak deployer pre-configured. Following the steps will guide you through the provider specific configuration and launching clusters using that provider.  You can follow the AWS provider specific documentation using this  link  Azure based installation  We have pre-built custom cloud images with Cloudbreak deployer pre-configured. Following the steps will guide you through the provider specific configuration and launching clusters using that provider.  You can follow the Azure provider specific documentation using this  link  GCP based installation  We have pre-built custom cloud images with Cloudbreak deployer pre-configured. Following the steps will guide you through the provider specific configuration and launching clusters using that provider.  You can follow the GCP provider specific documentation using this  link  OpenStack based installation  We have pre-built custom cloud images with Cloudbreak deployer pre-configured. Following the steps will guide you through the provider specific configuration and launching clusters using that provider.  You can follow the OpenStack provider specific documentation using this  link", 
            "title": "Installation"
        }, 
        {
            "location": "/#release-notes-110", 
            "text": "Components  GA  Tech preview      AWS  yes     Azure ARM  yes     Azure ARM  yes     GCP  yes     OpenStack Juno   yes    SPI interface   yes    CLI/shell  yes     Recipes   yes    Kerberos   yes     Credits  This tool, and the PR driven release, is inspired from  glidergun . Actually it\ncould be a fork of it. The reason it\u2019s not a fork, because we wanted to have our own binary with all modules\nbuilt in, so only a single binary is needed.", 
            "title": "Release notes - 1.1.0"
        }, 
        {
            "location": "/technology/", 
            "text": "Cloudbreak deployer architecture\n\n\n\n\nuaa\n: OAuth Identity Server\n\n\ncloudbreak\n - the Cloudbreak app\n\n\nperiscope\n - the Periscope app\n\n\nuluwatu\n - Cloudbreak UI\n\n\nsultans\n - user management\n\n\n\n\nSystem Level Containers\n\n\n\n\nconsul: Service Registry\n\n\nregistrator: automatically registers/unregisters containers with Consul\n\n\n\n\nCloudbreak application architecture\n\n\nCloudbreak is built on the foundation of cloud providers APIs, Apache Ambari, Docker containers, Swarm and Consul.\n\n\nApache Ambari\n\n\nThe Apache Ambari project is aimed at making Hadoop management simpler by developing software for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari provides an intuitive, easy-to-use Hadoop management web UI backed by its RESTful APIs.\n\n\n\n\nAmbari enables System Administrators to:\n\n\n\n\nProvision a Hadoop Cluster\n\n\nAmbari provides a step-by-step wizard for installing Hadoop services across any number of hosts.\n\n\n\n\nAmbari handles configuration of Hadoop services for the cluster.\n\n\n\n\n\n\nManage a Hadoop Cluster\n\n\n\n\n\n\nAmbari provides central management for starting, stopping, and reconfiguring Hadoop services across the entire cluster.\n\n\n\n\n\n\nMonitor a Hadoop Cluster\n\n\n\n\nAmbari provides a dashboard for monitoring health and status of the Hadoop cluster.\n\n\nAmbari allows to choose between predefined alerts or add yur custom ones\n\n\n\n\nAmbari enables to integrate Hadoop provisioning, management and monitoring capabilities into applications with the Ambari REST APIs.\nAmbari Blueprints are a declarative definition of a cluster. With a Blueprint, you can specify a Stack, the Component layout and the Configurations to materialise a Hadoop cluster instance (via a REST API) without having to use the Ambari Cluster Install Wizard.\n\n\n\n\nDocker\n\n\nDocker is an open platform for developers and sysadmins to build, ship, and run distributed applications. Consisting of Docker Engine, a portable, lightweight runtime and packaging tool, and Docker Hub, a cloud service for sharing applications and automating workflows, Docker enables apps to be quickly assembled from components and eliminates the friction between development, QA, and production environments. As a result, IT can ship faster and run the same app, unchanged, on laptops, data center VMs, and any cloud.\n\n\nThe main features of Docker are:\n\n\n\n\nLightweight, portable\n\n\nBuild once, run anywhere\n\n\nVM - without the overhead of a VM\n\n\nEach virtualised application includes not only the application and the necessary binaries and libraries, but also an entire guest operating system\n\n\n\n\nThe Docker Engine container comprises just the application and its dependencies. It runs as an isolated process in userspace on the host operating system, sharing the kernel with other containers.\n    \n\n\n\n\n\n\nContainers are isolated\n\n\n\n\nIt can be automated and scripted\n\n\n\n\nSwarm\n\n\nDocker Swarm is native clustering for Docker. It turns a pool of Docker hosts into a single, virtual host. Swarm serves the standard Docker API.\n\n\n\n\nDistributed container orchestration: Allows to remotely orchestrate Docker containers on different hosts\n    \n\n\nDiscovery services: Supports different discovery backends to provide service discovery, as such: token (hosted) and file based, etcd, Consul, Zookeeper.\n\n\nAdvanced scheduling: Swarm will schedule containers on hosts based on different filters and strategies\n\n\n\n\nConsul\n\n\nConsul it is a tool for discovering and configuring services in your infrastructure. It provides several key features\n\n\n\n\n\n\nService Discovery: Clients of Consul can provide a service, such as api or mysql, and other clients can use Consul to discover providers of a given service. Using either DNS or HTTP, applications can easily find the services they depend upon.\n\n\n\n\n\n\nHealth Checking: Consul clients can provide any number of health checks, either associated with a given service (\"is the webserver returning 200 OK\"), or with the local node (\"is memory utilization below 90%\"). This information can be used by an operator to monitor cluster health, and it is used by the service discovery components to route traffic away from unhealthy hosts.\n\n\n\n\n\n\nKey/Value Store: Applications can make use of Consul's hierarchical key/value store for any number of purposes, including dynamic configuration, feature flagging, coordination, leader election, and more. The simple HTTP API makes it easy to use.\n\n\n\n\n\n\nMulti Datacenter: Consul supports multiple datacenters out of the box. This means users of Consul do not have to worry about building additional layers of abstraction to grow to multiple regions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupported components\n\n\nAmbari supports the concept of stacks and associated services in a stack definition. By leveraging the stack definition, Ambari has a consistent and defined interface to install, manage and monitor a set of services and provides extensibility model for new stacks and services to be introduced.\n\n\nAt high level the supported list of components can be grouped into main categories: Master and Slave - and bundling them together form a Hadoop Service.\n\n\n\n\n\n\n\n\nServices\n\n\nComponents\n\n\n\n\n\n\n\n\n\n\nHDFS\n\n\nDATANODE, HDFS_CLIENT, JOURNALNODE, NAMENODE, SECONDARY_NAMENODE, ZKFC\n\n\n\n\n\n\nYARN\n\n\nAPP_TIMELINE_SERVER, NODEMANAGER, RESOURCEMANAGER, YARN_CLIENT\n\n\n\n\n\n\nMAPREDUCE2\n\n\nHISTORYSERVER, MAPREDUCE2_CLIENT\n\n\n\n\n\n\nGANGLIA\n\n\nGANGLIA_MONITOR, GANGLIA_SERVER\n\n\n\n\n\n\nHBASE\n\n\nHBASE_CLIENT, HBASE_MASTER, HBASE_REGIONSERVER\n\n\n\n\n\n\nHIVE\n\n\nHIVE_CLIENT, HIVE_METASTORE, HIVE_SERVER, MYSQL_SERVER\n\n\n\n\n\n\nHCATALOG\n\n\nHCAT\n\n\n\n\n\n\nWEBHCAT\n\n\nWEBHCAT_SERVER\n\n\n\n\n\n\nOOZIE\n\n\nOOZIE_CLIENT, OOZIE_SERVER\n\n\n\n\n\n\nPIG\n\n\nPIG\n\n\n\n\n\n\nSQOOP\n\n\nSQOOP\n\n\n\n\n\n\nSTORM\n\n\nDRPC_SERVER, NIMBUS, STORM_REST_API, STORM_UI_SERVER, SUPERVISOR\n\n\n\n\n\n\nTEZ\n\n\nTEZ_CLIENT\n\n\n\n\n\n\nFALCON\n\n\nFALCON_CLIENT, FALCON_SERVER\n\n\n\n\n\n\nZOOKEEPER\n\n\nZOOKEEPER_CLIENT, ZOOKEEPER_SERVER\n\n\n\n\n\n\nSPARK\n\n\nSPARK_JOBHISTORYSERVER, SPARK_CLIENT\n\n\n\n\n\n\nRANGER\n\n\nRANGER_USERSYNC, RANGER_ADMIN\n\n\n\n\n\n\nAMBARI_METRICS\n\n\nAMBARI_METRICS, METRICS_COLLECTOR, METRICS_MONITOR\n\n\n\n\n\n\nKERBEROS\n\n\nKERBEROS_CLIENT\n\n\n\n\n\n\nFLUME\n\n\nFLUME_HANDLER\n\n\n\n\n\n\nKAFKA\n\n\nKAFKA_BROKER\n\n\n\n\n\n\nKNOX\n\n\nKNOX_GATEWAY\n\n\n\n\n\n\nNAGIOS\n\n\nNAGIOS_SERVER\n\n\n\n\n\n\nATLAS\n\n\nATLAS\n\n\n\n\n\n\nCLOUDBREAK\n\n\nCLOUDBREAK\n\n\n\n\n\n\n\n\nWe provide a list of default Hadoop cluster Blueprints for your convenience, however you can always build and use your own Blueprint.\n\n\n\n\nhdp-small-default - HDP 2.3 blueprint\n\n\n\n\nThis is a complex \nBlueprint\n which allows you to launch a multi node, fully distributed HDP 2.3 Cluster in the cloud.\n\n\nIt allows you to use the following services: HDFS, YARN, MAPREDUCE2, KNOX, HBASE, HIVE, HCATALOG, WEBHCAT, SLIDER, OOZIE, PIG, SQOOP, METRICS, TEZ, FALCON, ZOOKEEPER.\n\n\n\n\nhdp-streaming-cluster - HDP 2.3 blueprint\n\n\n\n\nThis is a streaming \nBlueprint\n which allows you to launch a multi node, fully distributed HDP 2.3 Cluster in the cloud, optimized for streaming jobs.\n\n\nIt allows you to use the following services: HDFS, YARN, MAPREDUCE2, STORM, KNOX, HBASE, HIVE, HCATALOG, WEBHCAT, SLIDER, OOZIE, PIG, SQOOP, METRICS, TEZ, FALCON, ZOOKEEPER.\n\n\n\n\nhdp-spark-cluster - HDP 2.3 blueprint\n\n\n\n\nThis is an analytics \nBlueprint\n which allows you to launch a multi node, fully distributed HDP 2.3 Cluster in the cloud, optimized for analytic jobs.\n\n\nIt allows you to use the following services: HDFS, YARN, MAPREDUCE2, SPARK, ZEPPELIN, KNOX, HBASE, HIVE, HCATALOG, WEBHCAT, SLIDER, OOZIE, PIG, SQOOP, METRICS, TEZ, FALCON, ZOOKEEPER.", 
            "title": "Technology"
        }, 
        {
            "location": "/technology/#cloudbreak-deployer-architecture", 
            "text": "uaa : OAuth Identity Server  cloudbreak  - the Cloudbreak app  periscope  - the Periscope app  uluwatu  - Cloudbreak UI  sultans  - user management   System Level Containers   consul: Service Registry  registrator: automatically registers/unregisters containers with Consul", 
            "title": "Cloudbreak deployer architecture"
        }, 
        {
            "location": "/technology/#cloudbreak-application-architecture", 
            "text": "Cloudbreak is built on the foundation of cloud providers APIs, Apache Ambari, Docker containers, Swarm and Consul.  Apache Ambari  The Apache Ambari project is aimed at making Hadoop management simpler by developing software for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari provides an intuitive, easy-to-use Hadoop management web UI backed by its RESTful APIs.   Ambari enables System Administrators to:   Provision a Hadoop Cluster  Ambari provides a step-by-step wizard for installing Hadoop services across any number of hosts.   Ambari handles configuration of Hadoop services for the cluster.    Manage a Hadoop Cluster    Ambari provides central management for starting, stopping, and reconfiguring Hadoop services across the entire cluster.    Monitor a Hadoop Cluster   Ambari provides a dashboard for monitoring health and status of the Hadoop cluster.  Ambari allows to choose between predefined alerts or add yur custom ones   Ambari enables to integrate Hadoop provisioning, management and monitoring capabilities into applications with the Ambari REST APIs.\nAmbari Blueprints are a declarative definition of a cluster. With a Blueprint, you can specify a Stack, the Component layout and the Configurations to materialise a Hadoop cluster instance (via a REST API) without having to use the Ambari Cluster Install Wizard.   Docker  Docker is an open platform for developers and sysadmins to build, ship, and run distributed applications. Consisting of Docker Engine, a portable, lightweight runtime and packaging tool, and Docker Hub, a cloud service for sharing applications and automating workflows, Docker enables apps to be quickly assembled from components and eliminates the friction between development, QA, and production environments. As a result, IT can ship faster and run the same app, unchanged, on laptops, data center VMs, and any cloud.  The main features of Docker are:   Lightweight, portable  Build once, run anywhere  VM - without the overhead of a VM  Each virtualised application includes not only the application and the necessary binaries and libraries, but also an entire guest operating system   The Docker Engine container comprises just the application and its dependencies. It runs as an isolated process in userspace on the host operating system, sharing the kernel with other containers.\n        Containers are isolated   It can be automated and scripted   Swarm  Docker Swarm is native clustering for Docker. It turns a pool of Docker hosts into a single, virtual host. Swarm serves the standard Docker API.   Distributed container orchestration: Allows to remotely orchestrate Docker containers on different hosts\n      Discovery services: Supports different discovery backends to provide service discovery, as such: token (hosted) and file based, etcd, Consul, Zookeeper.  Advanced scheduling: Swarm will schedule containers on hosts based on different filters and strategies   Consul  Consul it is a tool for discovering and configuring services in your infrastructure. It provides several key features    Service Discovery: Clients of Consul can provide a service, such as api or mysql, and other clients can use Consul to discover providers of a given service. Using either DNS or HTTP, applications can easily find the services they depend upon.    Health Checking: Consul clients can provide any number of health checks, either associated with a given service (\"is the webserver returning 200 OK\"), or with the local node (\"is memory utilization below 90%\"). This information can be used by an operator to monitor cluster health, and it is used by the service discovery components to route traffic away from unhealthy hosts.    Key/Value Store: Applications can make use of Consul's hierarchical key/value store for any number of purposes, including dynamic configuration, feature flagging, coordination, leader election, and more. The simple HTTP API makes it easy to use.    Multi Datacenter: Consul supports multiple datacenters out of the box. This means users of Consul do not have to worry about building additional layers of abstraction to grow to multiple regions.", 
            "title": "Cloudbreak application architecture"
        }, 
        {
            "location": "/technology/#supported-components", 
            "text": "Ambari supports the concept of stacks and associated services in a stack definition. By leveraging the stack definition, Ambari has a consistent and defined interface to install, manage and monitor a set of services and provides extensibility model for new stacks and services to be introduced.  At high level the supported list of components can be grouped into main categories: Master and Slave - and bundling them together form a Hadoop Service.     Services  Components      HDFS  DATANODE, HDFS_CLIENT, JOURNALNODE, NAMENODE, SECONDARY_NAMENODE, ZKFC    YARN  APP_TIMELINE_SERVER, NODEMANAGER, RESOURCEMANAGER, YARN_CLIENT    MAPREDUCE2  HISTORYSERVER, MAPREDUCE2_CLIENT    GANGLIA  GANGLIA_MONITOR, GANGLIA_SERVER    HBASE  HBASE_CLIENT, HBASE_MASTER, HBASE_REGIONSERVER    HIVE  HIVE_CLIENT, HIVE_METASTORE, HIVE_SERVER, MYSQL_SERVER    HCATALOG  HCAT    WEBHCAT  WEBHCAT_SERVER    OOZIE  OOZIE_CLIENT, OOZIE_SERVER    PIG  PIG    SQOOP  SQOOP    STORM  DRPC_SERVER, NIMBUS, STORM_REST_API, STORM_UI_SERVER, SUPERVISOR    TEZ  TEZ_CLIENT    FALCON  FALCON_CLIENT, FALCON_SERVER    ZOOKEEPER  ZOOKEEPER_CLIENT, ZOOKEEPER_SERVER    SPARK  SPARK_JOBHISTORYSERVER, SPARK_CLIENT    RANGER  RANGER_USERSYNC, RANGER_ADMIN    AMBARI_METRICS  AMBARI_METRICS, METRICS_COLLECTOR, METRICS_MONITOR    KERBEROS  KERBEROS_CLIENT    FLUME  FLUME_HANDLER    KAFKA  KAFKA_BROKER    KNOX  KNOX_GATEWAY    NAGIOS  NAGIOS_SERVER    ATLAS  ATLAS    CLOUDBREAK  CLOUDBREAK     We provide a list of default Hadoop cluster Blueprints for your convenience, however you can always build and use your own Blueprint.   hdp-small-default - HDP 2.3 blueprint   This is a complex  Blueprint  which allows you to launch a multi node, fully distributed HDP 2.3 Cluster in the cloud.  It allows you to use the following services: HDFS, YARN, MAPREDUCE2, KNOX, HBASE, HIVE, HCATALOG, WEBHCAT, SLIDER, OOZIE, PIG, SQOOP, METRICS, TEZ, FALCON, ZOOKEEPER.   hdp-streaming-cluster - HDP 2.3 blueprint   This is a streaming  Blueprint  which allows you to launch a multi node, fully distributed HDP 2.3 Cluster in the cloud, optimized for streaming jobs.  It allows you to use the following services: HDFS, YARN, MAPREDUCE2, STORM, KNOX, HBASE, HIVE, HCATALOG, WEBHCAT, SLIDER, OOZIE, PIG, SQOOP, METRICS, TEZ, FALCON, ZOOKEEPER.   hdp-spark-cluster - HDP 2.3 blueprint   This is an analytics  Blueprint  which allows you to launch a multi node, fully distributed HDP 2.3 Cluster in the cloud, optimized for analytic jobs.  It allows you to use the following services: HDFS, YARN, MAPREDUCE2, SPARK, ZEPPELIN, KNOX, HBASE, HIVE, HCATALOG, WEBHCAT, SLIDER, OOZIE, PIG, SQOOP, METRICS, TEZ, FALCON, ZOOKEEPER.", 
            "title": "Supported components"
        }, 
        {
            "location": "/aws/", 
            "text": "Launch/configure your instance\n\n\nWe have pre-built a custom AWS AMI image with all the required tooling and Cloudbreak deployer installed. In order to launch this image on AWS please use the following [Cloudformation] link().\n\n\nCloudbreak will already be installed, thus you can follow these steps to launch the application.\n\n\nConfigure Cloudbreak deployer\n\n\nEnter into the \ncloudbreak-deployment folder\n.\n\n\ncd ~/cloudbreak-deployment\n\n\n\n\nIn this folder you will find a \nProfile\n file.\n\n\nConfigure Cloudbreak UI access\n\n\nPlease edit the Profile file - the only mandatory configuration is the \nPUBLIC_IP\n. This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the \ncbd\n tool tries to guess it, if can't than will give a hint.\n\n\nAWS access setup\n\n\nIn order for Cloudbreak to be able to launch clusters on AWS on your behalf you need to set up your AWS keys in the Profile file:\n\n\nexport AWS_ACCESS_KEY_ID=AKIA**************W7SA\nexport AWS_SECRET_ACCESS_KEY=RWCT4Cs8******************/*skiOkWD\n\n\n\n\nSMTP configurations\n\n\nDuring registration or cluster provisioning Cloudbreak sends emails to the user. In order for email sending to work put these lines into your \nProfile\n file.\n\n\nexport CLOUDBREAK_SMTP_SENDER_USERNAME=\nexport CLOUDBREAK_SMTP_SENDER_PASSWORD=\nexport CLOUDBREAK_SMTP_SENDER_HOST=\nexport CLOUDBREAK_SMTP_SENDER_PORT=\nexport CLOUDBREAK_SMTP_SENDER_FROM=\n\n\n\n\nGenerate an AWS role\n\n\nOne key point is that Cloudbreak \ndoes not\n store your Cloud provider account details (such as username, password, keys, private SSL certificates, etc). We work around the concept that Identity and Access Management is fully controlled by the end user. Cloudbreak is purely acting on behalf of the end user - without having access to the user's account. In order to launch clusters on your behalf we need an AWS IAM role - that can be used in the Cloudbreak application as a credential.\n\n\ncbd aws generate-role  - Generates an AWS IAM role for Cloudbreak provisioning on AWS\ncbd aws show-role      - Show assumers and policies for an AWS role\ncbd aws delete-role    - Deletes an AWS IAM role, removes all inline policies\n\n\n\n\nYou can check the generated role on your AWS console, under IAM roles.\n\n\nChange default username/Password\n\n\nThe default credentials can be revealed by \ncbd login\n These values are used in the \nuaa.yml\n file's end section. To change these values, add 2 lines into your Profile:\n\n\nexport UAA_DEFAULT_USER_EMAIL=myself@example.com\nexport UAA_DEFAULT_USER_PW=demo123\n\n\n\n\nRegenerate your Profile\n\n\nYou are done with the configuration of Cloudbreak deployer. The last thing you have to do is to regenerate the configurations in order to take effect.\n\n\nrm *.yml\ncbd generate\n\n\n\n\nVerify configs\n\n\nIn order to verify that all configs are OK use the \ndoctor\n command.\n\n\ncbd doctor\n\n\n\n\nUse Cloudbreak\n\n\nTo start the Cloudbreak application use the following command.\n\n\ncbd start\n\n\n\n\nThis will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.\n\n\ncbd logs\n\n\n\n\nOnce Cloudbreak is up and running you can launch clusters in two different ways. You can use the \nCloudbreak UI\n or use the \nCloudbreak shell\n.", 
            "title": "AWS"
        }, 
        {
            "location": "/aws/#launchconfigure-your-instance", 
            "text": "We have pre-built a custom AWS AMI image with all the required tooling and Cloudbreak deployer installed. In order to launch this image on AWS please use the following [Cloudformation] link().  Cloudbreak will already be installed, thus you can follow these steps to launch the application.", 
            "title": "Launch/configure your instance"
        }, 
        {
            "location": "/aws/#configure-cloudbreak-deployer", 
            "text": "Enter into the  cloudbreak-deployment folder .  cd ~/cloudbreak-deployment  In this folder you will find a  Profile  file.  Configure Cloudbreak UI access  Please edit the Profile file - the only mandatory configuration is the  PUBLIC_IP . This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the  cbd  tool tries to guess it, if can't than will give a hint.  AWS access setup  In order for Cloudbreak to be able to launch clusters on AWS on your behalf you need to set up your AWS keys in the Profile file:  export AWS_ACCESS_KEY_ID=AKIA**************W7SA\nexport AWS_SECRET_ACCESS_KEY=RWCT4Cs8******************/*skiOkWD  SMTP configurations  During registration or cluster provisioning Cloudbreak sends emails to the user. In order for email sending to work put these lines into your  Profile  file.  export CLOUDBREAK_SMTP_SENDER_USERNAME=\nexport CLOUDBREAK_SMTP_SENDER_PASSWORD=\nexport CLOUDBREAK_SMTP_SENDER_HOST=\nexport CLOUDBREAK_SMTP_SENDER_PORT=\nexport CLOUDBREAK_SMTP_SENDER_FROM=  Generate an AWS role  One key point is that Cloudbreak  does not  store your Cloud provider account details (such as username, password, keys, private SSL certificates, etc). We work around the concept that Identity and Access Management is fully controlled by the end user. Cloudbreak is purely acting on behalf of the end user - without having access to the user's account. In order to launch clusters on your behalf we need an AWS IAM role - that can be used in the Cloudbreak application as a credential.  cbd aws generate-role  - Generates an AWS IAM role for Cloudbreak provisioning on AWS\ncbd aws show-role      - Show assumers and policies for an AWS role\ncbd aws delete-role    - Deletes an AWS IAM role, removes all inline policies  You can check the generated role on your AWS console, under IAM roles.  Change default username/Password  The default credentials can be revealed by  cbd login  These values are used in the  uaa.yml  file's end section. To change these values, add 2 lines into your Profile:  export UAA_DEFAULT_USER_EMAIL=myself@example.com\nexport UAA_DEFAULT_USER_PW=demo123  Regenerate your Profile  You are done with the configuration of Cloudbreak deployer. The last thing you have to do is to regenerate the configurations in order to take effect.  rm *.yml\ncbd generate  Verify configs  In order to verify that all configs are OK use the  doctor  command.  cbd doctor", 
            "title": "Configure Cloudbreak deployer"
        }, 
        {
            "location": "/aws/#use-cloudbreak", 
            "text": "To start the Cloudbreak application use the following command.  cbd start  This will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.  cbd logs  Once Cloudbreak is up and running you can launch clusters in two different ways. You can use the  Cloudbreak UI  or use the  Cloudbreak shell .", 
            "title": "Use Cloudbreak"
        }, 
        {
            "location": "/azure/", 
            "text": "AZURE deployment\n\n\nYou already have a cloudbreak-deployer on the machine now we have to start Cloudbreak.\n\n\nmkdir -p cloudbreak-deployer\ncd cloudbreak-deployer\n\n\n\n\nInitialize Profile\n\n\nFirst initialize your directory by creating a \nProfile\n file:\n\n\ncbd init\n\n\n\n\nIt will create a \nProfile\n file in the current directory. Please edit the file - the only required\nconfiguration is the \nPUBLIC_IP\n. This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the \ncbd\n tool tries to guess it, if can't than will give a hint.\n\n\nGenerate your Profile\n\n\nYou are done with the configuration of Cloudbreak deployer. The last thing you have to do is to regenerate the configurations in order to take effect.\n\n\nrm *.yml\ncbd generate\n\n\n\n\nUse Cloudbreak\n\n\nTo start the Cloudbreak application use the following command.\n\n\ncbd start\n\n\n\n\nLaunching the first time will take more time as it does some additional steps:\n\n\n\n\ndownload all the docker images, needed by Cloudbreak.\n\n\ncreate \ndocker-compose.yml\n: Full configuration of containers needed for the Cloudbreak deployment.\n\n\ncreate \nuaa.yml\n: Identity Server configuration.\n\n\n\n\nThis will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.\n\n\ncbd logs cloudbreak\n\n\n\n\n\n\nYou can check the logs when the application is ready. It is about 30 seconds.\n\n\n\n\nOnce Cloudbreak is up and running you can launch clusters in two different ways. You can follow the \nProvisioning prerequisites\n.", 
            "title": "Azure"
        }, 
        {
            "location": "/azure/#azure-deployment", 
            "text": "You already have a cloudbreak-deployer on the machine now we have to start Cloudbreak.  mkdir -p cloudbreak-deployer\ncd cloudbreak-deployer", 
            "title": "AZURE deployment"
        }, 
        {
            "location": "/azure/#initialize-profile", 
            "text": "First initialize your directory by creating a  Profile  file:  cbd init  It will create a  Profile  file in the current directory. Please edit the file - the only required\nconfiguration is the  PUBLIC_IP . This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the  cbd  tool tries to guess it, if can't than will give a hint.  Generate your Profile  You are done with the configuration of Cloudbreak deployer. The last thing you have to do is to regenerate the configurations in order to take effect.  rm *.yml\ncbd generate", 
            "title": "Initialize Profile"
        }, 
        {
            "location": "/azure/#use-cloudbreak", 
            "text": "To start the Cloudbreak application use the following command.  cbd start  Launching the first time will take more time as it does some additional steps:   download all the docker images, needed by Cloudbreak.  create  docker-compose.yml : Full configuration of containers needed for the Cloudbreak deployment.  create  uaa.yml : Identity Server configuration.   This will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.  cbd logs cloudbreak   You can check the logs when the application is ready. It is about 30 seconds.   Once Cloudbreak is up and running you can launch clusters in two different ways. You can follow the  Provisioning prerequisites .", 
            "title": "Use Cloudbreak"
        }, 
        {
            "location": "/gcp/", 
            "text": "GCP deployment\n\n\nYou already have a cloudbreak-deployer on the machine now we have to start Cloudbreak.\n\n\nmkdir -p cloudbreak-deployer\ncd cloudbreak-deployer\n\n\n\n\nInitialize Profile\n\n\nFirst initialize your directory by creating a \nProfile\n file:\n\n\ncbd init\n\n\n\n\nIt will create a \nProfile\n file in the current directory. Please edit the file - the only required\nconfiguration is the \nPUBLIC_IP\n. This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the \ncbd\n tool tries to guess it, if can't than will give a hint.\n\n\nChange default username/Password\n\n\nThe default credentials can be revealed by \ncbd login\n These values are used in the \nuaa.yml\n file's end section. To change these values, add 2 lines into your Profile:\n\n\nexport UAA_DEFAULT_USER_EMAIL=myself@example.com\nexport UAA_DEFAULT_USER_PW=demo123\n\n\n\n\nRegenerate your Profile\n\n\nThere is available a \"cbd regenerate\" command for this.\n\n\ncbd regenerate\n\n\n\n\nVerify configurations\n\n\nIn order to verify that all configs are OK use the \ndoctor\n command.\n\n\ncbd doctor\n\n\n\n\nPull Docker images\n\n\nAll Cloudbreak components and the backend database is running inside containers. The pull command is optional but you can run it prior to cbd start\n\n\ncbd pull\n\n\n\n\nUse Cloudbreak\n\n\nTo start the Cloudbreak application use the following command.\n\n\ncbd start\n\n\n\n\nLaunching the first time will take more time as it does some additional steps:\n\n\n\n\ndownload all the docker images, needed by Cloudbreak.\n\n\ncreate \ndocker-compose.yml\n: Full configuration of containers needed for the Cloudbreak deployment.\n\n\ncreate \nuaa.yml\n: Identity Server configuration.\n\n\n\n\nThis will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.\n\n\ncbd logs\n\n\n\n\n\n\nYou can check the logs when the application is ready. It is about 30 seconds.\n\n\n\n\nOnce Cloudbreak is up and running you have to make some provider based configuration. You can use the \nCloudbreak UI\n.", 
            "title": "GCP"
        }, 
        {
            "location": "/gcp/#gcp-deployment", 
            "text": "You already have a cloudbreak-deployer on the machine now we have to start Cloudbreak.  mkdir -p cloudbreak-deployer\ncd cloudbreak-deployer", 
            "title": "GCP deployment"
        }, 
        {
            "location": "/gcp/#initialize-profile", 
            "text": "First initialize your directory by creating a  Profile  file:  cbd init  It will create a  Profile  file in the current directory. Please edit the file - the only required\nconfiguration is the  PUBLIC_IP . This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the  cbd  tool tries to guess it, if can't than will give a hint.  Change default username/Password  The default credentials can be revealed by  cbd login  These values are used in the  uaa.yml  file's end section. To change these values, add 2 lines into your Profile:  export UAA_DEFAULT_USER_EMAIL=myself@example.com\nexport UAA_DEFAULT_USER_PW=demo123  Regenerate your Profile  There is available a \"cbd regenerate\" command for this.  cbd regenerate  Verify configurations  In order to verify that all configs are OK use the  doctor  command.  cbd doctor  Pull Docker images  All Cloudbreak components and the backend database is running inside containers. The pull command is optional but you can run it prior to cbd start  cbd pull", 
            "title": "Initialize Profile"
        }, 
        {
            "location": "/gcp/#use-cloudbreak", 
            "text": "To start the Cloudbreak application use the following command.  cbd start  Launching the first time will take more time as it does some additional steps:   download all the docker images, needed by Cloudbreak.  create  docker-compose.yml : Full configuration of containers needed for the Cloudbreak deployment.  create  uaa.yml : Identity Server configuration.   This will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.  cbd logs   You can check the logs when the application is ready. It is about 30 seconds.   Once Cloudbreak is up and running you have to make some provider based configuration. You can use the  Cloudbreak UI .", 
            "title": "Use Cloudbreak"
        }, 
        {
            "location": "/openstack/", 
            "text": "OpenStack based installation\n\n\nWe have pre-built a custom OpenStack image available on VM Depot with all the required tooling and Cloudbreak deployer installed. In order to launch this image on OpenStack please use the following \nimage\n.\n\n\nCloudbreak will already be installed, thus you can follow these steps to launch the application.\n\n\nUsage\n\n\nOnce the Cloudbreak deployer is installed it will generate some config files and will download supporting binaries. It is\nadvised that you create a dedicated directory for it:\n\n\nmkdir cloudbreak-deployment\ncd cloudbreak-deployment\n\n\n\n\nInitialize Profile\n\n\nFirst initialize your directory by creating a \nProfile\n file:\n\n\ncbd init\n\n\n\n\nIt will create a \nProfile\n file in the current directory. Please edit the file - the only required\nconfiguration is the \nPUBLIC_IP\n. This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the \ncbd\n tool tries to guess it, if can't than will give a hint.\n\n\nChange default username/Password\n\n\nThe default credentials can be revealed by \ncbd login\n These values are used in the \nuaa.yml\n file's end section. To change these values, add 2 lines into your Profile:\n\n\nexport UAA_DEFAULT_USER_EMAIL=myself@example.com\nexport UAA_DEFAULT_USER_PW=demo123\n\n\n\n\nRegenerate your Profile\n\n\nYou are done with the configuration of Cloudbreak deployer. The last thing you have to do is to regenerate the configurations in order to take effect.\n\n\nrm *.yml\ncbd generate\n\n\n\n\nVerify configs\n\n\nIn order to verify that all configs are OK use the \ndoctor\n command.\n\n\ncbd doctor\n\n\n\n\nStart Cloudbreak\n\n\nTo start all the containers run:\n\n\ncbd start\n\n\n\n\nLaunching the first time will take more time as it does some additional steps:\n\n\n\n\ndownload all the docker images, needed by Cloudbreak.\n\n\ncreate \ndocker-compose.yml\n: Full configuration of containers needed for the Cloudbreak deployment.\n\n\ncreate \nuaa.yml\n: Identity Server configuration.\n\n\n\n\nThis will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.\n\n\nWatch the logs\n\n\ncbd logs", 
            "title": "OpenStack"
        }, 
        {
            "location": "/openstack/#openstack-based-installation", 
            "text": "We have pre-built a custom OpenStack image available on VM Depot with all the required tooling and Cloudbreak deployer installed. In order to launch this image on OpenStack please use the following  image .  Cloudbreak will already be installed, thus you can follow these steps to launch the application.", 
            "title": "OpenStack based installation"
        }, 
        {
            "location": "/openstack/#usage", 
            "text": "Once the Cloudbreak deployer is installed it will generate some config files and will download supporting binaries. It is\nadvised that you create a dedicated directory for it:  mkdir cloudbreak-deployment\ncd cloudbreak-deployment  Initialize Profile  First initialize your directory by creating a  Profile  file:  cbd init  It will create a  Profile  file in the current directory. Please edit the file - the only required\nconfiguration is the  PUBLIC_IP . This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the  cbd  tool tries to guess it, if can't than will give a hint.  Change default username/Password  The default credentials can be revealed by  cbd login  These values are used in the  uaa.yml  file's end section. To change these values, add 2 lines into your Profile:  export UAA_DEFAULT_USER_EMAIL=myself@example.com\nexport UAA_DEFAULT_USER_PW=demo123  Regenerate your Profile  You are done with the configuration of Cloudbreak deployer. The last thing you have to do is to regenerate the configurations in order to take effect.  rm *.yml\ncbd generate  Verify configs  In order to verify that all configs are OK use the  doctor  command.  cbd doctor  Start Cloudbreak  To start all the containers run:  cbd start  Launching the first time will take more time as it does some additional steps:   download all the docker images, needed by Cloudbreak.  create  docker-compose.yml : Full configuration of containers needed for the Cloudbreak deployment.  create  uaa.yml : Identity Server configuration.   This will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.  Watch the logs  cbd logs", 
            "title": "Usage"
        }, 
        {
            "location": "/aws/", 
            "text": "Launch/configure your instance\n\n\nWe have pre-built a custom AWS AMI image with all the required tooling and Cloudbreak deployer installed. In order to launch this image on AWS please use the following [Cloudformation] link().\n\n\nCloudbreak will already be installed, thus you can follow these steps to launch the application.\n\n\nConfigure Cloudbreak deployer\n\n\nEnter into the \ncloudbreak-deployment folder\n.\n\n\ncd ~/cloudbreak-deployment\n\n\n\n\nIn this folder you will find a \nProfile\n file.\n\n\nConfigure Cloudbreak UI access\n\n\nPlease edit the Profile file - the only mandatory configuration is the \nPUBLIC_IP\n. This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the \ncbd\n tool tries to guess it, if can't than will give a hint.\n\n\nAWS access setup\n\n\nIn order for Cloudbreak to be able to launch clusters on AWS on your behalf you need to set up your AWS keys in the Profile file:\n\n\nexport AWS_ACCESS_KEY_ID=AKIA**************W7SA\nexport AWS_SECRET_ACCESS_KEY=RWCT4Cs8******************/*skiOkWD\n\n\n\n\nSMTP configurations\n\n\nDuring registration or cluster provisioning Cloudbreak sends emails to the user. In order for email sending to work put these lines into your \nProfile\n file.\n\n\nexport CLOUDBREAK_SMTP_SENDER_USERNAME=\nexport CLOUDBREAK_SMTP_SENDER_PASSWORD=\nexport CLOUDBREAK_SMTP_SENDER_HOST=\nexport CLOUDBREAK_SMTP_SENDER_PORT=\nexport CLOUDBREAK_SMTP_SENDER_FROM=\n\n\n\n\nGenerate an AWS role\n\n\nOne key point is that Cloudbreak \ndoes not\n store your Cloud provider account details (such as username, password, keys, private SSL certificates, etc). We work around the concept that Identity and Access Management is fully controlled by the end user. Cloudbreak is purely acting on behalf of the end user - without having access to the user's account. In order to launch clusters on your behalf we need an AWS IAM role - that can be used in the Cloudbreak application as a credential.\n\n\ncbd aws generate-role  - Generates an AWS IAM role for Cloudbreak provisioning on AWS\ncbd aws show-role      - Show assumers and policies for an AWS role\ncbd aws delete-role    - Deletes an AWS IAM role, removes all inline policies\n\n\n\n\nYou can check the generated role on your AWS console, under IAM roles.\n\n\nChange default username/Password\n\n\nThe default credentials can be revealed by \ncbd login\n These values are used in the \nuaa.yml\n file's end section. To change these values, add 2 lines into your Profile:\n\n\nexport UAA_DEFAULT_USER_EMAIL=myself@example.com\nexport UAA_DEFAULT_USER_PW=demo123\n\n\n\n\nRegenerate your Profile\n\n\nYou are done with the configuration of Cloudbreak deployer. The last thing you have to do is to regenerate the configurations in order to take effect.\n\n\nrm *.yml\ncbd generate\n\n\n\n\nVerify configs\n\n\nIn order to verify that all configs are OK use the \ndoctor\n command.\n\n\ncbd doctor\n\n\n\n\nUse Cloudbreak\n\n\nTo start the Cloudbreak application use the following command.\n\n\ncbd start\n\n\n\n\nThis will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.\n\n\ncbd logs\n\n\n\n\nOnce Cloudbreak is up and running you can launch clusters in two different ways. You can use the \nCloudbreak UI\n or use the \nCloudbreak shell\n.", 
            "title": "Deployment"
        }, 
        {
            "location": "/aws/#launchconfigure-your-instance", 
            "text": "We have pre-built a custom AWS AMI image with all the required tooling and Cloudbreak deployer installed. In order to launch this image on AWS please use the following [Cloudformation] link().  Cloudbreak will already be installed, thus you can follow these steps to launch the application.", 
            "title": "Launch/configure your instance"
        }, 
        {
            "location": "/aws/#configure-cloudbreak-deployer", 
            "text": "Enter into the  cloudbreak-deployment folder .  cd ~/cloudbreak-deployment  In this folder you will find a  Profile  file.  Configure Cloudbreak UI access  Please edit the Profile file - the only mandatory configuration is the  PUBLIC_IP . This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the  cbd  tool tries to guess it, if can't than will give a hint.  AWS access setup  In order for Cloudbreak to be able to launch clusters on AWS on your behalf you need to set up your AWS keys in the Profile file:  export AWS_ACCESS_KEY_ID=AKIA**************W7SA\nexport AWS_SECRET_ACCESS_KEY=RWCT4Cs8******************/*skiOkWD  SMTP configurations  During registration or cluster provisioning Cloudbreak sends emails to the user. In order for email sending to work put these lines into your  Profile  file.  export CLOUDBREAK_SMTP_SENDER_USERNAME=\nexport CLOUDBREAK_SMTP_SENDER_PASSWORD=\nexport CLOUDBREAK_SMTP_SENDER_HOST=\nexport CLOUDBREAK_SMTP_SENDER_PORT=\nexport CLOUDBREAK_SMTP_SENDER_FROM=  Generate an AWS role  One key point is that Cloudbreak  does not  store your Cloud provider account details (such as username, password, keys, private SSL certificates, etc). We work around the concept that Identity and Access Management is fully controlled by the end user. Cloudbreak is purely acting on behalf of the end user - without having access to the user's account. In order to launch clusters on your behalf we need an AWS IAM role - that can be used in the Cloudbreak application as a credential.  cbd aws generate-role  - Generates an AWS IAM role for Cloudbreak provisioning on AWS\ncbd aws show-role      - Show assumers and policies for an AWS role\ncbd aws delete-role    - Deletes an AWS IAM role, removes all inline policies  You can check the generated role on your AWS console, under IAM roles.  Change default username/Password  The default credentials can be revealed by  cbd login  These values are used in the  uaa.yml  file's end section. To change these values, add 2 lines into your Profile:  export UAA_DEFAULT_USER_EMAIL=myself@example.com\nexport UAA_DEFAULT_USER_PW=demo123  Regenerate your Profile  You are done with the configuration of Cloudbreak deployer. The last thing you have to do is to regenerate the configurations in order to take effect.  rm *.yml\ncbd generate  Verify configs  In order to verify that all configs are OK use the  doctor  command.  cbd doctor", 
            "title": "Configure Cloudbreak deployer"
        }, 
        {
            "location": "/aws/#use-cloudbreak", 
            "text": "To start the Cloudbreak application use the following command.  cbd start  This will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.  cbd logs  Once Cloudbreak is up and running you can launch clusters in two different ways. You can use the  Cloudbreak UI  or use the  Cloudbreak shell .", 
            "title": "Use Cloudbreak"
        }, 
        {
            "location": "/aws_cb_ui/", 
            "text": "You can now log into the Cloudbreak application at http://PUBLIC_IP:3000.\n\n\nManage cloud credentials\n\n\nUsing manage credentials will  link your cloud account with the Cloudbreak account.\n\n\nName:\n name of your credential\n\n\nDescription:\n short description of your linked credential\n\n\nRole ARN:\n the role string - you can find it at the summary tab of the IAM role, default is \ncbreak -deployer\n\n\nSSH public key:\n an SSH public key in OpenSSH format that's private keypair can be used to log into the launched instances later\n\n\nPublic in account:\n share it with others in the account\n\n\nThe ssh username is \nec2-user\n\n\nManage resources\n\n\nUsing manage resources you can create infrastructure templates. Templates describes the infrastructure where the HDP cluster will be provisioned. We support heterogenous clusters - this means that one cluster can be built by combining different templates.\n\n\nName:\n name of your template\n\n\nDescription:\n short description of your template\n\n\nInstance type:\n the Amazon instance type to be used - we suggest to use at least small or medium instances\n\n\nVolume type:\n option to choose are SSD, regular HDD (both EBS) or Ephemeral\n\n\nAttached volumes per instance:\n the number of disks to be attached\n\n\nVolume size (GB):\n the size of the attached disks (in GB)\n\n\nSpot price:\n option to set a spot price - not mandatory, if specified we will request spot price instances (which might take a while or never be fulfilled by Amazon)\n\n\nEBS encryption:\n this feature is supported with all EBS volume types (General Purpose (SSD), Provisioned IOPS (SSD), and Magnetic\n\n\nPublic in account:\n share it with others in the account\n\n\nManage blueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster.\n\n\nName:\n name of your blueprint\n\n\nDescription:\n short description of your blueprint\n\n\nSource URL:\n you can add a blueprint by pointing to a URL. As an example you can use this \nblueprint\n.\n\n\nManual copy:\n you can copy paste your blueprint in this text area\n\n\nPublic in account:\n share it with others in the account\n\n\nManage networks\n\n\nManage networks allows you to create or reuse existing networks and configure them.\n\n\nName:\n name of the network\n\n\nDescription:\n short description of your network\n\n\nSubnet (CIDR):\n a subnet in the VPC with CIDR block\n\n\nPublic in account:\n share it with others in the account\n\n\nManage security groups\n\n\nSecurity groups allows configuration of traffic/access to the cluster. Currently there are two default groups, and later versions will allow setup of new groups.\n\n\nonly-ssh-and-ssl:\n all ports are locked down (you can't access Hadoop services outside of the VPN)\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\n\n\nall-services-port:\n all Hadoop services + SSH/HTTP are accessible by default:\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\nAmbari (8080)\n\n\nConsul (8500)\n\n\nNN (50070)\n\n\nRM Web (8088)\n\n\nRM Scheduler (8030)\n\n\nRM IPC (8050)\n\n\nJob history server (19888)\n\n\nHBase master (60010)\n\n\nFalcon (15000)\n\n\nStorm (8744)\n\n\nOozie (11000)\n\n\nSpark HS (18080)\n\n\nNM Web (8042)\n\n\nZeppelin WebSocket (9996)\n\n\nZeppelin UI (9995)\n\n\nKibana (3080)\n\n\nElasticsearch (9200)\n\n\n\n\nCreate a cluster\n\n\nUsing the create cluster functionality Cloudbreak will create a cloud Stack and a Hadoop Cluster. In order to create a cluster you will have to select a credential first.\n\n\nCluster name:\n your cluster name\n\n\nRegion:\n the region where the cluster is started\n\n\nNetwork:\n the network template\n\n\n`Security Group:\" the security group\n\n\nBlueprint:\n your Hadoop cluster blueprint. Once the blueprint is selected we parse it and give you the option to select the followings for each \nhostgroup\n.\n\n\nHostgroup configuration\n\n\nGroup size:\n the number of instances to be started\n\n\nTemplate:\n the stack template associated to the hostgroup\n\n\nEnable security:\n Install KDC and Kerberize the cluster\n\n\nPublic in account:\n share it with others in the account\n\n\nAdvanced features\n:\n\n\nConsul server count:\n the number of Consul servers (odd number), by default is 3. It varies with the cluster size.\n\n\nMinimum cluster size:\n the provisioning strategy in case of the cloud provider can't allocate all the requested nodes\n\n\nValidate blueprint:\n feature to validate or not the Ambari blueprint. By default is switched on.\n\n\nDedicated instances:\n AWS allows to use dedicated instances\n\n\nAmbari Repository config:\n you can take the stack RPM's from a custom stack repository\n\n\nOnce you have launched the cluster creation you can track the progress either on Cloudbreak UI or your cloud provider management UI.", 
            "title": "Provisioning - UI"
        }, 
        {
            "location": "/aws_cb_ui/#manage-cloud-credentials", 
            "text": "Using manage credentials will  link your cloud account with the Cloudbreak account.  Name:  name of your credential  Description:  short description of your linked credential  Role ARN:  the role string - you can find it at the summary tab of the IAM role, default is  cbreak -deployer  SSH public key:  an SSH public key in OpenSSH format that's private keypair can be used to log into the launched instances later  Public in account:  share it with others in the account  The ssh username is  ec2-user", 
            "title": "Manage cloud credentials"
        }, 
        {
            "location": "/aws_cb_ui/#manage-resources", 
            "text": "Using manage resources you can create infrastructure templates. Templates describes the infrastructure where the HDP cluster will be provisioned. We support heterogenous clusters - this means that one cluster can be built by combining different templates.  Name:  name of your template  Description:  short description of your template  Instance type:  the Amazon instance type to be used - we suggest to use at least small or medium instances  Volume type:  option to choose are SSD, regular HDD (both EBS) or Ephemeral  Attached volumes per instance:  the number of disks to be attached  Volume size (GB):  the size of the attached disks (in GB)  Spot price:  option to set a spot price - not mandatory, if specified we will request spot price instances (which might take a while or never be fulfilled by Amazon)  EBS encryption:  this feature is supported with all EBS volume types (General Purpose (SSD), Provisioned IOPS (SSD), and Magnetic  Public in account:  share it with others in the account", 
            "title": "Manage resources"
        }, 
        {
            "location": "/aws_cb_ui/#manage-blueprints", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster.  Name:  name of your blueprint  Description:  short description of your blueprint  Source URL:  you can add a blueprint by pointing to a URL. As an example you can use this  blueprint .  Manual copy:  you can copy paste your blueprint in this text area  Public in account:  share it with others in the account", 
            "title": "Manage blueprints"
        }, 
        {
            "location": "/aws_cb_ui/#manage-networks", 
            "text": "Manage networks allows you to create or reuse existing networks and configure them.  Name:  name of the network  Description:  short description of your network  Subnet (CIDR):  a subnet in the VPC with CIDR block  Public in account:  share it with others in the account", 
            "title": "Manage networks"
        }, 
        {
            "location": "/aws_cb_ui/#manage-security-groups", 
            "text": "Security groups allows configuration of traffic/access to the cluster. Currently there are two default groups, and later versions will allow setup of new groups.  only-ssh-and-ssl:  all ports are locked down (you can't access Hadoop services outside of the VPN)   SSH (22)  HTTPS (443)   all-services-port:  all Hadoop services + SSH/HTTP are accessible by default:   SSH (22)  HTTPS (443)  Ambari (8080)  Consul (8500)  NN (50070)  RM Web (8088)  RM Scheduler (8030)  RM IPC (8050)  Job history server (19888)  HBase master (60010)  Falcon (15000)  Storm (8744)  Oozie (11000)  Spark HS (18080)  NM Web (8042)  Zeppelin WebSocket (9996)  Zeppelin UI (9995)  Kibana (3080)  Elasticsearch (9200)", 
            "title": "Manage security groups"
        }, 
        {
            "location": "/aws_cb_ui/#create-a-cluster", 
            "text": "Using the create cluster functionality Cloudbreak will create a cloud Stack and a Hadoop Cluster. In order to create a cluster you will have to select a credential first.  Cluster name:  your cluster name  Region:  the region where the cluster is started  Network:  the network template  `Security Group:\" the security group  Blueprint:  your Hadoop cluster blueprint. Once the blueprint is selected we parse it and give you the option to select the followings for each  hostgroup .  Hostgroup configuration  Group size:  the number of instances to be started  Template:  the stack template associated to the hostgroup  Enable security:  Install KDC and Kerberize the cluster  Public in account:  share it with others in the account  Advanced features :  Consul server count:  the number of Consul servers (odd number), by default is 3. It varies with the cluster size.  Minimum cluster size:  the provisioning strategy in case of the cloud provider can't allocate all the requested nodes  Validate blueprint:  feature to validate or not the Ambari blueprint. By default is switched on.  Dedicated instances:  AWS allows to use dedicated instances  Ambari Repository config:  you can take the stack RPM's from a custom stack repository  Once you have launched the cluster creation you can track the progress either on Cloudbreak UI or your cloud provider management UI.", 
            "title": "Create a cluster"
        }, 
        {
            "location": "/aws_cb_shell/", 
            "text": "Interactive mode\n\n\nStart the shell with \ncbd util cloudbreak-shell\n. This will launch the Cloudbreak shell inside a Docker container and you are ready to start using it.\n\n\nYou have to copy files into the cbd working directory, which you would like to use from shell. For example if your \ncbd\n working directory is \n~/prj/cbd\n then copy your blueprint and public ssh key file into this directory. You can refer to these files with their names from the shell.\n\n\nCreate a cloud credential\n\n\nIn order to start using Cloudbreak you will need to have an AWS cloud credential configured. Note that Cloudbreak \ndoes not\n store your cloud user details - we work around the concept of \nIAM\n - on Amazon (or other cloud providers) you will have to create an IAM role, a policy and associate that with your Cloudbreak account.\n\n\ncredential create --EC2 --description \ndescription\n --name my-aws-credential --roleArn \narn role\n --sshKeyFile \npath of your AWS public key\n\n\n\n\n\nAlternatively you can upload your public key from an url as well, by using the \n\u2014sshKeyUrl\n switch. You can check whether the credential was created successfully by using the \ncredential list\n command. You can switch between your cloud credentials - when you\u2019d like to use one and act with that you will have to use:\n\n\ncredential select --name my-aws-credential\n\n\n\n\nCreate a template\n\n\nA template gives developers and systems administrators an easy way to create and manage a collection of cloud infrastructure related resources, maintaining and updating them in an orderly and predictable fashion. A template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a new stack).\n\n\ntemplate create --EC2 --name awstemplate --description aws-template --instanceType M3Xlarge --volumeSize 100 --volumeCount 2\n\n\n\n\nYou can check whether the template was created successfully by using the \ntemplate list\n or \ntemplate show\n command.\n\n\nCreate or select a blueprint\n\n\nYou can define Ambari blueprints with cloudbreak-shell:\n\n\nblueprint add --name myblueprint --description myblueprint-description --file \nthe path of the blueprint\n\n\n\n\n\nOther available options:\n\n\n--url\n the url of the blueprint\n\n\n--publicInAccount\n flags if the network is public in the account\n\n\nWe ship default Ambari blueprints with Cloudbreak. You can use these blueprints or add yours. To see the available blueprints and use one of them please use:\n\n\nblueprint list\n\nblueprint select --name hdp-small-default\n\n\n\n\nCreate a network\n\n\nA network gives developers and systems administrators an easy way to create and manage a collection of cloud infrastructure related networking, maintaining and updating them in an orderly and predictable fashion. A network can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a new stack).\n\n\nnetwork create --EC2 --name awsnetwork --description aws-network --subnet 10.0.0.0/16\n\n\n\n\nOther available options:\n\n\n--vpcID\n your existing vpc on amazon\n\n\n--internetGatewayID\n your amazon internet gateway of the given VPC\n\n\n--publicInAccount\n flags if the network is public in the account\n\n\nThere is a default network with name \ndefault-aws-network\n. If we use this for cluster creation, Cloudbreak will create a new VPC with 10.0.0.0/16 subnet.\n\n\nYou can check whether the network was created successfully by using the \nnetwork list\n command. Check the network and select it if you are happy with it:\n\n\nnetwork show --name awsnetwork\n\nnetwork select --name awsnetwork\n\n\n\n\nCreate a security group\n\n\nA security group gives developers and systems administrators an easy way to create and manage a collection of cloud infrastructure related security rules.\n\n\nsecuritygroup create --name secgroup_example --description securitygroup-example --rules 0.0.0.0/0:tcp:8080,9090;10.0.33.0/24:tcp:1234,1235\n\n\n\n\nYou can check whether the security group was created successfully by using the \nsecuritygroup list\n command. Check the security group and select it if you are happy with it:\n\n\nsecuritygroup show --name secgroup_example\n\nsecuritygroup select --name secgroup_example\n\n\n\n\nThere are two default security groups defined: \nall-services-port\n and \nonly-ssh-and-ssl\n\n\nonly-ssh-and-ssl:\n all ports are locked down (you can't access Hadoop services outside of the VPN)\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\n\n\nall-services-port:\n all Hadoop services + SSH/HTTP are accessible by default:\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\nAmbari (8080)\n\n\nConsul (8500)\n\n\nNN (50070)\n\n\nRM Web (8088)\n\n\nRM Scheduler (8030)\n\n\nRM IPC (8050)\n\n\nJob history server (19888)\n\n\nHBase master (60010)\n\n\nFalcon (15000)\n\n\nStorm (8744)\n\n\nOozie (11000)\n\n\nSpark HS (18080)\n\n\nNM Web (8042)\n\n\nZeppelin WebSocket (9996)\n\n\nZeppelin UI (9995)\n\n\nKibana (3080)\n\n\nElasticsearch (9200)\n\n\n\n\nConfigure instance groups\n\n\nYou have to configure the instancegroups before the provisioning. An instancegroup is defining a group of your nodes with a specified template. Usually we create instancegroups for the hostgroups defined in the blueprints.\n\n\ninstancegroup configure --instanceGroup host_group_slave_1 --nodecount 3 --templateName minviable-aws\n\n\n\n\nOther available options:\n\n\n\n\n--templateId \"string\": Id of the template\n\n\n\n\nCreate a Hadoop cluster\n\n\nYou are almost done - two more command and this will create your Hadoop cluster on your favorite cloud provider. Same as the API, or UI this will use your \ncredential\n, \ninstancegroups\n, \nnetwork\n, \nsecuritygroup\n, and by using CloudFormation will launch a cloud stack\n\n\nstack create --name my-first-stack\n\n\n\n\nOnce the \nstack\n is up and running (cloud provisioning is done) it will use your selected \nblueprint\n and install your custom Hadoop cluster with the selected components and services.\n\n\ncluster create --description \nmy first cluster\n\n\n\n\n\nYou are done - you can check the progress through the Ambari UI. If you log back to Cloudbreak UI you can check the progress over there as well, and learn the IP address of Ambari.\n\n\nSilent mode\n\n\nWith Cloudbreak shell you can execute script files as well. A script file contains cloudbreak shell commands and can be executed with the \nscript\n cloudbreak shell command \n\n\nscript \nyour script file\n\n\n\n\n\nor with the \ncbd util cloudbreak-shell-quiet\n cbd command:\n\n\ncbd util cloudbreak-shell-quiet \n example.sh\n\n\n\n\nExample\n\n\nThe following example creates a hadoop cluster with \nhdp-small-default\n blueprint on M3Xlarge instances with 2X100G attached disks on \ndefault-aws-network\n network using \nall-services-port\n security group. You should copy your ssh public key file into your cbd working directory with name \nid_rsa.pub\n and change the \narn role\n part with your arn role.\n\n\ncredential create --EC2 --description description --name my-aws-credential --roleArn \narn role\n --sshKeyPath id_rsa.pub\ncredential select --name mvCredentialName\ntemplate create --EC2 --name awstemplate --description aws-template --instanceType M3Xlarge --volumeSize 100 --volumeCount 2\nblueprint select --name hdp-small-default\ninstancegroup configure --instanceGroup cbgateway --nodecount 1 --templateName minviable-aws\ninstancegroup configure --instanceGroup host_group_master_1 --nodecount 1 --templateName awstemplate\ninstancegroup configure --instanceGroup host_group_master_2 --nodecount 1 --templateName awstemplate\ninstancegroup configure --instanceGroup host_group_master_3 --nodecount 1 --templateName awstemplate\ninstancegroup configure --instanceGroup host_group_client_1  --nodecount 1 --templateName awstemplate\ninstancegroup configure --instanceGroup host_group_slave_1 --nodecount 3 --templateName awstemplate\nnetwork select --name default-aws-network\nsecuritygroup select --name all-services-port\nstack create --name my-first-stack --region US_EAST_1\ncluster create --description \nMy first cluster", 
            "title": "Provisioning - CLI"
        }, 
        {
            "location": "/aws_cb_shell/#interactive-mode", 
            "text": "Start the shell with  cbd util cloudbreak-shell . This will launch the Cloudbreak shell inside a Docker container and you are ready to start using it.  You have to copy files into the cbd working directory, which you would like to use from shell. For example if your  cbd  working directory is  ~/prj/cbd  then copy your blueprint and public ssh key file into this directory. You can refer to these files with their names from the shell.  Create a cloud credential  In order to start using Cloudbreak you will need to have an AWS cloud credential configured. Note that Cloudbreak  does not  store your cloud user details - we work around the concept of  IAM  - on Amazon (or other cloud providers) you will have to create an IAM role, a policy and associate that with your Cloudbreak account.  credential create --EC2 --description  description  --name my-aws-credential --roleArn  arn role  --sshKeyFile  path of your AWS public key   Alternatively you can upload your public key from an url as well, by using the  \u2014sshKeyUrl  switch. You can check whether the credential was created successfully by using the  credential list  command. You can switch between your cloud credentials - when you\u2019d like to use one and act with that you will have to use:  credential select --name my-aws-credential  Create a template  A template gives developers and systems administrators an easy way to create and manage a collection of cloud infrastructure related resources, maintaining and updating them in an orderly and predictable fashion. A template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a new stack).  template create --EC2 --name awstemplate --description aws-template --instanceType M3Xlarge --volumeSize 100 --volumeCount 2  You can check whether the template was created successfully by using the  template list  or  template show  command.  Create or select a blueprint  You can define Ambari blueprints with cloudbreak-shell:  blueprint add --name myblueprint --description myblueprint-description --file  the path of the blueprint   Other available options:  --url  the url of the blueprint  --publicInAccount  flags if the network is public in the account  We ship default Ambari blueprints with Cloudbreak. You can use these blueprints or add yours. To see the available blueprints and use one of them please use:  blueprint list\n\nblueprint select --name hdp-small-default  Create a network  A network gives developers and systems administrators an easy way to create and manage a collection of cloud infrastructure related networking, maintaining and updating them in an orderly and predictable fashion. A network can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a new stack).  network create --EC2 --name awsnetwork --description aws-network --subnet 10.0.0.0/16  Other available options:  --vpcID  your existing vpc on amazon  --internetGatewayID  your amazon internet gateway of the given VPC  --publicInAccount  flags if the network is public in the account  There is a default network with name  default-aws-network . If we use this for cluster creation, Cloudbreak will create a new VPC with 10.0.0.0/16 subnet.  You can check whether the network was created successfully by using the  network list  command. Check the network and select it if you are happy with it:  network show --name awsnetwork\n\nnetwork select --name awsnetwork  Create a security group  A security group gives developers and systems administrators an easy way to create and manage a collection of cloud infrastructure related security rules.  securitygroup create --name secgroup_example --description securitygroup-example --rules 0.0.0.0/0:tcp:8080,9090;10.0.33.0/24:tcp:1234,1235  You can check whether the security group was created successfully by using the  securitygroup list  command. Check the security group and select it if you are happy with it:  securitygroup show --name secgroup_example\n\nsecuritygroup select --name secgroup_example  There are two default security groups defined:  all-services-port  and  only-ssh-and-ssl  only-ssh-and-ssl:  all ports are locked down (you can't access Hadoop services outside of the VPN)   SSH (22)  HTTPS (443)   all-services-port:  all Hadoop services + SSH/HTTP are accessible by default:   SSH (22)  HTTPS (443)  Ambari (8080)  Consul (8500)  NN (50070)  RM Web (8088)  RM Scheduler (8030)  RM IPC (8050)  Job history server (19888)  HBase master (60010)  Falcon (15000)  Storm (8744)  Oozie (11000)  Spark HS (18080)  NM Web (8042)  Zeppelin WebSocket (9996)  Zeppelin UI (9995)  Kibana (3080)  Elasticsearch (9200)", 
            "title": "Interactive mode"
        }, 
        {
            "location": "/aws_cb_shell/#configure-instance-groups", 
            "text": "You have to configure the instancegroups before the provisioning. An instancegroup is defining a group of your nodes with a specified template. Usually we create instancegroups for the hostgroups defined in the blueprints.  instancegroup configure --instanceGroup host_group_slave_1 --nodecount 3 --templateName minviable-aws  Other available options:   --templateId \"string\": Id of the template   Create a Hadoop cluster  You are almost done - two more command and this will create your Hadoop cluster on your favorite cloud provider. Same as the API, or UI this will use your  credential ,  instancegroups ,  network ,  securitygroup , and by using CloudFormation will launch a cloud stack  stack create --name my-first-stack  Once the  stack  is up and running (cloud provisioning is done) it will use your selected  blueprint  and install your custom Hadoop cluster with the selected components and services.  cluster create --description  my first cluster   You are done - you can check the progress through the Ambari UI. If you log back to Cloudbreak UI you can check the progress over there as well, and learn the IP address of Ambari.", 
            "title": "Configure instance groups"
        }, 
        {
            "location": "/aws_cb_shell/#silent-mode", 
            "text": "With Cloudbreak shell you can execute script files as well. A script file contains cloudbreak shell commands and can be executed with the  script  cloudbreak shell command   script  your script file   or with the  cbd util cloudbreak-shell-quiet  cbd command:  cbd util cloudbreak-shell-quiet   example.sh", 
            "title": "Silent mode"
        }, 
        {
            "location": "/aws_cb_shell/#example", 
            "text": "The following example creates a hadoop cluster with  hdp-small-default  blueprint on M3Xlarge instances with 2X100G attached disks on  default-aws-network  network using  all-services-port  security group. You should copy your ssh public key file into your cbd working directory with name  id_rsa.pub  and change the  arn role  part with your arn role.  credential create --EC2 --description description --name my-aws-credential --roleArn  arn role  --sshKeyPath id_rsa.pub\ncredential select --name mvCredentialName\ntemplate create --EC2 --name awstemplate --description aws-template --instanceType M3Xlarge --volumeSize 100 --volumeCount 2\nblueprint select --name hdp-small-default\ninstancegroup configure --instanceGroup cbgateway --nodecount 1 --templateName minviable-aws\ninstancegroup configure --instanceGroup host_group_master_1 --nodecount 1 --templateName awstemplate\ninstancegroup configure --instanceGroup host_group_master_2 --nodecount 1 --templateName awstemplate\ninstancegroup configure --instanceGroup host_group_master_3 --nodecount 1 --templateName awstemplate\ninstancegroup configure --instanceGroup host_group_client_1  --nodecount 1 --templateName awstemplate\ninstancegroup configure --instanceGroup host_group_slave_1 --nodecount 3 --templateName awstemplate\nnetwork select --name default-aws-network\nsecuritygroup select --name all-services-port\nstack create --name my-first-stack --region US_EAST_1\ncluster create --description  My first cluster", 
            "title": "Example"
        }, 
        {
            "location": "/azure/", 
            "text": "AZURE deployment\n\n\nYou already have a cloudbreak-deployer on the machine now we have to start Cloudbreak.\n\n\nmkdir -p cloudbreak-deployer\ncd cloudbreak-deployer\n\n\n\n\nInitialize Profile\n\n\nFirst initialize your directory by creating a \nProfile\n file:\n\n\ncbd init\n\n\n\n\nIt will create a \nProfile\n file in the current directory. Please edit the file - the only required\nconfiguration is the \nPUBLIC_IP\n. This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the \ncbd\n tool tries to guess it, if can't than will give a hint.\n\n\nGenerate your Profile\n\n\nYou are done with the configuration of Cloudbreak deployer. The last thing you have to do is to regenerate the configurations in order to take effect.\n\n\nrm *.yml\ncbd generate\n\n\n\n\nUse Cloudbreak\n\n\nTo start the Cloudbreak application use the following command.\n\n\ncbd start\n\n\n\n\nLaunching the first time will take more time as it does some additional steps:\n\n\n\n\ndownload all the docker images, needed by Cloudbreak.\n\n\ncreate \ndocker-compose.yml\n: Full configuration of containers needed for the Cloudbreak deployment.\n\n\ncreate \nuaa.yml\n: Identity Server configuration.\n\n\n\n\nThis will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.\n\n\ncbd logs cloudbreak\n\n\n\n\n\n\nYou can check the logs when the application is ready. It is about 30 seconds.\n\n\n\n\nOnce Cloudbreak is up and running you can launch clusters in two different ways. You can follow the \nProvisioning prerequisites\n.", 
            "title": "Installation"
        }, 
        {
            "location": "/azure/#azure-deployment", 
            "text": "You already have a cloudbreak-deployer on the machine now we have to start Cloudbreak.  mkdir -p cloudbreak-deployer\ncd cloudbreak-deployer", 
            "title": "AZURE deployment"
        }, 
        {
            "location": "/azure/#initialize-profile", 
            "text": "First initialize your directory by creating a  Profile  file:  cbd init  It will create a  Profile  file in the current directory. Please edit the file - the only required\nconfiguration is the  PUBLIC_IP . This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the  cbd  tool tries to guess it, if can't than will give a hint.  Generate your Profile  You are done with the configuration of Cloudbreak deployer. The last thing you have to do is to regenerate the configurations in order to take effect.  rm *.yml\ncbd generate", 
            "title": "Initialize Profile"
        }, 
        {
            "location": "/azure/#use-cloudbreak", 
            "text": "To start the Cloudbreak application use the following command.  cbd start  Launching the first time will take more time as it does some additional steps:   download all the docker images, needed by Cloudbreak.  create  docker-compose.yml : Full configuration of containers needed for the Cloudbreak deployment.  create  uaa.yml : Identity Server configuration.   This will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.  cbd logs cloudbreak   You can check the logs when the application is ready. It is about 30 seconds.   Once Cloudbreak is up and running you can launch clusters in two different ways. You can follow the  Provisioning prerequisites .", 
            "title": "Use Cloudbreak"
        }, 
        {
            "location": "/azure_pre_provision/", 
            "text": "Preprovision configurations\n\n\nNote that we use the new \nAzure ARM\n in order to launch clusters. In order to work we need to create an Active Directory application with the configured name and password and adds the permissions that are needed to call the Azure Resource Manager API. Cloudbreak deployer automates all this for you.\n\n\nAzure access setup\n\n\nIf you do not have an Active directory user then you have to configure it before deploying a cluster with Cloudbreak.\n\n\n\n\n\n\nYou can configure your AD users on \nmanage.windowsazure.com\n \n \nActive Directory\n \n \nYour active directory\n \n \nUsers\n menu\n\n\n\n\n\n\n\nHere you can add the new user to AD. Simply click on \nAdd User\n on the bottom of the page\n\n\n\n\n\n\n\nType the new user name into the box\n\n\n\n\n\n\n\nYou will see the new user in the list\n\n\n\n\n\n\n\nAfter you add the user to the AD you need to add your AD user to the \nmanage.windowsazure.com\n \n \nSettings\n \n \nAdministrators\n\n\n\n\n\n\n\n\nHere you can add the new user to Administrators. Simply click on \nAdd\n on the bottom of the page\n\n\n\n\n\n\n\nIn order for Cloudbreak to be able to launch clusters on Azure on your behalf you need to set up your \nAzure ARM application\n.\n\n\ncbd azure configure-arm --app_name myapp --app_password password123 --subscription_id 1234-abcd-efgh-1234 --username testuser@company.onmicrosoft.com --password password123\n\n\n\n\nThe command first creates an Active Directory application with the configured name and password and adds the permissions that are needed to call the Azure Resource Manager API.\nPlease use the output of the command when you creating your Azure credential in Cloudbreak.\n\n\nOptions:\n\n\n--app_name\n: Your application name. Default is \napp\n.\n\n\n--app_password\n: Your application password. Default is \npassword\n.\n\n\n--subscription_id\n: Your Azure subscription ID.\n\n\n--username\n: Your Azure username.\n\n\n--password\n: Your Azure password.\n\n\nFilesystem configuration\n\n\nWhen starting a cluster with Cloudbreak on Azure, the default filesystem is \u201cWindows Azure blob storage with DASH\u201d. Hadoop has built-in support for the \nWASB filesystem\n so it can be used easily as HDFS instead of disks.\n\n\nDisks and blob storage\n\n\nIn Azure every data disk attached to a virtual machine \nis stored\n as a virtual hard disk (VHD) in a page blob inside an Azure storage account. Because these are not local disks and the operations must be done on the VHD files it causes degraded performance when used as HDFS.\nWhen WASB is used as a Hadoop filesystem the files are full-value blobs in a storage account. It means better performance compared to the data disks and the WASB filesystem can be configured very easily but Azure storage accounts have their own \nlimitations\n as well. There is a space limitation for TB per storage account (500 TB) as well but the real bottleneck is the total request rate that is only 20000 IOPS where Azure will start to throw errors when trying to do an I/O operation.\nTo bypass those limits Microsoft created a small service called \nDASH\n. DASH itself is a service that imitates the API of the Azure Blob Storage API and it can be deployed as a Microsoft Azure Cloud Service. Because its API is the same as the standard blob storage API it can be used \nalmost\n in the same way as the default WASB filesystem from a Hadoop deployment.\nDASH works by sharding the storage access across multiple storage accounts. It can be configured to distribute storage account load to at most 15 \nscaleout\n storage accounts. It needs one more \nnamespace\n storage account where it keeps track of where the data is stored.\nWhen configuring a WASB filesystem with Hadoop, the only required config entries are the ones where the access details are described. To access a storage account Azure generates an access key that is displayed on the Azure portal or can be queried through the API while the account name is the name of the storage account itself. A DASH service has a similar account name and key, those can be configured in the configuration file while deploying the cloud service.\n\n\n\n\nDeploying a DASH service with Cloudbreak deployer\n\n\nWe have automated the deployment of a DASH service in cloudbreak-deployer. After cbd is installed, simply run the following command to deploy a DASH cloud service with 5 scale out storage accounts:\n\n\ncbd azure deploy-dash --accounts 5 --prefix dash --location \nWest Europe\n --instances 3\n\n\n\n\nThe command first creates the namespace account and the scaleout storage accounts, builds the \n.cscfg\n configuration file based on the created storage account names and keys, generates an Account Name and an Account Key for the DASH service and finally deploys the cloud service package file to a new cloud service.\n\n\nThe WASB filesystem configured with DASH can be used as a data lake - when multiple clusters are deployed with the same DASH filesystem configuration the same data can be accessed from all the clusters, but every cluster can have a different service configured as well. In that case deploy as many DASH services with cbd as clusters with Cloudbreak and configure them accordingly.\n\n\nOnce Cloudbreak is up and running you can launch clusters in two different ways. You can use the \nCloudbreak UI\n or use the \nCloudbreak shell\n.", 
            "title": "Provisioning prerequisites"
        }, 
        {
            "location": "/azure_pre_provision/#preprovision-configurations", 
            "text": "Note that we use the new  Azure ARM  in order to launch clusters. In order to work we need to create an Active Directory application with the configured name and password and adds the permissions that are needed to call the Azure Resource Manager API. Cloudbreak deployer automates all this for you.", 
            "title": "Preprovision configurations"
        }, 
        {
            "location": "/azure_pre_provision/#azure-access-setup", 
            "text": "If you do not have an Active directory user then you have to configure it before deploying a cluster with Cloudbreak.    You can configure your AD users on  manage.windowsazure.com     Active Directory     Your active directory     Users  menu    Here you can add the new user to AD. Simply click on  Add User  on the bottom of the page    Type the new user name into the box    You will see the new user in the list    After you add the user to the AD you need to add your AD user to the  manage.windowsazure.com     Settings     Administrators     Here you can add the new user to Administrators. Simply click on  Add  on the bottom of the page    In order for Cloudbreak to be able to launch clusters on Azure on your behalf you need to set up your  Azure ARM application .  cbd azure configure-arm --app_name myapp --app_password password123 --subscription_id 1234-abcd-efgh-1234 --username testuser@company.onmicrosoft.com --password password123  The command first creates an Active Directory application with the configured name and password and adds the permissions that are needed to call the Azure Resource Manager API.\nPlease use the output of the command when you creating your Azure credential in Cloudbreak.  Options:  --app_name : Your application name. Default is  app .  --app_password : Your application password. Default is  password .  --subscription_id : Your Azure subscription ID.  --username : Your Azure username.  --password : Your Azure password.", 
            "title": "Azure access setup"
        }, 
        {
            "location": "/azure_pre_provision/#filesystem-configuration", 
            "text": "When starting a cluster with Cloudbreak on Azure, the default filesystem is \u201cWindows Azure blob storage with DASH\u201d. Hadoop has built-in support for the  WASB filesystem  so it can be used easily as HDFS instead of disks.  Disks and blob storage  In Azure every data disk attached to a virtual machine  is stored  as a virtual hard disk (VHD) in a page blob inside an Azure storage account. Because these are not local disks and the operations must be done on the VHD files it causes degraded performance when used as HDFS.\nWhen WASB is used as a Hadoop filesystem the files are full-value blobs in a storage account. It means better performance compared to the data disks and the WASB filesystem can be configured very easily but Azure storage accounts have their own  limitations  as well. There is a space limitation for TB per storage account (500 TB) as well but the real bottleneck is the total request rate that is only 20000 IOPS where Azure will start to throw errors when trying to do an I/O operation.\nTo bypass those limits Microsoft created a small service called  DASH . DASH itself is a service that imitates the API of the Azure Blob Storage API and it can be deployed as a Microsoft Azure Cloud Service. Because its API is the same as the standard blob storage API it can be used  almost  in the same way as the default WASB filesystem from a Hadoop deployment.\nDASH works by sharding the storage access across multiple storage accounts. It can be configured to distribute storage account load to at most 15  scaleout  storage accounts. It needs one more  namespace  storage account where it keeps track of where the data is stored.\nWhen configuring a WASB filesystem with Hadoop, the only required config entries are the ones where the access details are described. To access a storage account Azure generates an access key that is displayed on the Azure portal or can be queried through the API while the account name is the name of the storage account itself. A DASH service has a similar account name and key, those can be configured in the configuration file while deploying the cloud service.   Deploying a DASH service with Cloudbreak deployer  We have automated the deployment of a DASH service in cloudbreak-deployer. After cbd is installed, simply run the following command to deploy a DASH cloud service with 5 scale out storage accounts:  cbd azure deploy-dash --accounts 5 --prefix dash --location  West Europe  --instances 3  The command first creates the namespace account and the scaleout storage accounts, builds the  .cscfg  configuration file based on the created storage account names and keys, generates an Account Name and an Account Key for the DASH service and finally deploys the cloud service package file to a new cloud service.  The WASB filesystem configured with DASH can be used as a data lake - when multiple clusters are deployed with the same DASH filesystem configuration the same data can be accessed from all the clusters, but every cluster can have a different service configured as well. In that case deploy as many DASH services with cbd as clusters with Cloudbreak and configure them accordingly.  Once Cloudbreak is up and running you can launch clusters in two different ways. You can use the  Cloudbreak UI  or use the  Cloudbreak shell .", 
            "title": "Filesystem configuration"
        }, 
        {
            "location": "/azure_cb_ui/", 
            "text": "Manage cloud credentials\n\n\nYou can now log into the Cloudbreak application at http://PUBLIC_IP:3000. Once logged in go to \nManage credentials\n. Using manage credentials will  link your cloud account with the Cloudbreak account.\nIf you do not have an Azure Resource manager application you can simply create it with Cloudbreak deployer. Please read the \nProvisioning prerequisites\n for more information.\n\n\nName:\n name of your credential\n\n\nDescription:\n short description of your linked credential\n\n\nSubscription Id:\n your Azure subscription id - see Accounts (Browse all\n Subscription)\n\n\nPassword:\n your password which was setted up when you create the AD app\n\n\nApp ID:\n You app Id (\nBrowse all\n \nSubscription\n \nSubscription detail\n \nUsers\n \nYou application\n \nProperties\n)\n\n\nApp Owner Tenant ID:\n You Tenant Id (\nBrowse all\n \nSubscription\n \nSubscription detail\n \nUsers\n \nYou application\n \nProperties\n)\n\n\nSSH public key:\n the SSH public key in OpenSSH format that's private keypair can be used to log into the launched instances later\n\n\n\n\nCloudbreak supporting simple rsa public key instead of X509 certificate file after 1.0.4 version\n\n\n\n\nThe ssh username is \ncloudbreak\n\n\nManage resources\n\n\nUsing manage resources you can create infrastructure templates. Templates describes the infrastructure where the HDP cluster will be provisioned. We support heterogenous clusters - this means that one cluster can be built by combining different templates.\n\n\nName:\n name of your template\n\n\nDescription:\n short description of your template\n\n\nInstance type:\n the Azure instance type to be used\n\n\nAttached volumes per instance:\n the number of disks to be attached\n\n\nVolume size (GB):\n the size of the attached disks (in GB)\n\n\nPublic in account:\n share it with others in the account\n\n\nManage blueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster.\n\n\nName:\n name of your blueprint\n\n\nDescription:\n short description of your blueprint\n\n\nSource URL:\n you can add a blueprint by pointing to a URL. As an example you can use this \nblueprint\n.\n\n\nManual copy:\n you can copy paste your blueprint in this text area\n\n\nPublic in account:\n share it with others in the account\n\n\nManage networks\n\n\nManage networks allows you to create or reuse existing networks and configure them.\n\n\nName:\n name of the network\n\n\nDescription:\n short description of your network\n\n\nSubnet (CIDR):\n a subnet in the VPC with CIDR block\n\n\nAddress prefix (CIDR):\n the address space that is used for subnets\n\n\nPublic in account:\n share it with others in the account\n\n\nManage security groups\n\n\nSecurity groups allows configuration of traffic/access to the cluster. Currently there are two default groups, and later versions will allow setup of new groups.\n\n\nonly-ssh-and-ssl:\n all ports are locked down (you can't access Hadoop services outside of the VPN)\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\n\n\nall-services-port:\n all Hadoop services + SSH/HTTP are accessible by default:\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\nAmbari (8080)\n\n\nConsul (8500)\n\n\nNN (50070)\n\n\nRM Web (8088)\n\n\nRM Scheduler (8030)\n\n\nRM IPC (8050)\n\n\nJob history server (19888)\n\n\nHBase master (60010)\n\n\nFalcon (15000)\n\n\nStorm (8744)\n\n\nOozie (11000)\n\n\nSpark HS (18080)\n\n\nNM Web (8042)\n\n\nZeppelin WebSocket (9996)\n\n\nZeppelin UI (9995)\n\n\nKibana (3080)\n\n\nElasticsearch (9200)\n\n\n\n\nCreate a cluster\n\n\nUsing the create cluster functionality Cloudbreak will create a cloud Stack and a Hadoop Cluster. In order to create a cluster you will have to select a credential first.\n\n\nCluster name:\n your cluster name\n\n\nRegion:\n the region where the cluster is started\n\n\nNetwork:\n the network template\n\n\nSecurity Group:\n the security group\n\n\nBlueprint:\n your Hadoop cluster blueprint. Once the blueprint is selected we parse it and give you the option to select the followings for each \nhostgroup\n.\n\n\nHostgroup configuration\n\n\nGroup size:\n the number of instances to be started\n\n\nTemplate:\n the stack template associated to the hostgroup\n\n\nDASH Account Name:\n values printed by Cloudbreak deployer when the DASH service was deployed\n\n\nDASH Account Key:\n values printed by Cloudbreak deployer when the DASH service was deployed\n\n\nImportant:\n For better performance DASH service and the Cloudbreak cluster must be in the same Azure region.\n\n\nEnable security:\n Install KDC and Kerberize the cluster\n\n\nPublic in account:\n share it with others in the account\n\n\nAdvanced features\n:\n\n\nConsul server count:\n the number of Consul servers (odd number), by default is 3. It varies with the cluster size.\n\n\nMinimum cluster size:\n the provisioning strategy in case of the cloud provider can't allocate all the requested nodes\n\n\nValidate blueprint:\n feature to validate or not the Ambari blueprint. By default is switched on.\n\n\nAmbari Repository config:\n you can take the stack RPM's from a custom stack repository\n\n\nOnce you have launched the cluster creation you can track the progress either on Cloudbreak UI or your cloud provider management UI.", 
            "title": "Provisioning - UI"
        }, 
        {
            "location": "/azure_cb_ui/#manage-cloud-credentials", 
            "text": "You can now log into the Cloudbreak application at http://PUBLIC_IP:3000. Once logged in go to  Manage credentials . Using manage credentials will  link your cloud account with the Cloudbreak account.\nIf you do not have an Azure Resource manager application you can simply create it with Cloudbreak deployer. Please read the  Provisioning prerequisites  for more information.  Name:  name of your credential  Description:  short description of your linked credential  Subscription Id:  your Azure subscription id - see Accounts (Browse all  Subscription)  Password:  your password which was setted up when you create the AD app  App ID:  You app Id ( Browse all   Subscription   Subscription detail   Users   You application   Properties )  App Owner Tenant ID:  You Tenant Id ( Browse all   Subscription   Subscription detail   Users   You application   Properties )  SSH public key:  the SSH public key in OpenSSH format that's private keypair can be used to log into the launched instances later   Cloudbreak supporting simple rsa public key instead of X509 certificate file after 1.0.4 version   The ssh username is  cloudbreak", 
            "title": "Manage cloud credentials"
        }, 
        {
            "location": "/azure_cb_ui/#manage-resources", 
            "text": "Using manage resources you can create infrastructure templates. Templates describes the infrastructure where the HDP cluster will be provisioned. We support heterogenous clusters - this means that one cluster can be built by combining different templates.  Name:  name of your template  Description:  short description of your template  Instance type:  the Azure instance type to be used  Attached volumes per instance:  the number of disks to be attached  Volume size (GB):  the size of the attached disks (in GB)  Public in account:  share it with others in the account", 
            "title": "Manage resources"
        }, 
        {
            "location": "/azure_cb_ui/#manage-blueprints", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster.  Name:  name of your blueprint  Description:  short description of your blueprint  Source URL:  you can add a blueprint by pointing to a URL. As an example you can use this  blueprint .  Manual copy:  you can copy paste your blueprint in this text area  Public in account:  share it with others in the account", 
            "title": "Manage blueprints"
        }, 
        {
            "location": "/azure_cb_ui/#manage-networks", 
            "text": "Manage networks allows you to create or reuse existing networks and configure them.  Name:  name of the network  Description:  short description of your network  Subnet (CIDR):  a subnet in the VPC with CIDR block  Address prefix (CIDR):  the address space that is used for subnets  Public in account:  share it with others in the account", 
            "title": "Manage networks"
        }, 
        {
            "location": "/azure_cb_ui/#manage-security-groups", 
            "text": "Security groups allows configuration of traffic/access to the cluster. Currently there are two default groups, and later versions will allow setup of new groups.  only-ssh-and-ssl:  all ports are locked down (you can't access Hadoop services outside of the VPN)   SSH (22)  HTTPS (443)   all-services-port:  all Hadoop services + SSH/HTTP are accessible by default:   SSH (22)  HTTPS (443)  Ambari (8080)  Consul (8500)  NN (50070)  RM Web (8088)  RM Scheduler (8030)  RM IPC (8050)  Job history server (19888)  HBase master (60010)  Falcon (15000)  Storm (8744)  Oozie (11000)  Spark HS (18080)  NM Web (8042)  Zeppelin WebSocket (9996)  Zeppelin UI (9995)  Kibana (3080)  Elasticsearch (9200)", 
            "title": "Manage security groups"
        }, 
        {
            "location": "/azure_cb_ui/#create-a-cluster", 
            "text": "Using the create cluster functionality Cloudbreak will create a cloud Stack and a Hadoop Cluster. In order to create a cluster you will have to select a credential first.  Cluster name:  your cluster name  Region:  the region where the cluster is started  Network:  the network template  Security Group:  the security group  Blueprint:  your Hadoop cluster blueprint. Once the blueprint is selected we parse it and give you the option to select the followings for each  hostgroup .  Hostgroup configuration  Group size:  the number of instances to be started  Template:  the stack template associated to the hostgroup  DASH Account Name:  values printed by Cloudbreak deployer when the DASH service was deployed  DASH Account Key:  values printed by Cloudbreak deployer when the DASH service was deployed  Important:  For better performance DASH service and the Cloudbreak cluster must be in the same Azure region.  Enable security:  Install KDC and Kerberize the cluster  Public in account:  share it with others in the account  Advanced features :  Consul server count:  the number of Consul servers (odd number), by default is 3. It varies with the cluster size.  Minimum cluster size:  the provisioning strategy in case of the cloud provider can't allocate all the requested nodes  Validate blueprint:  feature to validate or not the Ambari blueprint. By default is switched on.  Ambari Repository config:  you can take the stack RPM's from a custom stack repository  Once you have launched the cluster creation you can track the progress either on Cloudbreak UI or your cloud provider management UI.", 
            "title": "Create a cluster"
        }, 
        {
            "location": "/azure_cb_shell/", 
            "text": "Interactive mode\n\n\nStart the shell with \ncbd util cloudbreak-shell\n. This will launch the Cloudbr shell inside a Docker container and you are ready to start using it.\n\n\nCreate a cloud credential\n\n\ncredential create --AZURE --description \ndescription\n --name \nmyCredentialName\n --subscriptionId \nmySubscriptionId\n --tenantId \nsdfsd-sdfdsf-dsfdsf-sdfsdf\n --secretKey \nsdfdsfs-sdfsddsf-sdfsdf-sdfsdf\n --accesKey \nacceskey\n --sshKeyUrl \nURL towards your public SSH key file\n\n\n\n\n\n\n\nCloudbreak supporting simple rsa public key instead of X509 certificate file after 1.0.4 version\n\n\n\n\nAlternatively you can upload your public key from a file as well, by using the \n\u2014sshKeyPath\n switch. You can check whether the credential was creates successfully by using the \ncredential list\n command.\nYou can switch between your cloud credential - when you\u2019d like to use one and act with that you will have to use:\n\n\ncredential select --name #NAME of the credential\n\n\n\n\nYou can delete your cloud credential - when you\u2019d like to delete one you will have to use:\n\n\ncredential delete --name #NAME of the credential\n\n\n\n\nYou can show your cloud credential - when you\u2019d like to show one you will have to use:\n\n\ncredential show --name #NAME of the credential\n\n\n\n\nCreate a template\n\n\nA template gives developers and systems administrators an easy way to create and manage a collection of cloud infrastructure related resources, maintaining and updating them in an orderly and predictable fashion. A template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a new stack).\n\n\ntemplate create --AZURE --name azuretemplate --description azure-template --instanceType STANDARD_D2 --volumeSize 100 --volumeCount 2\n\n\n\n\nYou can check whether the template was created successfully by using the \ntemplate list\n command.\nCheck the template and select it if you are happy with it:\n\n\ntemplate select --name #NAME of the template\n\n\n\n\nYou can delete your cloud template - when you\u2019d like to delete one you will have to use:\n\n\ntemplate delete --name #NAME of the template\n\n\n\n\nYou can show your cloud template - when you\u2019d like to show one you will have to use:\n\n\ntemplate show --name #NAME of the template\n\n\n\n\nCreate a stack\n\n\nStacks are template \ninstances\n - a running cloud infrastructure created based on a template. Use the following command to create a stack to be used with your Hadoop cluster:\n\n\nstack create --name \nmyStackName\n --nodeCount 10\n\n\n\n\nSelect a blueprint\n\n\nWe ship default Hadoop cluster blueprints with Cloudbreak. You can use these blueprints or add yours. To see the available blueprints and use one of them please use:\n\n\nblueprint list\n\nblueprint select --name #NAME of the blueprint\n\n\n\n\nCreate a Hadoop cluster\n\n\nYou are almost done - one more command and this will create your Hadoop cluster on your favorite cloud provider. Same as the API, or UI this will use your \ntemplate\n, and by using CloudFormation will launch a cloud \nstack\n - once the \nstack\n is up and running (cloud provisioning is done) it will use your selected \nblueprint\n and install your custom Hadoop cluster with the selected components and services.\n\n\ncluster create --description \nmy cluster desc\n\n\n\n\n\nYou are done - you can check the progress through the Ambari UI. If you log back to Cloudbreak UI you can check the progress over there as well, and learn the IP address of Ambari.\n\n\nSilent mode\n\n\nWith Cloudbreak shell you can recreate clusters based on earlier deployments. Each time you start the shell the executed commands are logged in a file line by line and later either with the \nscript\n command or specifying an \n\u2014cmdfile\n option the same commands can be executed again.\n\n\nWith \ncbd util cloudbreak-shell-quiet\n you can specify a shell file and let the shell apply the configs step by step in a silent mode.", 
            "title": "Provisioning - CLI"
        }, 
        {
            "location": "/azure_cb_shell/#interactive-mode", 
            "text": "Start the shell with  cbd util cloudbreak-shell . This will launch the Cloudbr shell inside a Docker container and you are ready to start using it.", 
            "title": "Interactive mode"
        }, 
        {
            "location": "/azure_cb_shell/#create-a-cloud-credential", 
            "text": "credential create --AZURE --description  description  --name  myCredentialName  --subscriptionId  mySubscriptionId  --tenantId  sdfsd-sdfdsf-dsfdsf-sdfsdf  --secretKey  sdfdsfs-sdfsddsf-sdfsdf-sdfsdf  --accesKey  acceskey  --sshKeyUrl  URL towards your public SSH key file    Cloudbreak supporting simple rsa public key instead of X509 certificate file after 1.0.4 version   Alternatively you can upload your public key from a file as well, by using the  \u2014sshKeyPath  switch. You can check whether the credential was creates successfully by using the  credential list  command.\nYou can switch between your cloud credential - when you\u2019d like to use one and act with that you will have to use:  credential select --name #NAME of the credential  You can delete your cloud credential - when you\u2019d like to delete one you will have to use:  credential delete --name #NAME of the credential  You can show your cloud credential - when you\u2019d like to show one you will have to use:  credential show --name #NAME of the credential", 
            "title": "Create a cloud credential"
        }, 
        {
            "location": "/azure_cb_shell/#create-a-template", 
            "text": "A template gives developers and systems administrators an easy way to create and manage a collection of cloud infrastructure related resources, maintaining and updating them in an orderly and predictable fashion. A template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a new stack).  template create --AZURE --name azuretemplate --description azure-template --instanceType STANDARD_D2 --volumeSize 100 --volumeCount 2  You can check whether the template was created successfully by using the  template list  command.\nCheck the template and select it if you are happy with it:  template select --name #NAME of the template  You can delete your cloud template - when you\u2019d like to delete one you will have to use:  template delete --name #NAME of the template  You can show your cloud template - when you\u2019d like to show one you will have to use:  template show --name #NAME of the template", 
            "title": "Create a template"
        }, 
        {
            "location": "/azure_cb_shell/#create-a-stack", 
            "text": "Stacks are template  instances  - a running cloud infrastructure created based on a template. Use the following command to create a stack to be used with your Hadoop cluster:  stack create --name  myStackName  --nodeCount 10", 
            "title": "Create a stack"
        }, 
        {
            "location": "/azure_cb_shell/#select-a-blueprint", 
            "text": "We ship default Hadoop cluster blueprints with Cloudbreak. You can use these blueprints or add yours. To see the available blueprints and use one of them please use:  blueprint list\n\nblueprint select --name #NAME of the blueprint", 
            "title": "Select a blueprint"
        }, 
        {
            "location": "/azure_cb_shell/#create-a-hadoop-cluster", 
            "text": "You are almost done - one more command and this will create your Hadoop cluster on your favorite cloud provider. Same as the API, or UI this will use your  template , and by using CloudFormation will launch a cloud  stack  - once the  stack  is up and running (cloud provisioning is done) it will use your selected  blueprint  and install your custom Hadoop cluster with the selected components and services.  cluster create --description  my cluster desc   You are done - you can check the progress through the Ambari UI. If you log back to Cloudbreak UI you can check the progress over there as well, and learn the IP address of Ambari.", 
            "title": "Create a Hadoop cluster"
        }, 
        {
            "location": "/azure_cb_shell/#silent-mode", 
            "text": "With Cloudbreak shell you can recreate clusters based on earlier deployments. Each time you start the shell the executed commands are logged in a file line by line and later either with the  script  command or specifying an  \u2014cmdfile  option the same commands can be executed again.  With  cbd util cloudbreak-shell-quiet  you can specify a shell file and let the shell apply the configs step by step in a silent mode.", 
            "title": "Silent mode"
        }, 
        {
            "location": "/gcp/", 
            "text": "GCP deployment\n\n\nYou already have a cloudbreak-deployer on the machine now we have to start Cloudbreak.\n\n\nmkdir -p cloudbreak-deployer\ncd cloudbreak-deployer\n\n\n\n\nInitialize Profile\n\n\nFirst initialize your directory by creating a \nProfile\n file:\n\n\ncbd init\n\n\n\n\nIt will create a \nProfile\n file in the current directory. Please edit the file - the only required\nconfiguration is the \nPUBLIC_IP\n. This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the \ncbd\n tool tries to guess it, if can't than will give a hint.\n\n\nChange default username/Password\n\n\nThe default credentials can be revealed by \ncbd login\n These values are used in the \nuaa.yml\n file's end section. To change these values, add 2 lines into your Profile:\n\n\nexport UAA_DEFAULT_USER_EMAIL=myself@example.com\nexport UAA_DEFAULT_USER_PW=demo123\n\n\n\n\nRegenerate your Profile\n\n\nThere is available a \"cbd regenerate\" command for this.\n\n\ncbd regenerate\n\n\n\n\nVerify configurations\n\n\nIn order to verify that all configs are OK use the \ndoctor\n command.\n\n\ncbd doctor\n\n\n\n\nPull Docker images\n\n\nAll Cloudbreak components and the backend database is running inside containers. The pull command is optional but you can run it prior to cbd start\n\n\ncbd pull\n\n\n\n\nUse Cloudbreak\n\n\nTo start the Cloudbreak application use the following command.\n\n\ncbd start\n\n\n\n\nLaunching the first time will take more time as it does some additional steps:\n\n\n\n\ndownload all the docker images, needed by Cloudbreak.\n\n\ncreate \ndocker-compose.yml\n: Full configuration of containers needed for the Cloudbreak deployment.\n\n\ncreate \nuaa.yml\n: Identity Server configuration.\n\n\n\n\nThis will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.\n\n\ncbd logs\n\n\n\n\n\n\nYou can check the logs when the application is ready. It is about 30 seconds.\n\n\n\n\nOnce Cloudbreak is up and running you have to make some provider based configuration. You can use the \nCloudbreak UI\n.", 
            "title": "Deployment"
        }, 
        {
            "location": "/gcp/#gcp-deployment", 
            "text": "You already have a cloudbreak-deployer on the machine now we have to start Cloudbreak.  mkdir -p cloudbreak-deployer\ncd cloudbreak-deployer", 
            "title": "GCP deployment"
        }, 
        {
            "location": "/gcp/#initialize-profile", 
            "text": "First initialize your directory by creating a  Profile  file:  cbd init  It will create a  Profile  file in the current directory. Please edit the file - the only required\nconfiguration is the  PUBLIC_IP . This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the  cbd  tool tries to guess it, if can't than will give a hint.  Change default username/Password  The default credentials can be revealed by  cbd login  These values are used in the  uaa.yml  file's end section. To change these values, add 2 lines into your Profile:  export UAA_DEFAULT_USER_EMAIL=myself@example.com\nexport UAA_DEFAULT_USER_PW=demo123  Regenerate your Profile  There is available a \"cbd regenerate\" command for this.  cbd regenerate  Verify configurations  In order to verify that all configs are OK use the  doctor  command.  cbd doctor  Pull Docker images  All Cloudbreak components and the backend database is running inside containers. The pull command is optional but you can run it prior to cbd start  cbd pull", 
            "title": "Initialize Profile"
        }, 
        {
            "location": "/gcp/#use-cloudbreak", 
            "text": "To start the Cloudbreak application use the following command.  cbd start  Launching the first time will take more time as it does some additional steps:   download all the docker images, needed by Cloudbreak.  create  docker-compose.yml : Full configuration of containers needed for the Cloudbreak deployment.  create  uaa.yml : Identity Server configuration.   This will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.  cbd logs   You can check the logs when the application is ready. It is about 30 seconds.   Once Cloudbreak is up and running you have to make some provider based configuration. You can use the  Cloudbreak UI .", 
            "title": "Use Cloudbreak"
        }, 
        {
            "location": "/gcp_pre_provision/", 
            "text": "Preprovision configurations\n\n\nFollow the \ninstructions\n in Google Cloud's documentation to create a \nService account\n and \nGenerate a new P12 key\n.\n\n\nMake sure that at API level (\nAPIs and auth\n menu) you have enabled:\n\n\n\n\nGoogle Compute Engine\n\n\nGoogle Compute Engine Instance Group Manager API\n\n\nGoogle Compute Engine Instance Groups API\n\n\nBigQuery API\n\n\nGoogle Cloud Deployment Manager API\n\n\nGoogle Cloud DNS API\n\n\nGoogle Cloud SQL\n\n\nGoogle Cloud Storage\n\n\nGoogle Cloud Storage JSON API\n\n\n\n\n\n\nIf you enabled every API then you have to wait about \n10 minutes\n for the provider.\n\n\n\n\nWhen creating GCP credentials in Cloudbreak you will have to provide the email address of the Service Account and the project ID (from Google Developers Console - Projects) where the service account is created. You'll also have to upload the generated P12 file and provide an OpenSSH formatted public key that will be used as an SSH key.\n\n\nOnce Cloudbreak is up and running you can launch clusters in two different ways. You can follow the \nProvisioning prerequisites\n.", 
            "title": "Provisioning prerequisites"
        }, 
        {
            "location": "/gcp_pre_provision/#preprovision-configurations", 
            "text": "Follow the  instructions  in Google Cloud's documentation to create a  Service account  and  Generate a new P12 key .  Make sure that at API level ( APIs and auth  menu) you have enabled:   Google Compute Engine  Google Compute Engine Instance Group Manager API  Google Compute Engine Instance Groups API  BigQuery API  Google Cloud Deployment Manager API  Google Cloud DNS API  Google Cloud SQL  Google Cloud Storage  Google Cloud Storage JSON API    If you enabled every API then you have to wait about  10 minutes  for the provider.   When creating GCP credentials in Cloudbreak you will have to provide the email address of the Service Account and the project ID (from Google Developers Console - Projects) where the service account is created. You'll also have to upload the generated P12 file and provide an OpenSSH formatted public key that will be used as an SSH key.  Once Cloudbreak is up and running you can launch clusters in two different ways. You can follow the  Provisioning prerequisites .", 
            "title": "Preprovision configurations"
        }, 
        {
            "location": "/gcp_cb_ui/", 
            "text": "Manage cloud credentials\n\n\nYou can now log into the Cloudbreak application at http://PUBLIC_IP:3000. Once logged in go to \nManage credentials\n. Using manage credentials will  link your cloud account with the Cloudbreak account.\n\n\nName:\n name of your credential\n\n\nDescription:\n short description of your linked credential\n\n\nProject Id:\n your GCP Project id - see Accounts\n\n\nService Account Email Address:\n your GCP service account mail address - see Accounts\n\n\nService Account private (p12) key:\n your GCP service account generated private key - see Accounts\n\n\nSSH public key:\n the SSH public key in OpenSSH format that's private keypair can be used to log into the launched instances later\n\n\nPublic in account:\n share it with others in the account\n\n\nThe ssh username is \ncloudbreak\n.\n\n\nManage resources\n\n\nUsing manage resources you can create infrastructure templates. Templates describes the infrastructure where the HDP cluster will be provisioned. We support heterogenous clusters - this means that one cluster can be built by combining different templates.\n\n\nName:\n name of your template\n\n\nDescription:\n short description of your template\n\n\nInstance type:\n the Amazon instance type to be used - we suggest to use at least small or medium instances\n\n\nVolume type:\n option to choose are SSD, regular HDD (both EBS) or Ephemeral\n\n\nAttached volumes per instance:\n the number of disks to be attached\n\n\nVolume size (GB):\n the size of the attached disks (in GB)\n\n\nPublic in account:\n share it with others in the account\n\n\nManage blueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster.\n\n\nName:\n name of your blueprint\n\n\nDescription:\n short description of your blueprint\n\n\nSource URL:\n you can add a blueprint by pointing to a URL. As an example you can use this [blueprint](https://raw.githubusercontent.com/sequenceiq/cloudbreak/master/core/src/main/resources/defaults/blueprints/multi-node-hdfs-yarn.bp.\n\n\nManual copy:\n you can copy paste your blueprint in this text area\n\n\nPublic in account:\n share it with others in the account\n\n\nManage networks\n\n\nManage networks allows you to create or reuse existing networks and configure them.\n\n\nName:\n name of the network\n\n\nDescription:\n short description of your network\n\n\nSubnet (CIDR):\n a subnet in the VPC with CIDR block\n\n\nPublic in account:\n share it with others in the account\n\n\nManage security groups\n\n\nSecurity groups allows configuration of traffic/access to the cluster. Currently there are two default groups, and later versions will allow setup of new groups.\n\n\nonly-ssh-and-ssl:\n all ports are locked down (you can't access Hadoop services outside of the VPN)\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\n\n\nall-services-port:\n all Hadoop services + SSH/HTTP are accessible by default:\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\nAmbari (8080)\n\n\nConsul (8500)\n\n\nNN (50070)\n\n\nRM Web (8088)\n\n\nRM Scheduler (8030)\n\n\nRM IPC (8050)\n\n\nJob history server (19888)\n\n\nHBase master (60010)\n\n\nFalcon (15000)\n\n\nStorm (8744)\n\n\nOozie (11000)\n\n\nSpark HS (18080)\n\n\nNM Web (8042)\n\n\nZeppelin WebSocket (9996)\n\n\nZeppelin UI (9995)\n\n\nKibana (3080)\n\n\nElasticsearch (9200)\n\n\n\n\nCreate a cluster\n\n\nUsing the create cluster functionality Cloudbreak will create a cloud Stack and a Hadoop Cluster. In order to create a cluster you will have to select a credential first.\n\n\nCluster name:\n your cluster name\n\n\nRegion:\n the region where the cluster is started\n\n\nNetwork:\n the network template\n\n\nSecurity Group:\n the security group\n\n\nBlueprint:\n your Hadoop cluster blueprint. Once the blueprint is selected we parse it and give you the option to select the followings for each \nhostgroup\n.\n\n\nHostgroup configuration\n\n\nGroup size:\n the number of instances to be started\n\n\nTemplate:\n the stack template associated to the hostgroup\n\n\nEnable security:\n Install KDC and Kerberize the cluster\n\n\nPublic in account:\n share it with others in the account\n\n\nAdvanced features\n:\n\n\nConsul server count:\n the number of Consul servers (odd number), by default is 3. It varies with the cluster size.\n\n\nMinimum cluster size:\n the provisioning strategy in case of the cloud provider can't allocate all the requested nodes\n\n\nValidate blueprint:\n feature to validate or not the Ambari blueprint. By default is switched on.\n\n\nAmbari Repository config:\n you can take the stack RPM's from a custom stack repository\n\n\nOnce you have launched the cluster creation you can track the progress either on Cloudbreak UI or your cloud provider management UI.", 
            "title": "Provisioning - UI"
        }, 
        {
            "location": "/gcp_cb_ui/#manage-cloud-credentials", 
            "text": "You can now log into the Cloudbreak application at http://PUBLIC_IP:3000. Once logged in go to  Manage credentials . Using manage credentials will  link your cloud account with the Cloudbreak account.  Name:  name of your credential  Description:  short description of your linked credential  Project Id:  your GCP Project id - see Accounts  Service Account Email Address:  your GCP service account mail address - see Accounts  Service Account private (p12) key:  your GCP service account generated private key - see Accounts  SSH public key:  the SSH public key in OpenSSH format that's private keypair can be used to log into the launched instances later  Public in account:  share it with others in the account  The ssh username is  cloudbreak .", 
            "title": "Manage cloud credentials"
        }, 
        {
            "location": "/gcp_cb_ui/#manage-resources", 
            "text": "Using manage resources you can create infrastructure templates. Templates describes the infrastructure where the HDP cluster will be provisioned. We support heterogenous clusters - this means that one cluster can be built by combining different templates.  Name:  name of your template  Description:  short description of your template  Instance type:  the Amazon instance type to be used - we suggest to use at least small or medium instances  Volume type:  option to choose are SSD, regular HDD (both EBS) or Ephemeral  Attached volumes per instance:  the number of disks to be attached  Volume size (GB):  the size of the attached disks (in GB)  Public in account:  share it with others in the account", 
            "title": "Manage resources"
        }, 
        {
            "location": "/gcp_cb_ui/#manage-blueprints", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster.  Name:  name of your blueprint  Description:  short description of your blueprint  Source URL:  you can add a blueprint by pointing to a URL. As an example you can use this [blueprint](https://raw.githubusercontent.com/sequenceiq/cloudbreak/master/core/src/main/resources/defaults/blueprints/multi-node-hdfs-yarn.bp.  Manual copy:  you can copy paste your blueprint in this text area  Public in account:  share it with others in the account", 
            "title": "Manage blueprints"
        }, 
        {
            "location": "/gcp_cb_ui/#manage-networks", 
            "text": "Manage networks allows you to create or reuse existing networks and configure them.  Name:  name of the network  Description:  short description of your network  Subnet (CIDR):  a subnet in the VPC with CIDR block  Public in account:  share it with others in the account", 
            "title": "Manage networks"
        }, 
        {
            "location": "/gcp_cb_ui/#manage-security-groups", 
            "text": "Security groups allows configuration of traffic/access to the cluster. Currently there are two default groups, and later versions will allow setup of new groups.  only-ssh-and-ssl:  all ports are locked down (you can't access Hadoop services outside of the VPN)   SSH (22)  HTTPS (443)   all-services-port:  all Hadoop services + SSH/HTTP are accessible by default:   SSH (22)  HTTPS (443)  Ambari (8080)  Consul (8500)  NN (50070)  RM Web (8088)  RM Scheduler (8030)  RM IPC (8050)  Job history server (19888)  HBase master (60010)  Falcon (15000)  Storm (8744)  Oozie (11000)  Spark HS (18080)  NM Web (8042)  Zeppelin WebSocket (9996)  Zeppelin UI (9995)  Kibana (3080)  Elasticsearch (9200)", 
            "title": "Manage security groups"
        }, 
        {
            "location": "/gcp_cb_ui/#create-a-cluster", 
            "text": "Using the create cluster functionality Cloudbreak will create a cloud Stack and a Hadoop Cluster. In order to create a cluster you will have to select a credential first.  Cluster name:  your cluster name  Region:  the region where the cluster is started  Network:  the network template  Security Group:  the security group  Blueprint:  your Hadoop cluster blueprint. Once the blueprint is selected we parse it and give you the option to select the followings for each  hostgroup .  Hostgroup configuration  Group size:  the number of instances to be started  Template:  the stack template associated to the hostgroup  Enable security:  Install KDC and Kerberize the cluster  Public in account:  share it with others in the account  Advanced features :  Consul server count:  the number of Consul servers (odd number), by default is 3. It varies with the cluster size.  Minimum cluster size:  the provisioning strategy in case of the cloud provider can't allocate all the requested nodes  Validate blueprint:  feature to validate or not the Ambari blueprint. By default is switched on.  Ambari Repository config:  you can take the stack RPM's from a custom stack repository  Once you have launched the cluster creation you can track the progress either on Cloudbreak UI or your cloud provider management UI.", 
            "title": "Create a cluster"
        }, 
        {
            "location": "/gcp_cb_shell/", 
            "text": "Interactive mode\n\n\nStart the shell with \ncbd util cloudbreak-shell\n. This will launch the Cloudbreak shell inside a Docker container and you are ready to start using it.\n\n\nCreate a cloud credential\n\n\nIn order to start using Cloudbreak to provision a cluster in Google Cloud you will need to have an GCP credential. If you do not want to Cloubreak to reach you google cloud resources then you have to delete the service account.\n\n\ncredential create --GCP --description \ndescription\n --name \nmyCredentialName\n --projectId \nprojectid\n --serviceAccountId \n12345test@developer.gserviceaccount.com\n --serviceAccountPrivateKeyPath \n/tmp/gcp.p12\n --sshKeyUrl \nURL towards your GCP public key\n\n\n\n\n\nAlternatively you can upload your public key from a file as well, by using the \n\u2014sshKeyPath\n switch. You can check whether the credential was creates successfully by using the \ncredential list\n command.\nYou can switch between your cloud credential - when you\u2019d like to use one and act with that you will have to use:\n\n\ncredential select --name #NAME of the credential\n\n\n\n\nYou can delete your cloud credential - when you\u2019d like to delete one you will have to use:\n\n\ncredential delete --name #NAME of the credential\n\n\n\n\nYou can show your cloud credential - when you\u2019d like to show one you will have to use:\n\n\ncredential show --name #NAME of the credential\n\n\n\n\nCreate a template\n\n\nA template gives developers and systems administrators an easy way to create and manage a collection of cloud infrastructure related resources, maintaining and updating them in an orderly and predictable fashion. A template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a new stack).\n\n\ntemplate create --GCP --name gcptemplate --description gcp-template --instanceType N1_STANDARD_4 --volumeSize 100 --volumeCount 2\n\n\n\n\nOther available options:\n\n\n--volumeType \"voltype\": defaults to \"HDD\", other allowed value: \"SSD\"\n\n\n--publicInAccount \"flag\": flags if the template is public in the account\n\n\nYou can check whether the template was created successfully by using the \ntemplate list\n command.\nCheck the template and select it if you are happy with it:\n\n\ntemplate select --name #NAME of the template\n\n\n\n\nYou can delete your cloud template - when you\u2019d like to delete one you will have to use:\n\n\ntemplate delete --name #NAME of the template\n\n\n\n\nYou can show your cloud template - when you\u2019d like to show one you will have to use:\n\n\ntemplate show --name #NAME of the template\n\n\n\n\nCreate a stack\n\n\nStacks are template \ninstances\n - a running cloud infrastructure created based on a template. Use the following command to create a stack to be used with your Hadoop cluster:\n\n\nstack create --name \nmyStackName\n --nodeCount 10\n\n\n\n\nSelect a blueprint\n\n\nWe ship default Hadoop cluster blueprints with Cloudbreak. You can use these blueprints or add yours. To see the available blueprints and use one of them please use:\n\n\nblueprint list\n\nblueprint select --name #NAME of the blueprint\n\n\n\n\nCreate a Hadoop cluster\n\n\nYou are almost done - one more command and this will create your Hadoop cluster on your favorite cloud provider. Same as the API, or UI this will use your \ntemplate\n, and by using CloudFormation will launch a cloud \nstack\n - once the \nstack\n is up and running (cloud provisioning is done) it will use your selected \nblueprint\n and install your custom Hadoop cluster with the selected components and services.\n\n\ncluster create --description \nmy cluster desc\n\n\n\n\n\nYou are done - you can check the progress through the Ambari UI. If you log back to Cloudbreak UI you can check the progress over there as well, and learn the IP address of Ambari.\n\n\nSilent mode\n\n\nWith Cloudbreak shell you can recreate clusters based on earlier deployments. Each time you start the shell the executed commands are logged in a file line by line and later either with the \nscript\n command or specifying an \n\u2014cmdfile\n option the same commands can be executed again.\n\n\nWith \ncbd util cloudbreak-shell-quiet\n you can specify a shell file and let the shell apply the configs step by step in a silent mode.", 
            "title": "Provisioning - CLI"
        }, 
        {
            "location": "/gcp_cb_shell/#interactive-mode", 
            "text": "Start the shell with  cbd util cloudbreak-shell . This will launch the Cloudbreak shell inside a Docker container and you are ready to start using it.  Create a cloud credential  In order to start using Cloudbreak to provision a cluster in Google Cloud you will need to have an GCP credential. If you do not want to Cloubreak to reach you google cloud resources then you have to delete the service account.  credential create --GCP --description  description  --name  myCredentialName  --projectId  projectid  --serviceAccountId  12345test@developer.gserviceaccount.com  --serviceAccountPrivateKeyPath  /tmp/gcp.p12  --sshKeyUrl  URL towards your GCP public key   Alternatively you can upload your public key from a file as well, by using the  \u2014sshKeyPath  switch. You can check whether the credential was creates successfully by using the  credential list  command.\nYou can switch between your cloud credential - when you\u2019d like to use one and act with that you will have to use:  credential select --name #NAME of the credential  You can delete your cloud credential - when you\u2019d like to delete one you will have to use:  credential delete --name #NAME of the credential  You can show your cloud credential - when you\u2019d like to show one you will have to use:  credential show --name #NAME of the credential  Create a template  A template gives developers and systems administrators an easy way to create and manage a collection of cloud infrastructure related resources, maintaining and updating them in an orderly and predictable fashion. A template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a new stack).  template create --GCP --name gcptemplate --description gcp-template --instanceType N1_STANDARD_4 --volumeSize 100 --volumeCount 2  Other available options:  --volumeType \"voltype\": defaults to \"HDD\", other allowed value: \"SSD\"  --publicInAccount \"flag\": flags if the template is public in the account  You can check whether the template was created successfully by using the  template list  command.\nCheck the template and select it if you are happy with it:  template select --name #NAME of the template  You can delete your cloud template - when you\u2019d like to delete one you will have to use:  template delete --name #NAME of the template  You can show your cloud template - when you\u2019d like to show one you will have to use:  template show --name #NAME of the template  Create a stack  Stacks are template  instances  - a running cloud infrastructure created based on a template. Use the following command to create a stack to be used with your Hadoop cluster:  stack create --name  myStackName  --nodeCount 10  Select a blueprint  We ship default Hadoop cluster blueprints with Cloudbreak. You can use these blueprints or add yours. To see the available blueprints and use one of them please use:  blueprint list\n\nblueprint select --name #NAME of the blueprint  Create a Hadoop cluster  You are almost done - one more command and this will create your Hadoop cluster on your favorite cloud provider. Same as the API, or UI this will use your  template , and by using CloudFormation will launch a cloud  stack  - once the  stack  is up and running (cloud provisioning is done) it will use your selected  blueprint  and install your custom Hadoop cluster with the selected components and services.  cluster create --description  my cluster desc   You are done - you can check the progress through the Ambari UI. If you log back to Cloudbreak UI you can check the progress over there as well, and learn the IP address of Ambari.", 
            "title": "Interactive mode"
        }, 
        {
            "location": "/gcp_cb_shell/#silent-mode", 
            "text": "With Cloudbreak shell you can recreate clusters based on earlier deployments. Each time you start the shell the executed commands are logged in a file line by line and later either with the  script  command or specifying an  \u2014cmdfile  option the same commands can be executed again.  With  cbd util cloudbreak-shell-quiet  you can specify a shell file and let the shell apply the configs step by step in a silent mode.", 
            "title": "Silent mode"
        }, 
        {
            "location": "/openstack/", 
            "text": "OpenStack based installation\n\n\nWe have pre-built a custom OpenStack image available on VM Depot with all the required tooling and Cloudbreak deployer installed. In order to launch this image on OpenStack please use the following \nimage\n.\n\n\nCloudbreak will already be installed, thus you can follow these steps to launch the application.\n\n\nUsage\n\n\nOnce the Cloudbreak deployer is installed it will generate some config files and will download supporting binaries. It is\nadvised that you create a dedicated directory for it:\n\n\nmkdir cloudbreak-deployment\ncd cloudbreak-deployment\n\n\n\n\nInitialize Profile\n\n\nFirst initialize your directory by creating a \nProfile\n file:\n\n\ncbd init\n\n\n\n\nIt will create a \nProfile\n file in the current directory. Please edit the file - the only required\nconfiguration is the \nPUBLIC_IP\n. This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the \ncbd\n tool tries to guess it, if can't than will give a hint.\n\n\nChange default username/Password\n\n\nThe default credentials can be revealed by \ncbd login\n These values are used in the \nuaa.yml\n file's end section. To change these values, add 2 lines into your Profile:\n\n\nexport UAA_DEFAULT_USER_EMAIL=myself@example.com\nexport UAA_DEFAULT_USER_PW=demo123\n\n\n\n\nRegenerate your Profile\n\n\nYou are done with the configuration of Cloudbreak deployer. The last thing you have to do is to regenerate the configurations in order to take effect.\n\n\nrm *.yml\ncbd generate\n\n\n\n\nVerify configs\n\n\nIn order to verify that all configs are OK use the \ndoctor\n command.\n\n\ncbd doctor\n\n\n\n\nStart Cloudbreak\n\n\nTo start all the containers run:\n\n\ncbd start\n\n\n\n\nLaunching the first time will take more time as it does some additional steps:\n\n\n\n\ndownload all the docker images, needed by Cloudbreak.\n\n\ncreate \ndocker-compose.yml\n: Full configuration of containers needed for the Cloudbreak deployment.\n\n\ncreate \nuaa.yml\n: Identity Server configuration.\n\n\n\n\nThis will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.\n\n\nWatch the logs\n\n\ncbd logs", 
            "title": "Deployment"
        }, 
        {
            "location": "/openstack/#openstack-based-installation", 
            "text": "We have pre-built a custom OpenStack image available on VM Depot with all the required tooling and Cloudbreak deployer installed. In order to launch this image on OpenStack please use the following  image .  Cloudbreak will already be installed, thus you can follow these steps to launch the application.", 
            "title": "OpenStack based installation"
        }, 
        {
            "location": "/openstack/#usage", 
            "text": "Once the Cloudbreak deployer is installed it will generate some config files and will download supporting binaries. It is\nadvised that you create a dedicated directory for it:  mkdir cloudbreak-deployment\ncd cloudbreak-deployment  Initialize Profile  First initialize your directory by creating a  Profile  file:  cbd init  It will create a  Profile  file in the current directory. Please edit the file - the only required\nconfiguration is the  PUBLIC_IP . This IP will be used to access the Cloudbreak UI\n(called Uluwatu). In some cases the  cbd  tool tries to guess it, if can't than will give a hint.  Change default username/Password  The default credentials can be revealed by  cbd login  These values are used in the  uaa.yml  file's end section. To change these values, add 2 lines into your Profile:  export UAA_DEFAULT_USER_EMAIL=myself@example.com\nexport UAA_DEFAULT_USER_PW=demo123  Regenerate your Profile  You are done with the configuration of Cloudbreak deployer. The last thing you have to do is to regenerate the configurations in order to take effect.  rm *.yml\ncbd generate  Verify configs  In order to verify that all configs are OK use the  doctor  command.  cbd doctor  Start Cloudbreak  To start all the containers run:  cbd start  Launching the first time will take more time as it does some additional steps:   download all the docker images, needed by Cloudbreak.  create  docker-compose.yml : Full configuration of containers needed for the Cloudbreak deployment.  create  uaa.yml : Identity Server configuration.   This will start all the Docker containers and initialize the application. Please give a few minutes until all services starts. While the services are starting you can check the logs.  Watch the logs  cbd logs", 
            "title": "Usage"
        }, 
        {
            "location": "/openstack_cb_ui/", 
            "text": "Once Cloudbreak is up and running you can launch clusters in two different ways. You can use the \nCloudbreak UI\n or use the \nCloudbreak shell\n.\n\n\nManage cloud credentials\n\n\nYou can now log into the Cloudbreak application at http://PUBLIC_IP:3000. Once logged in go to \nManage credentials\n. Using manage credentials will  link your cloud account with the Cloudbreak account.\n\n\nName:\n name of your credential\n\n\nDescription:\n short description of your linked credential\n\n\nUser:\n your OpenStack user\n\n\nPassword:\n your password\n\n\nTenant Name:\n OpenStack tenant name\n\n\nEndpoint:\n Openstack Identity Service (Keystone) endpont (e.g. http://PUBLIC_IP:5000/v2.0)\n\n\nSSH certificate:\n the SSH public certificate in OpenSSH format that's private keypair can be used to log into the launched instances later with the ssh username \ncentos\n\n\nPublic in account:\n share it with others in the account\n\n\nManage resources\n\n\nUsing manage resources you can create infrastructure templates. Templates describes the infrastructure where the HDP cluster will be provisioned. We support heterogenous clusters - this means that one cluster can be built by combining different templates.\n\n\nName:\n name of your template\n\n\nDescription:\n short description of your template\n\n\nInstance type:\n the OpenStack instance type to be used\n\n\nAttached volumes per instance:\n the number of disks to be attached\n\n\nVolume size (GB):\n the size of the attached disks (in GB)\n\n\nPublic in account:\n share it with others in the account\n\n\nManage blueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster.\n\n\nName:\n name of your blueprint\n\n\nDescription:\n short description of your blueprint\n\n\nSource URL:\n you can add a blueprint by pointing to a URL. As an example you can use this \nblueprint\n.\n\n\nManual copy:\n you can copy paste your blueprint in this text area\n\n\nPublic in account:\n share it with others in the account\n\n\nManage networks\n\n\nManage networks allows you to create or reuse existing networks and configure them.\n\n\nName:\n name of the network\n\n\nDescription:\n short description of your network\n\n\nSubnet (CIDR):\n a subnet in the VPC with CIDR block\n\n\nPublic network ID\n id of an OpenStack public network\n\n\nPublic in account:\n share it with others in the account\n\n\nManage security groups\n\n\nSecurity groups allows configuration of traffic/access to the cluster. Currently there are two default groups, and later versions will allow setup of new groups.\n\n\nonly-ssh-and-ssl:\n all ports are locked down (you can't access Hadoop services outside of the VPN) but \n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\n\n\nall-services-port:\n all Hadoop services + SSH/HTTP are accessible by default:\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\nAmbari (8080)\n\n\nConsul (8500) \n\n\nNN (50070) \n\n\nRM Web (8088) \n\n\nRM Scheduler (8030) \n\n\nRM IPC (8050) \n\n\nJob history server (19888) \n\n\nHBase master (60010) \n\n\nFalcon (15000) \n\n\nStorm (8744) \n\n\nOozie (11000) \n\n\nSpark HS (18080) \n\n\nNM Web (8042) \n\n\nZeppelin WebSocket (9996) \n\n\nZeppelin UI (9995) \n\n\nKibana (3080) \n\n\nElasticsearch (9200) \n\n\n\n\nCreate a cluster\n\n\nUsing the create cluster functionality Cloudbreak will create a cloud Stack and a Hadoop Cluster. In order to create a cluster you will have to select a credential first.\n\n\nCluster name:\n your cluster name\n\n\nRegion:\n the region where the cluster is started\n\n\nNetwork:\n the network template\n\n\n`Security Group:\" the security group\n\n\nBlueprint:\n your Hadoop cluster blueprint. Once the blueprint is selected we parse it and give you the option to select the followings for each \nhostgroup\n.\n\n\nHostgroup configuration\n\n\n\n\nGroup size:\n the number of instances to be started\n\n\nTemplate:\n the stack template associated to the hostgroup\n\n\n\n\nPublic in account:\n share it with others in the account\n\n\nEnable security:\n Install KDC and Kerberize the cluster\n\n\nAdvanced features\n:\n\n\nConsul server count:\n the number of Consul servers (odd number), by default is 3. It varies with the cluster size.\n\n\nPlatform variant:\n Cloudbreak provides two implementation for creating OpenStack cluster\n\n\n\n\nHEAT:\n using heat template to create the resources\n\n\nNATIVE:\n using API calls to create the resources\n\n\n\n\nMinimum cluster size:\n the provisioning strategy in case of the cloud provider can't allocate all the requested nodes\n\n\nValidate blueprint:\n feature to validate or not the Ambari blueprint. By default is switched on.\n\n\nAmbari Repository config:\n you can take the stack RPM's from a custom stack repository\n\n\nOnce you have launched the cluster creation you can track the progress either on Cloudbreak UI or your cloud provider management UI.", 
            "title": "Provisioning - UI"
        }, 
        {
            "location": "/openstack_cb_ui/#manage-cloud-credentials", 
            "text": "You can now log into the Cloudbreak application at http://PUBLIC_IP:3000. Once logged in go to  Manage credentials . Using manage credentials will  link your cloud account with the Cloudbreak account.  Name:  name of your credential  Description:  short description of your linked credential  User:  your OpenStack user  Password:  your password  Tenant Name:  OpenStack tenant name  Endpoint:  Openstack Identity Service (Keystone) endpont (e.g. http://PUBLIC_IP:5000/v2.0)  SSH certificate:  the SSH public certificate in OpenSSH format that's private keypair can be used to log into the launched instances later with the ssh username  centos  Public in account:  share it with others in the account", 
            "title": "Manage cloud credentials"
        }, 
        {
            "location": "/openstack_cb_ui/#manage-resources", 
            "text": "Using manage resources you can create infrastructure templates. Templates describes the infrastructure where the HDP cluster will be provisioned. We support heterogenous clusters - this means that one cluster can be built by combining different templates.  Name:  name of your template  Description:  short description of your template  Instance type:  the OpenStack instance type to be used  Attached volumes per instance:  the number of disks to be attached  Volume size (GB):  the size of the attached disks (in GB)  Public in account:  share it with others in the account", 
            "title": "Manage resources"
        }, 
        {
            "location": "/openstack_cb_ui/#manage-blueprints", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster.  Name:  name of your blueprint  Description:  short description of your blueprint  Source URL:  you can add a blueprint by pointing to a URL. As an example you can use this  blueprint .  Manual copy:  you can copy paste your blueprint in this text area  Public in account:  share it with others in the account", 
            "title": "Manage blueprints"
        }, 
        {
            "location": "/openstack_cb_ui/#manage-networks", 
            "text": "Manage networks allows you to create or reuse existing networks and configure them.  Name:  name of the network  Description:  short description of your network  Subnet (CIDR):  a subnet in the VPC with CIDR block  Public network ID  id of an OpenStack public network  Public in account:  share it with others in the account", 
            "title": "Manage networks"
        }, 
        {
            "location": "/openstack_cb_ui/#manage-security-groups", 
            "text": "Security groups allows configuration of traffic/access to the cluster. Currently there are two default groups, and later versions will allow setup of new groups.  only-ssh-and-ssl:  all ports are locked down (you can't access Hadoop services outside of the VPN) but    SSH (22)  HTTPS (443)   all-services-port:  all Hadoop services + SSH/HTTP are accessible by default:   SSH (22)  HTTPS (443)  Ambari (8080)  Consul (8500)   NN (50070)   RM Web (8088)   RM Scheduler (8030)   RM IPC (8050)   Job history server (19888)   HBase master (60010)   Falcon (15000)   Storm (8744)   Oozie (11000)   Spark HS (18080)   NM Web (8042)   Zeppelin WebSocket (9996)   Zeppelin UI (9995)   Kibana (3080)   Elasticsearch (9200)", 
            "title": "Manage security groups"
        }, 
        {
            "location": "/openstack_cb_ui/#create-a-cluster", 
            "text": "Using the create cluster functionality Cloudbreak will create a cloud Stack and a Hadoop Cluster. In order to create a cluster you will have to select a credential first.  Cluster name:  your cluster name  Region:  the region where the cluster is started  Network:  the network template  `Security Group:\" the security group  Blueprint:  your Hadoop cluster blueprint. Once the blueprint is selected we parse it and give you the option to select the followings for each  hostgroup .  Hostgroup configuration   Group size:  the number of instances to be started  Template:  the stack template associated to the hostgroup   Public in account:  share it with others in the account  Enable security:  Install KDC and Kerberize the cluster  Advanced features :  Consul server count:  the number of Consul servers (odd number), by default is 3. It varies with the cluster size.  Platform variant:  Cloudbreak provides two implementation for creating OpenStack cluster   HEAT:  using heat template to create the resources  NATIVE:  using API calls to create the resources   Minimum cluster size:  the provisioning strategy in case of the cloud provider can't allocate all the requested nodes  Validate blueprint:  feature to validate or not the Ambari blueprint. By default is switched on.  Ambari Repository config:  you can take the stack RPM's from a custom stack repository  Once you have launched the cluster creation you can track the progress either on Cloudbreak UI or your cloud provider management UI.", 
            "title": "Create a cluster"
        }, 
        {
            "location": "/openstack_cb_shell/", 
            "text": "", 
            "title": "Provisioning - CLI"
        }, 
        {
            "location": "/api/", 
            "text": "API documentation\n\n\nCloudbreak is a RESTful application development platform with the goal of helping developers to build solutions for deploying HDP clusters in different environments. Once it is deployed in your favourite servlet container it exposes a REST API allowing to span up Hadoop clusters of arbitary sizes and cloud providers.\n\n\nThe \nAPI documentation\n is generated from the code using \nSwagger\n.", 
            "title": "API"
        }, 
        {
            "location": "/api/#api-documentation", 
            "text": "Cloudbreak is a RESTful application development platform with the goal of helping developers to build solutions for deploying HDP clusters in different environments. Once it is deployed in your favourite servlet container it exposes a REST API allowing to span up Hadoop clusters of arbitary sizes and cloud providers.  The  API documentation  is generated from the code using  Swagger .", 
            "title": "API documentation"
        }, 
        {
            "location": "/shell/", 
            "text": "Cloudbreak Shell\n\n\nThe goal with the CLI was to provide an interactive command line tool which supports:\n\n\n\n\nall functionality available through the REST API or Cloudbreak web UI\n\n\nmakes possible complete automation of management task via \nscripts\n\n\ncontext aware command availability\n\n\ntab completion\n\n\nrequired/optional parameter support\n\n\nhint\n command to guide you on the usual path\n\n\n\n\nInstall and start Cloudbreak shell\n\n\nYou have a few options to give it a try:\n\n\n\n\nuse Cloudreak deployer\n\n\nuse our prepared docker image\n\n\nbuild it from source\n\n\n\n\n\n\nStarting cloudbreak shell using cloudbreak deployer\n\n\nStart the shell with \ncbd util cloudbreak-shell\n. This will launch the Cloudbreak shell inside a Docker container and you are ready to start using it.\n\n\n\n\nStarting Cloudbreak shell with our prepared docker image\n\n\nYou can find the docker image and its documentation \nhere\n.\n\n\n\n\nBuild from source\n\n\nIf want to use the code or extend it with new commands follow the steps below. You will need:\n- jdk 1.7\n\n\ngit clone https://github.com/sequenceiq/cloudbreak-shell.git\ncd cloudbreak-shell\n./gradlew clean build\n\n\n\n\nNote: In case you use the hosted version of Cloudbreak you should use the \nlatest-release.sh\n to get the right version of the CLI.\n\n\nStart Cloudbreak-shell from the built source\n\n\nUsage:\n  java -jar cloudbreak-shell-0.5-SNAPSHOT.jar                  : Starts Cloudbreak Shell in interactive mode.\n  java -jar cloudbreak-shell-0.5-SNAPSHOT.jar --cmdfile=\nFILE\n : Cloudbreak executes commands read from the file.\n\nOptions:\n  --cloudbreak.address=\nhttp[s]://HOSTNAME:PORT\n  Address of the Cloudbreak Server [default: https://cloudbreak-api.sequenceiq.com].\n  --identity.address=\nhttp[s]://HOSTNAME:PORT\n    Address of the SequenceIQ identity server [default: https://identity.sequenceiq.com].\n  --sequenceiq.user=\nUSER\n                        Username of the SequenceIQ user [default: user@sequenceiq.com].\n  --sequenceiq.password=\nPASSWORD\n                Password of the SequenceIQ user [default: password].\n\nNote:\n  You should specify at least your username and password.\n\n\n\n\nOnce you are connected you can start to create a cluster. If you are lost and need guidance through the process you can use \nhint\n. You can always use \nTAB\n for completion. Note that all commands are \ncontext aware\n - they are available only when it makes sense - this way you are never confused and guided by the system on the right path.\n\n\nYou can find the provider specific documentations here:\n\n\n\n\nAWS\n\n\nAzure\n\n\nGCP\n\n\nOpenStack", 
            "title": "Shell"
        }, 
        {
            "location": "/shell/#cloudbreak-shell", 
            "text": "The goal with the CLI was to provide an interactive command line tool which supports:   all functionality available through the REST API or Cloudbreak web UI  makes possible complete automation of management task via  scripts  context aware command availability  tab completion  required/optional parameter support  hint  command to guide you on the usual path", 
            "title": "Cloudbreak Shell"
        }, 
        {
            "location": "/shell/#install-and-start-cloudbreak-shell", 
            "text": "You have a few options to give it a try:   use Cloudreak deployer  use our prepared docker image  build it from source    Starting cloudbreak shell using cloudbreak deployer  Start the shell with  cbd util cloudbreak-shell . This will launch the Cloudbreak shell inside a Docker container and you are ready to start using it.   Starting Cloudbreak shell with our prepared docker image  You can find the docker image and its documentation  here .   Build from source  If want to use the code or extend it with new commands follow the steps below. You will need:\n- jdk 1.7  git clone https://github.com/sequenceiq/cloudbreak-shell.git\ncd cloudbreak-shell\n./gradlew clean build  Note: In case you use the hosted version of Cloudbreak you should use the  latest-release.sh  to get the right version of the CLI.  Start Cloudbreak-shell from the built source  Usage:\n  java -jar cloudbreak-shell-0.5-SNAPSHOT.jar                  : Starts Cloudbreak Shell in interactive mode.\n  java -jar cloudbreak-shell-0.5-SNAPSHOT.jar --cmdfile= FILE  : Cloudbreak executes commands read from the file.\n\nOptions:\n  --cloudbreak.address= http[s]://HOSTNAME:PORT   Address of the Cloudbreak Server [default: https://cloudbreak-api.sequenceiq.com].\n  --identity.address= http[s]://HOSTNAME:PORT     Address of the SequenceIQ identity server [default: https://identity.sequenceiq.com].\n  --sequenceiq.user= USER                         Username of the SequenceIQ user [default: user@sequenceiq.com].\n  --sequenceiq.password= PASSWORD                 Password of the SequenceIQ user [default: password].\n\nNote:\n  You should specify at least your username and password.  Once you are connected you can start to create a cluster. If you are lost and need guidance through the process you can use  hint . You can always use  TAB  for completion. Note that all commands are  context aware  - they are available only when it makes sense - this way you are never confused and guided by the system on the right path.  You can find the provider specific documentations here:   AWS  Azure  GCP  OpenStack", 
            "title": "Install and start Cloudbreak shell"
        }, 
        {
            "location": "/recipes/", 
            "text": "Cluster customization\n\n\nWith the help of Cloudbreak it is very easy to provision Hadoop clusters in the cloud from an Apache Ambari blueprint. Cloudbreak built in provisioning doesn't contain every use case, so we are introducing the concept of recipes.\nRecipes are basically script extensions to a cluster that run on a set of nodes before or after the Ambari cluster installation. With recipes it's quite easy for example to put a JAR file on the Hadoop classpath or run some custom scripts.\nIn Cloudbreak we supports two ways to configure recipe, we have downloadable and stored recipes. A downloadable recipe should be available on HTTP, HTTPS protocols optionally with basic authentication, or any kind of public Git repository.\nAs the name mentions stored recipes are uploaded and stored in Cloudbreak via web interface or shell.\n\n\nDownloadable recipes\n\n\nThis kind of recipe must contain a plugin.toml file, with some basic information about the recipe, and at least a recipe-pre-install or recipe-post-install script.\nContent of plugin.toml\n\n\n[plugin]\nname = \n[recipe-name]\n\ndescription = \n[description-of-the-recipe]\n\nversion = \n1.0\n\nmaintainer_name = \n[maintainer-name]\n\nmaintainer_email = \n[maintainer-email]\n\nwebsite_url = \n[website-url]\n\n\n\n\n\nPre and post scripts are regular shell scripts, and must be executable.\n\n\nTo configure recipe or recipe groups in Cloudbreak you have to create a descriptive JSON file and send it to Cloudbreak via our shell. On web interface you could skip this step, just fill the required fields.\n\n\n{\n  \nname\n: \n[recipe-name]\n,\n  \ndescription\n: \n[description-of-the-recipe]\n,\n  \nproperties\n: {\n    \n[key]\n: \n[value]\n\n  },\n  \nplugins\n: {\n      \ngit://github.com/account/recipe.git\n: \nONE_NODE\n\n      \nhttp://user:password@mydomain.com/my-recipe.tar\n: \nALL_NODES\n\n      \nhttps://mydomain.com/my-recipe.zip\n: \nALL_NODES\n\n  }\n}\n\n\n\n\nAt this point we need to understand some element of the JSON above.\n\n\nFirst of all properties. Properties are saved to Consul key/value store, and they are available from the pre or post script by fetching http://localhost:8500/v1/kv/[key]?raw url. The limitation of the value's base64 representation is 512kB. This option is a good choice if you want to write reusable recipes.\n\n\nThe next one is plugins. As you read before we support a few kind of protocols, and each of them has their own limitations:\n\n\n\n\n\n\nGit\n\n\n\n\ngit repository must be public (or available from the cluster)\n\n\nthe recipe files must be on the root\n\n\nonly repository default branch supported, there is no opportunity to check out different branch\n\n\n\n\n\n\n\n\nHTTP(S)\n\n\n\n\non this kind of protocols you have to bundle your recipe into a tar or zip file\n\n\nbasic authentication is the only way to protect recipe from public\n\n\n\n\n\n\n\n\nLast one is the execution type of the recipe. We supports two options:\n\n\n\n\nONE_NODE means the recipe will execute only one node in the hostgroup\n\n\nAll_NODES runs every single instance in the hostgroup.\n\n\n\n\nTo add recipe use the command(s) below:\n\n\nrecipe add --file /path/of/the/recipe/json\n\n\n\n\nor\n\n\nrecipe add --url http(s)://mydomain.com/my-recipe.json\n\n\n\n\nAdd command has an optional parameter --publicInAccount, flags if the template is public in the account.\n\n\nStored recipes\n\n\nThe easiest way to create a custom recipe in Cloudbreak is stored recipes. Create your own pre and/or post scripts, and upload them via shell or web interface. In the background Cloudbreak pushes recipe to Consul key/value store during cluster creation.\nStored recipes has the same size limitation like properties in downloadable recipe, because of the key/value store, the base64 encoded contents of the scripts must be less then 512kB.\n\n\nrecipe store --name [recipe-name] --executionType [ONE_NODE|ALL_NODES] --preInstallScriptFile /path/of/the/pre-install-script --postInstallScriptFile /path/of/the/post-install-script\n\n\n\n\nThis command has two optional parameters:\n- --description \"string\": description of the recipe\n- --timeout \"integer\": timeout of the script execution\n- --publicInAccount \"flag\": flags if the template is public in the account\n\n\nRecipes are ready to use at hostgroup configuration.", 
            "title": "Recipes"
        }, 
        {
            "location": "/recipes/#cluster-customization", 
            "text": "With the help of Cloudbreak it is very easy to provision Hadoop clusters in the cloud from an Apache Ambari blueprint. Cloudbreak built in provisioning doesn't contain every use case, so we are introducing the concept of recipes.\nRecipes are basically script extensions to a cluster that run on a set of nodes before or after the Ambari cluster installation. With recipes it's quite easy for example to put a JAR file on the Hadoop classpath or run some custom scripts.\nIn Cloudbreak we supports two ways to configure recipe, we have downloadable and stored recipes. A downloadable recipe should be available on HTTP, HTTPS protocols optionally with basic authentication, or any kind of public Git repository.\nAs the name mentions stored recipes are uploaded and stored in Cloudbreak via web interface or shell.  Downloadable recipes  This kind of recipe must contain a plugin.toml file, with some basic information about the recipe, and at least a recipe-pre-install or recipe-post-install script.\nContent of plugin.toml  [plugin]\nname =  [recipe-name] \ndescription =  [description-of-the-recipe] \nversion =  1.0 \nmaintainer_name =  [maintainer-name] \nmaintainer_email =  [maintainer-email] \nwebsite_url =  [website-url]   Pre and post scripts are regular shell scripts, and must be executable.  To configure recipe or recipe groups in Cloudbreak you have to create a descriptive JSON file and send it to Cloudbreak via our shell. On web interface you could skip this step, just fill the required fields.  {\n   name :  [recipe-name] ,\n   description :  [description-of-the-recipe] ,\n   properties : {\n     [key] :  [value] \n  },\n   plugins : {\n       git://github.com/account/recipe.git :  ONE_NODE \n       http://user:password@mydomain.com/my-recipe.tar :  ALL_NODES \n       https://mydomain.com/my-recipe.zip :  ALL_NODES \n  }\n}  At this point we need to understand some element of the JSON above.  First of all properties. Properties are saved to Consul key/value store, and they are available from the pre or post script by fetching http://localhost:8500/v1/kv/[key]?raw url. The limitation of the value's base64 representation is 512kB. This option is a good choice if you want to write reusable recipes.  The next one is plugins. As you read before we support a few kind of protocols, and each of them has their own limitations:    Git   git repository must be public (or available from the cluster)  the recipe files must be on the root  only repository default branch supported, there is no opportunity to check out different branch     HTTP(S)   on this kind of protocols you have to bundle your recipe into a tar or zip file  basic authentication is the only way to protect recipe from public     Last one is the execution type of the recipe. We supports two options:   ONE_NODE means the recipe will execute only one node in the hostgroup  All_NODES runs every single instance in the hostgroup.   To add recipe use the command(s) below:  recipe add --file /path/of/the/recipe/json  or  recipe add --url http(s)://mydomain.com/my-recipe.json  Add command has an optional parameter --publicInAccount, flags if the template is public in the account.  Stored recipes  The easiest way to create a custom recipe in Cloudbreak is stored recipes. Create your own pre and/or post scripts, and upload them via shell or web interface. In the background Cloudbreak pushes recipe to Consul key/value store during cluster creation.\nStored recipes has the same size limitation like properties in downloadable recipe, because of the key/value store, the base64 encoded contents of the scripts must be less then 512kB.  recipe store --name [recipe-name] --executionType [ONE_NODE|ALL_NODES] --preInstallScriptFile /path/of/the/pre-install-script --postInstallScriptFile /path/of/the/post-install-script  This command has two optional parameters:\n- --description \"string\": description of the recipe\n- --timeout \"integer\": timeout of the script execution\n- --publicInAccount \"flag\": flags if the template is public in the account  Recipes are ready to use at hostgroup configuration.", 
            "title": "Cluster customization"
        }, 
        {
            "location": "/spi/", 
            "text": "", 
            "title": "SPI"
        }, 
        {
            "location": "/kerberos/", 
            "text": "Kerberos security\n\n\nCloudbreak supports Kerberos security for Ambari internal communication. To activate Kerberos with Cloudbreak you have enable security option and fill the \nkerberos master key\n, \nkerberos admin\n and \nkerberos password\n fields too on web interface or shell during cluster creation. To run a job on the cluster, you can use one of the default Hadoop users, like \nambari-qa\n, as usual. Current implementation of Kerberos security doesn't contain Active Directory support or any other third party user authentication method. If you want to use custom user, you have to create users with the same name on all Ambari containers on each node manually.", 
            "title": "Kerberos"
        }, 
        {
            "location": "/kerberos/#kerberos-security", 
            "text": "Cloudbreak supports Kerberos security for Ambari internal communication. To activate Kerberos with Cloudbreak you have enable security option and fill the  kerberos master key ,  kerberos admin  and  kerberos password  fields too on web interface or shell during cluster creation. To run a job on the cluster, you can use one of the default Hadoop users, like  ambari-qa , as usual. Current implementation of Kerberos security doesn't contain Active Directory support or any other third party user authentication method. If you want to use custom user, you have to create users with the same name on all Ambari containers on each node manually.", 
            "title": "Kerberos security"
        }, 
        {
            "location": "/insights/", 
            "text": "Insights\n\n\nCloudbreak deployer\n\n\nDebug\n\n\nIf you want to have more detailed output set the \nDEBUG\n env variable to non-zero:\n\n\nDEBUG=1 cbd some_command\n\n\n\n\nTroubleshoot\n\n\nYou can use the \ndoctor\n command to diagnose your environment.\nIt can reveal some common problems with your docker or boot2docker configuration and it also checks the cbd versions.\n\n\ncbd doctor\n\n\n\n\nLogs\n\n\nThe aggregated logs of all the Cloudbreak components can be checked with:\n\n\ncbd logs\n\n\n\n\nIt can also be used to check the logs of an individual docker container. To see only the logs of the Cloudbreak backend:\n\n\ncbd logs cloudbreak\n\n\n\n\nYou can also check the individual logs of \nuluwatu\n, \nperiscope\n, and \nidentity\n.\n\n\nUpdate\n\n\nThe cloudbreak-deployer tool is capable of upgrading itself to a newer version.\n\n\ncbd update\n\n\n\n\nCloudbreak application\n\n\nSSH to the hosts\n\n\nIn the current version of Cloudbreak all the nodes have a public IP address and all the nodes are accessible via SSH.\nThe public IP addresses of a running cluster can be checked on the Cloudbreak UI under the \nNodes\n tab.\nOnly key-based authentication is supported - the public key can be specified when creating a credential.\n\n\nssh -i ~/.ssh/private-key.pem cloudbreak@\npublic-ip\n\n\n\n\n\nThe default user is \ncloudbreak\n except on EC2 where it is \nec2-user\n.\n\n\nAccessing HDP client services\n\n\nThe main difference between general HDP clusters and Cloudbreak-installed HDP clusters is that each host runs an Ambari server or agent Docker container and the HDP services will be installed in this container as well.\nIt means that after \nssh\n the client services won't be available instantly, first you'll have to enter the ambari-agent container.\nInside the container everything works the same way as expected.\nTo check the containers running on the host enter:\n\n\n[cloudbreak@vmhostgroupclient11 ~]$ sudo docker ps\nCONTAINER ID        IMAGE                                      COMMAND                  CREATED             STATUS              PORTS               NAMES\n1098ca778176        sequenceiq/baywatch-client:v1.0.0          \n/etc/bootstrap.sh -d\n   4 hours ago         Up 4 hours                              baywatch-client-14454170059514\nf4097c52fda5        sequenceiq/logrotate:v0.5.1                \n/start.sh\n              4 hours ago         Up 4 hours                              logrotate-14454169954830\n7b94aedaab30        sequenceiq/docker-consul-watch-plugn:1.0   \n/start.sh consul://1\n   4 hours ago         Up 4 hours                              consul-watch-14454169884044\nd8128b001427        sequenceiq/ambari:2.1.2-v2                 \n/start-agent\n           4 hours ago         Up 4 hours                              ambari-agent-14454169805924\na8ec90037aaf        swarm:0.4.0                                \n/swarm join --addr=1\n   4 hours ago         Up 4 hours          2375/tcp            vmhostgroupmaster12-swarm-agent\nef02b43eacee        sequenceiq/consul:v0.5.0-v5                \n/bin/start\n             4 hours ago         Up 4 hours                              vmhostgroupmaster12-consul\n\n\n\n\nYou should see the ambari-agent container running. Copy its id or name and \nexec\n into the container:\n\n\n[cloudbreak@vmhostgroupclient11 ~]$ sudo docker exec -it ambari-agent-14454169805924 bash\n[root@docker-ambari tmp]#\n\n\n\n\nOr you can use this one-step command as well:\n\n\n[cloudbreak@vmhostgroupclient11 ~]$ sudo docker exec -it $(sudo docker ps -f=name=ambari-agent -q) bash\n[root@docker-ambari tmp]#\n\n\n\n\nData volumes\n\n\nThe disks that are attached to the instances are automatically mounted to \n/hadoopfs/fs1\n, \n/hadoopfs/fs2\n, ... \n/hadoopfs/fsN\n respectively.\nThese directories are mounted from the host into the ambari-agent container under the same name so these can be accessed from inside.\nIt means that if you'd like to move some data to the instances you can use these volumes and the data will be available from the container instantly to work on it.\n\n\nAn \nscp\n Example:\n\n\n$ scp -qr -i ~/.ssh/private-key.pem ~/tmp/data cloudbreak@\nclient-node\n:/hadoopfs/fs1\n$ ssh -i ~/.ssh/private-key.pem cloudbreak@\nclient-node\n\n[cloudbreak@vmhostgroupclient11 ~]$ sudo docker exec -it $(sudo docker ps -f=name=ambari-agent -q) bash\n[root@docker-ambari tmp]# su hdfs\n[hdfs@docker-ambari tmp]# hadoop fs -put /hadoopfs/fs1/data /tmp\n[hdfs@docker-ambari tmp]# hadoop fs -ls /tmp\nFound 2 items\ndrwxr-xr-x   - hdfs supergroup          0 2015-10-21 13:46 /tmp/data\ndrwx-wx-wx   - hive supergroup          0 2015-10-21 08:51 /tmp/hive\n\n\n\n\nInternal hostnames\n\n\nAfter a cluster is created with Cloudbreak, the nodes will have internal hostnames like this:\n\n\nvmhostgroupclient11.node.dc1.consul\n\n\nThis is because Cloudbreak uses \nConsul\n to provide DNS services.\nIt means that you won't see entries to the other nodes inside the \n/etc/hosts\n file, because nodes are registered inside Consul and the hostnames are resolved by Consul as well.\n\n\nIn the current version the \nnode.dc1.consul\n domain is hardcoded and cannot be changed.\n\n\nAccessing Ambari server from the other nodes\n\n\nAmbari server is registered as a service in Consul, so it can always be accessed through its domain name \nambari-8080.service.consul\n from the other ambari containers.\nIt can be tried by pinging it from one of the \nambari-agent\n containers:\n\n\nping ambari-8080.service.consul\n\n\n\n\nCloudbreak gateway node\n\n\nWith every Cloudbreak cluster installation there is a special node called \ncbgateway\n started that won't run an ambari-agent container so it won't run HDP services either.\nIt can be seen on the Cloudbreak UI among the hostgroups when creating a cluster, but its node count cannot be changed from 1 and it shouldn't be there in the Ambari blueprint.\nIt is by design because this instance has some special tasks:\n\n\n\n\nit runs the Ambari server and its database inside Docker containers\n\n\nit runs an nginx proxy that is used by the Cloudbreak API to communicate with the cluster securely\n\n\nit runs the Swarm manager that orchestrates the Docker containers on the whole cluster\n\n\nit runs the Baywatch server that is responsible for collecting the operational logs from the cluster\n\n\nit runs a Kerberos KDC container if Kerberos is configured\n\n\n\n\nHadoop logs\n\n\nHadoop logs are available from the host and from the container as well in the \n/hadoopfs/fs1/logs\n directory.\n\n\nAmbari db\n\n\nAmbari's database runs on the \ncbgateway\n node inside a PostgreSQL docker container. To access it ssh to the gateway node and run the following command:\n\n\n[cloudbreak@vmcbgateway0 ~]$ sudo docker exec -it ambari_db psql -U postgres", 
            "title": "Insights"
        }, 
        {
            "location": "/insights/#insights", 
            "text": "Cloudbreak deployer  Debug  If you want to have more detailed output set the  DEBUG  env variable to non-zero:  DEBUG=1 cbd some_command  Troubleshoot  You can use the  doctor  command to diagnose your environment.\nIt can reveal some common problems with your docker or boot2docker configuration and it also checks the cbd versions.  cbd doctor  Logs  The aggregated logs of all the Cloudbreak components can be checked with:  cbd logs  It can also be used to check the logs of an individual docker container. To see only the logs of the Cloudbreak backend:  cbd logs cloudbreak  You can also check the individual logs of  uluwatu ,  periscope , and  identity .  Update  The cloudbreak-deployer tool is capable of upgrading itself to a newer version.  cbd update  Cloudbreak application  SSH to the hosts  In the current version of Cloudbreak all the nodes have a public IP address and all the nodes are accessible via SSH.\nThe public IP addresses of a running cluster can be checked on the Cloudbreak UI under the  Nodes  tab.\nOnly key-based authentication is supported - the public key can be specified when creating a credential.  ssh -i ~/.ssh/private-key.pem cloudbreak@ public-ip   The default user is  cloudbreak  except on EC2 where it is  ec2-user .  Accessing HDP client services  The main difference between general HDP clusters and Cloudbreak-installed HDP clusters is that each host runs an Ambari server or agent Docker container and the HDP services will be installed in this container as well.\nIt means that after  ssh  the client services won't be available instantly, first you'll have to enter the ambari-agent container.\nInside the container everything works the same way as expected.\nTo check the containers running on the host enter:  [cloudbreak@vmhostgroupclient11 ~]$ sudo docker ps\nCONTAINER ID        IMAGE                                      COMMAND                  CREATED             STATUS              PORTS               NAMES\n1098ca778176        sequenceiq/baywatch-client:v1.0.0           /etc/bootstrap.sh -d    4 hours ago         Up 4 hours                              baywatch-client-14454170059514\nf4097c52fda5        sequenceiq/logrotate:v0.5.1                 /start.sh               4 hours ago         Up 4 hours                              logrotate-14454169954830\n7b94aedaab30        sequenceiq/docker-consul-watch-plugn:1.0    /start.sh consul://1    4 hours ago         Up 4 hours                              consul-watch-14454169884044\nd8128b001427        sequenceiq/ambari:2.1.2-v2                  /start-agent            4 hours ago         Up 4 hours                              ambari-agent-14454169805924\na8ec90037aaf        swarm:0.4.0                                 /swarm join --addr=1    4 hours ago         Up 4 hours          2375/tcp            vmhostgroupmaster12-swarm-agent\nef02b43eacee        sequenceiq/consul:v0.5.0-v5                 /bin/start              4 hours ago         Up 4 hours                              vmhostgroupmaster12-consul  You should see the ambari-agent container running. Copy its id or name and  exec  into the container:  [cloudbreak@vmhostgroupclient11 ~]$ sudo docker exec -it ambari-agent-14454169805924 bash\n[root@docker-ambari tmp]#  Or you can use this one-step command as well:  [cloudbreak@vmhostgroupclient11 ~]$ sudo docker exec -it $(sudo docker ps -f=name=ambari-agent -q) bash\n[root@docker-ambari tmp]#  Data volumes  The disks that are attached to the instances are automatically mounted to  /hadoopfs/fs1 ,  /hadoopfs/fs2 , ...  /hadoopfs/fsN  respectively.\nThese directories are mounted from the host into the ambari-agent container under the same name so these can be accessed from inside.\nIt means that if you'd like to move some data to the instances you can use these volumes and the data will be available from the container instantly to work on it.  An  scp  Example:  $ scp -qr -i ~/.ssh/private-key.pem ~/tmp/data cloudbreak@ client-node :/hadoopfs/fs1\n$ ssh -i ~/.ssh/private-key.pem cloudbreak@ client-node \n[cloudbreak@vmhostgroupclient11 ~]$ sudo docker exec -it $(sudo docker ps -f=name=ambari-agent -q) bash\n[root@docker-ambari tmp]# su hdfs\n[hdfs@docker-ambari tmp]# hadoop fs -put /hadoopfs/fs1/data /tmp\n[hdfs@docker-ambari tmp]# hadoop fs -ls /tmp\nFound 2 items\ndrwxr-xr-x   - hdfs supergroup          0 2015-10-21 13:46 /tmp/data\ndrwx-wx-wx   - hive supergroup          0 2015-10-21 08:51 /tmp/hive  Internal hostnames  After a cluster is created with Cloudbreak, the nodes will have internal hostnames like this:  vmhostgroupclient11.node.dc1.consul  This is because Cloudbreak uses  Consul  to provide DNS services.\nIt means that you won't see entries to the other nodes inside the  /etc/hosts  file, because nodes are registered inside Consul and the hostnames are resolved by Consul as well.  In the current version the  node.dc1.consul  domain is hardcoded and cannot be changed.  Accessing Ambari server from the other nodes  Ambari server is registered as a service in Consul, so it can always be accessed through its domain name  ambari-8080.service.consul  from the other ambari containers.\nIt can be tried by pinging it from one of the  ambari-agent  containers:  ping ambari-8080.service.consul  Cloudbreak gateway node  With every Cloudbreak cluster installation there is a special node called  cbgateway  started that won't run an ambari-agent container so it won't run HDP services either.\nIt can be seen on the Cloudbreak UI among the hostgroups when creating a cluster, but its node count cannot be changed from 1 and it shouldn't be there in the Ambari blueprint.\nIt is by design because this instance has some special tasks:   it runs the Ambari server and its database inside Docker containers  it runs an nginx proxy that is used by the Cloudbreak API to communicate with the cluster securely  it runs the Swarm manager that orchestrates the Docker containers on the whole cluster  it runs the Baywatch server that is responsible for collecting the operational logs from the cluster  it runs a Kerberos KDC container if Kerberos is configured   Hadoop logs  Hadoop logs are available from the host and from the container as well in the  /hadoopfs/fs1/logs  directory.  Ambari db  Ambari's database runs on the  cbgateway  node inside a PostgreSQL docker container. To access it ssh to the gateway node and run the following command:  [cloudbreak@vmcbgateway0 ~]$ sudo docker exec -it ambari_db psql -U postgres", 
            "title": "Insights"
        }, 
        {
            "location": "/database/", 
            "text": "Migrate the databases\n\n\nCreate the database schema or migrate it to the latest version:\n\n\ncbd startdb\ncbd migrate cbdb up\n\n\n\n\nVerify that all scripts have been applied:\n\n\ncbd migrate cbdb status\n\n\n\n\ncbd generate\ncbd migrate cbdb up", 
            "title": "Migration"
        }, 
        {
            "location": "/configuration/", 
            "text": "Configuration\n\n\nConfiguration is based on environment variables. Cloudbreak Deployer always forks a new bash subprocess \nwithout\ninheriting environment variables\n. The only way to set ENV vars relevant for Cloudbreak Deployer is to set them\nin a file called \nProfile\n.\n\n\nTo see all available config variables with their default value:\n\n\ncbd env show\n\n\n\n\nThe \nProfile\n will be simple \nsourced\n in bash terms, so you can use the usual syntaxes to set config values:\n\n\nexport MY_VAR=some_value\nexport OTHER_VAR=dunno\n\n\n\n\nEnv specific Profile\n\n\nLet\u2019s say you want to use a different version of Cloudbreak for \nprod\n and \nqa\n profile.\nYou can specify the Docker image tag via: \nDOCKER_TAG_CLOUDBREAK\n.\n\nProfile\n is always sourced, so you will have two env specific configurations:\n- \nProfile.dev\n\n- \nProfile.qa\n\n\nFor prod you need:\n\n\n\n\ncreate a file called \nProfile.prod\n\n\nwrite the env specific \nexport DOCKER_TAG_CLOUDBREAK=0.3.99\n into \nProfile.prod\n\n\nset the env variable: \nCBD_DEFAULT_PROFILE=prod\n\n\n\n\nTo use the \nprod\n specific profile once:\n\n\nCBD_DEFAULT_PROFILE=prod cbd some_commands\n\n\n\n\nFor permanent setting you can \nexport CBD_DEFAULT_PROFILE=prod\n in your \n.bash_profile\n.\n\n\nAvailable Configurations\n\n\nSMTP\n\n\nPut these lines into your \nProfile\n\n\nexport CLOUDBREAK_SMTP_SENDER_USERNAME=\nexport CLOUDBREAK_SMTP_SENDER_PASSWORD=\nexport CLOUDBREAK_SMTP_SENDER_HOST=\nexport CLOUDBREAK_SMTP_SENDER_PORT=\nexport CLOUDBREAK_SMTP_SENDER_FROM=\n\n\n\n\nConsul\n\n\nConsul\n is used for dns resolution. All Cloudbreak related services are registered as\n\nsomeservice.service.consul\n. Consul\u2019s built in dns server is able to \u201cfall-back\u201d on an other dns server.\nThis option is called \n-recursor\n. Clodbreak Deployer first tries to discover the dns settings of the host,\nby looking for \nnameserver\n entry in \n/etc/resolv.conf\n. If it finds one consul will use it as a recursor,\notherwise \n8.8.8.8\n will be used.\n\n\nFor a full list of available consul config options, see the \ndocs\n\n\nYou can pass any additional consul configuration by defining a \nDOCKER_CONSUL_OPTIONS\n in \nProfile\n.\n\n\nList of configurations\n\n\n\n\nCB_AWS_AMI_MAP\n : tbd\n\n\nCB_AZURE_IMAGE_URI\n : tbd\n\n\nCB_BLUEPRINT_DEFAULTS\n : tbd\n\n\nCB_TEMPLATE_DEFAULTS\n : tbd\n\n\nCB_DB_ENV_DB\n : tbd\n\n\nCB_DB_ENV_PASS\n : tbd\n\n\nCB_DB_ENV_USER\n : tbd\n\n\nCB_GCP_SOURCE_IMAGE_PATH\n : tbd\n\n\nCB_HBM2DDL_STRATEGY\n : tbd\n\n\nCB_OPENSTACK_IMAGE\n : tbd\n\n\nDOCKER_TAG_ALPINE\n : tbd\n\n\nDOCKER_TAG_CBSHELL\n : tbd\n\n\nDOCKER_TAG_CLOUDBREAK\n : tbd\n\n\nDOCKER_TAG_CONSUL\n : tbd\n\n\nDOCKER_TAG_PERISCOPE\n : tbd\n\n\nDOCKER_TAG_POSTGRES\n : tbd\n\n\nDOCKER_TAG_REGISTRATOR\n : tbd\n\n\nDOCKER_TAG_SULTANS\n : tbd\n\n\nDOCKER_TAG_UAA\n : tbd\n\n\nDOCKER_TAG_ULUWATU\n : tbd\n\n\nPERISCOPE_DB_HBM2DDL_STRATEGY\n : tbd\n\n\n\n\nAzure Resource manager command\n\n\n\n\ncbd azure configure-arm\n\n\ncbd azure deploy-dash\n\nSee the documentation here\n\n\n\n\nCaveats\n\n\nThe \nCloudbreak Deployer\n tool opens a clean bash subshell, without inheriting environment vars.\nActually the following environment vars \nare\n inherited:\n\n\n\n\nHOME\n\n\nDEBUG\n\n\nTRACE\n\n\nCBD_DEFAULT_PROFILE\n\n\nall \nDOCKER_XXX", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/#configuration", 
            "text": "Configuration is based on environment variables. Cloudbreak Deployer always forks a new bash subprocess  without\ninheriting environment variables . The only way to set ENV vars relevant for Cloudbreak Deployer is to set them\nin a file called  Profile .  To see all available config variables with their default value:  cbd env show  The  Profile  will be simple  sourced  in bash terms, so you can use the usual syntaxes to set config values:  export MY_VAR=some_value\nexport OTHER_VAR=dunno", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/#env-specific-profile", 
            "text": "Let\u2019s say you want to use a different version of Cloudbreak for  prod  and  qa  profile.\nYou can specify the Docker image tag via:  DOCKER_TAG_CLOUDBREAK . Profile  is always sourced, so you will have two env specific configurations:\n-  Profile.dev \n-  Profile.qa  For prod you need:   create a file called  Profile.prod  write the env specific  export DOCKER_TAG_CLOUDBREAK=0.3.99  into  Profile.prod  set the env variable:  CBD_DEFAULT_PROFILE=prod   To use the  prod  specific profile once:  CBD_DEFAULT_PROFILE=prod cbd some_commands  For permanent setting you can  export CBD_DEFAULT_PROFILE=prod  in your  .bash_profile .", 
            "title": "Env specific Profile"
        }, 
        {
            "location": "/configuration/#available-configurations", 
            "text": "", 
            "title": "Available Configurations"
        }, 
        {
            "location": "/configuration/#smtp", 
            "text": "Put these lines into your  Profile  export CLOUDBREAK_SMTP_SENDER_USERNAME=\nexport CLOUDBREAK_SMTP_SENDER_PASSWORD=\nexport CLOUDBREAK_SMTP_SENDER_HOST=\nexport CLOUDBREAK_SMTP_SENDER_PORT=\nexport CLOUDBREAK_SMTP_SENDER_FROM=", 
            "title": "SMTP"
        }, 
        {
            "location": "/configuration/#consul", 
            "text": "Consul  is used for dns resolution. All Cloudbreak related services are registered as someservice.service.consul . Consul\u2019s built in dns server is able to \u201cfall-back\u201d on an other dns server.\nThis option is called  -recursor . Clodbreak Deployer first tries to discover the dns settings of the host,\nby looking for  nameserver  entry in  /etc/resolv.conf . If it finds one consul will use it as a recursor,\notherwise  8.8.8.8  will be used.  For a full list of available consul config options, see the  docs  You can pass any additional consul configuration by defining a  DOCKER_CONSUL_OPTIONS  in  Profile .  List of configurations   CB_AWS_AMI_MAP  : tbd  CB_AZURE_IMAGE_URI  : tbd  CB_BLUEPRINT_DEFAULTS  : tbd  CB_TEMPLATE_DEFAULTS  : tbd  CB_DB_ENV_DB  : tbd  CB_DB_ENV_PASS  : tbd  CB_DB_ENV_USER  : tbd  CB_GCP_SOURCE_IMAGE_PATH  : tbd  CB_HBM2DDL_STRATEGY  : tbd  CB_OPENSTACK_IMAGE  : tbd  DOCKER_TAG_ALPINE  : tbd  DOCKER_TAG_CBSHELL  : tbd  DOCKER_TAG_CLOUDBREAK  : tbd  DOCKER_TAG_CONSUL  : tbd  DOCKER_TAG_PERISCOPE  : tbd  DOCKER_TAG_POSTGRES  : tbd  DOCKER_TAG_REGISTRATOR  : tbd  DOCKER_TAG_SULTANS  : tbd  DOCKER_TAG_UAA  : tbd  DOCKER_TAG_ULUWATU  : tbd  PERISCOPE_DB_HBM2DDL_STRATEGY  : tbd", 
            "title": "Consul"
        }, 
        {
            "location": "/configuration/#azure-resource-manager-command", 
            "text": "cbd azure configure-arm  cbd azure deploy-dash \nSee the documentation here", 
            "title": "Azure Resource manager command"
        }, 
        {
            "location": "/configuration/#caveats", 
            "text": "The  Cloudbreak Deployer  tool opens a clean bash subshell, without inheriting environment vars.\nActually the following environment vars  are  inherited:   HOME  DEBUG  TRACE  CBD_DEFAULT_PROFILE  all  DOCKER_XXX", 
            "title": "Caveats"
        }, 
        {
            "location": "/development/", 
            "text": "Contribution\n\n\nDevelopment process should happen on separate branches. Then a pull-request should be opened as usual.\n\n\nTo build the project\n\n\n# make deps needed only once\nmake deps\n\nmake install\n\n\n\n\nTo run the unit tests:\n\n\nmake tests\n\n\n\n\nIf you want to test the binary CircleCI build from your branch named \nfix-something\n, to validate the PR binary \ncbd\n tool will be tested. It is built by CircleCI for each branch.\n\n\ncbd update fix-something\n\n\n\n\nTesting\n\n\nShell scripts shouldn\u2019t raise exceptions when it comes to unit testing. \nbasht\n is used for testing. See the reasoning: \nwhy not bats or shunit2\n\n\nPlease cover your bash functions with unit tests and run test with:\n\n\nmake tests\n\n\n\n\nRelease Process of the Clodbreak Deployer tool\n\n\nThe master branch is always built on \nCircleCI\n.\nWhen you wan\u2019t a new release, all you have to do:\n\n\nmake release-next-ver\n\n\n\n\nmake release-next-ver\n performs the following steps:\n\n\n\n\non the \nmaster\n branch:\n\n\nUpdates the \nVERSION\n file by increasing the \npatch\n version number (for example from 0.5.2 to 0.5.3)\n\n\nUpdates \nCHANGELOG.md\n with the release date\n\n\n\n\nCreates a new \nUnreleased\n section in top of \nCHANGELOG.md\n\n\n\n\n\n\nCreates a PullRequest for the release branch:\n\n\n\n\ncreate a new branch with a name like \nrelease-0.5.x\n\n\nthis branch should be the same as \norigin/master\n\n\ncreate a pull request into \nrelease\n branch\n\n\n\n\nAcceptance\n\n\nNow you should test this release. You can get it by \ncbd update release-x.y.z\n. Comment with LGTM (Looking Good To Me).\n\n\nOnce the PR is merged, CircleCI will:\n- create a new release on \nGitHub releases tab\n, with the help of \ngh-release\n.\n- it will create the git tag with \nv\n prefix like: \nv0.0.3", 
            "title": "Development"
        }, 
        {
            "location": "/development/#contribution", 
            "text": "Development process should happen on separate branches. Then a pull-request should be opened as usual.  To build the project  # make deps needed only once\nmake deps\n\nmake install  To run the unit tests:  make tests  If you want to test the binary CircleCI build from your branch named  fix-something , to validate the PR binary  cbd  tool will be tested. It is built by CircleCI for each branch.  cbd update fix-something", 
            "title": "Contribution"
        }, 
        {
            "location": "/development/#testing", 
            "text": "Shell scripts shouldn\u2019t raise exceptions when it comes to unit testing.  basht  is used for testing. See the reasoning:  why not bats or shunit2  Please cover your bash functions with unit tests and run test with:  make tests", 
            "title": "Testing"
        }, 
        {
            "location": "/development/#release-process-of-the-clodbreak-deployer-tool", 
            "text": "The master branch is always built on  CircleCI .\nWhen you wan\u2019t a new release, all you have to do:  make release-next-ver  make release-next-ver  performs the following steps:   on the  master  branch:  Updates the  VERSION  file by increasing the  patch  version number (for example from 0.5.2 to 0.5.3)  Updates  CHANGELOG.md  with the release date   Creates a new  Unreleased  section in top of  CHANGELOG.md    Creates a PullRequest for the release branch:   create a new branch with a name like  release-0.5.x  this branch should be the same as  origin/master  create a pull request into  release  branch   Acceptance  Now you should test this release. You can get it by  cbd update release-x.y.z . Comment with LGTM (Looking Good To Me).  Once the PR is merged, CircleCI will:\n- create a new release on  GitHub releases tab , with the help of  gh-release .\n- it will create the git tag with  v  prefix like:  v0.0.3", 
            "title": "Release Process of the Clodbreak Deployer tool"
        }, 
        {
            "location": "/changelog/", 
            "text": "Unreleased\n\n\nFixed\n\n\n\n\nconsul recursor now exculdes both docker ip and bridge ip to avoid recursive dns recursor chain\n\n\ndocs fixed about getting default credentials (cbd login)\n\n\n\n\nAdded\n\n\n\n\nCommand \ncbd azure configure-arm\n will create your arm application which can used by cloudbreak\n\n\nCommand \ncbd azure deploy-dash\n will deploy a dash application in your Azure account\n\n\nCommand \ncbd start\n will execute the migration by default. If SKIP_DB_MIGRATION_ON_START envvar set to true in Profile, the migration will be skipped\n\n\nUsing Dns SRV record in our services instead of ambassador\n\n\nUsing docker linking system in third party services instead of ambassador\n\n\nIntegration tests are added, where cbd binary is called, not only sourced functions\n\n\nDocker based CentOS integration test make target added\n\n\nUaa db migration\n\n\n\n\nRemoved\n\n\n\n\nFull removal of ambassador\n\n\n\n\nChanged\n\n\n\n\ncbd start\n doesn\u2019t start if compose yaml regeneration is needed\n\n\ncbd generate\n is less verbose, diff doesnt shown\n\n\ncbd doctor\n shows diff if generate would change\n\n\ncbd regenerate\n creates backup files if changes detected\n\n\nsequenceiq/uaadb:1.0.1 is used instead of postgres:9.4.1\n\n\n\n\n[v1.0.3] - 2015-09-03\n\n\nFixed\n\n\n\n\nAuthentication error with \ncloudbreak-shell\n and \ncloudbreak-shell-quiet\n is fixed\n\n\nCommand \ncbd update \nbranch\n checks for artifact\n\n\n\n\nAdded\n\n\n\n\nbinary version of gnu-sed 4.2.2 is now included, to solve lot of osx/busybox issues\n\n\nconsul recursor test are added\n\n\n\n\nRemoved\n\n\nChanged\n\n\n\n\n\n\nsequenceiq/cloudbreak image updated to 1.0.3\n\n\n\n\n\n\ndebug() function made multiline capable. Use \\n in messages\n\n\n\n\nrefactor bridge ip discovery to run helper docker command only once\n\n\nconsul recursor handling refactored to be more robust\n\n\n\n\n[v1.0.2] - 2015-08-25\n\n\nFixed\n\n\nAdded\n\n\n\n\nDOCKER_CONSUL_OPTIONS\n config option to provide arbitrary consul option\n\n\n\n\nRemoved\n\n\nChanged\n\n\n\n\nFixed docker version checker to be 1.8.1 compatible. (docker added --format option)\n\n\nsequenceiq/cloudbreak image updated to 1.0.2\n\n\nconsul image changed from sequenceiq/consul to gliderlabs/consul\n\n\nconsul image updated to 0.5.2 (from 0.5.0)\n\n\nconsul discovers host dns settings, and uses the configured nameserver as recursor\n\n\n\n\n[v1.0.0] - 2015-08-15\n\n\nFixed\n\n\nAdded\n\n\nRemoved\n\n\nChanged\n\n\n[v1.0.0] - 2015-07-23\n\n\nFixed\n\n\n\n\nGA Release\n\n\n\n\nAdded\n\n\nRemoved\n\n\nChanged\n\n\n[v0.5.8] - 2015-07-23\n\n\nFixed\n\n\n\n\nFix CircleCI release. CircleCI doesn\u2019t allow --rm on docker run\n\n\n\n\nAdded\n\n\nRemoved\n\n\nChanged\n\n\n[v0.5.7] - 2015-07-23\n\n\nFixed\n\n\n\n\nFix make release dependency\n\n\nFix CHANGELOG generation at \nmake release-next-ver\n avoid inserting extra -e\n\n\n\n\nAdded\n\n\nRemoved\n\n\nChanged\n\n\n[v0.5.6] - 2015-07-23\n\n\nFixed\n\n\nAdded\n\n\n\n\nRelease artifacts are published at public-repo-1.hortonworks.com/HDP/cloudbreak/\n\n\n\n\nRemoved\n\n\nChanged\n\n\n[v0.5.5] - 2015-07-10\n\n\nFixed\n\n\nAdded\n\n\n\n\nCommand \npull-parallel\n added for quicker/simultaneous image pull\n\n\nRelease process includes upload to public-repo s3 bucket\n\n\n\n\nRemoved\n\n\nChanged\n\n\n\n\nLicense changed from MIT to Apache v2\n\n\nrelease artifact includes additional files: license/readme/notes\n\n\n\n\n[v0.5.4] - 2015-07-03\n\n\nFixed\n\n\nAdded\n\n\n\n\nNew \ncbd-cleanup\n command for removing old images or exited containers\n\n\nBaywatch default parameters added: \nCB_BAYWATCH_ENABLED\n and\nCB_BAYWATCH_EXTERN_LOCATION\n\n\nLogs are saved via lospout\n\n\nTLS client certificate needed by Cloudbreak is generated with \ncbd generate\n\n\nCommand \naws delete-role\n added\n\n\nCommand \naws generate-role\n added\n\n\nCommand \naws show-role\n added\n\n\nCommand \ncloudbreak-shell\n added\n\n\nCommand \ncloudbreak-shell-quiet\n added\n\n\nCommand \nlocal-dev\n added\n\n\nCommand \ntoken\n added\n\n\n\n\nRemoved\n\n\nChanged\n\n\n\n\nAWS authentication env varibale is fixed to use the correct AWS_SECRET_ACCESS_KEY (instead the old AWS_SECRET_KEY)\n\n\nUsing sequenceiq/ambassadord:0.5.0 docker image instead of progrium/ambassadord:latest\n\n\n\n\n[v0.5.3] - 2015-06-03\n\n\nFixed\n\n\n\n\nOne-liner installer fixed, to work if previous cbd exists on path.\n\n\ncbd update\n upstream changes on go-bahser broke the selfupdate functionality\n\n\nIn some environment cloudbreak starts really slow. See: \ndetails\n, see: \ncommit\n\n\n\n\nAdded\n\n\n\n\nNew release proposal can be done by \nmake release-next-ver\n\n\n\n\nRemoved\n\n\nChanged\n\n\n[v0.5.2] - 2015-05-21\n\n\nFixed\n\n\nAdded\n\n\nRemoved\n\n\nChanged\n\n\n\n\nCommand \ndoctor\n hints to run boot2docker shellinit if env is unset\n\n\nCommand \ninit\n in case of OSX, DOCKER_XXX envs are initialized in local profile (Profile)\n\n\nDefault docker images are updated to:\n\n\nsequenceiq/cloudbreak:0.5.93\n\n\nsequenceiq/cbdb:0.5.92\n\n\nsequenceiq/uluwatu:0.5.28\n\n\nsequenceiq/sultans:0.5.3\n\n\nsequenceiq/periscope:0.5.5\n\n\n\n\n\n\n\n\n[v0.5.1] - 2015-05-18\n\n\nFixed\n\n\n\n\nIssue #55: Sed handles more robust the issue with: curl includes an extra CR char in header fields.\n\n\n\n\nAdded\n\n\nRemoved\n\n\n\n\ndeployer doesn\u2019t specify cloud specific image defaults. If left empty, they fall back\n  to defaults specified in \njava code\n\n\nCB_AZURE_IMAGE_URI\n\n\nCB_AWS_AMI_MAP\n\n\nCB_OPENSTACK_IMAGE\n\n\nCB_GCP_SOURCE_IMAGE_PATH\n\n\n\n\n\n\n\n\nChanged\n\n\n\n\nCommand \nlogs\n got usage example for specifying servies as filter\n\n\nDefault docker images are updated to:\n\n\nsequenceiq/cloudbreak:0.5.49\n\n\nsequenceiq/uluwatu:0.5.16\n\n\nsequenceiq/sutans:0.5.2\n\n\n\n\n\n\n\n\n[v0.5.0] - 2015-05-08\n\n\nFixed\n\n\n\n\nCommand \npull\n generates yaml files in case they are missing #31\n\n\n\n\nAdded\n\n\n\n\nCommand \nlogin\n Shows Uluwatu login url and credentials\n\n\nCommand \nregenerate\n deletes and generates docker-compose.yml and uaa.yml\n\n\nCommand \ndelete\n added: deletes yamls and dbs\n\n\nCommand \ncloudbreak-shell\n added, right now it internale use DEBUG=1 fn fn-call\n\n\nCommand \nversion\n does correct \nSemantic Versioning\n check to advise an upgrade\n\n\nCommand \ngenerate\n checks and shows if Profile change would result in yaml change.\n\n\nCommand \nstart\n: prints uluwatu url and credential hint\n\n\nCommand \ndoctor\n: fixes boot2docker date/time if not the same as on the host\n\n\nInternal command: \nbrowse\n added to be able to automatically open a browser to a specified url.\n\n\nMini Getting Started guide added into README\n\n\nmake dev-debug\n installs a special cbd on local OSX, which doesn\u2019t includes *.bash scrips, only refers them\n   by path. No need to \nmake dev\n to test small changes in bash scripts.\n\n\nLoad AWS key and AWS id from Profile\n\n\nCommand \ninit\n helps to guess the PUBLIC_IP in public clouds: google, amazon\n\n\n\n\nRemoved\n\n\nChanged\n\n\n\n\nCommand \ncbd env export\n adds export to the begining of each line\n\n\ncbd logs accepts optional [services] parameter\n\n\ndocker-compose uses \ncbreak_\n prefix for container naming instead of the directory name\n\n\nCommand \ngenerate\n prints out some more usefull info\n\n\nuaa.yml generation wont overwrite, just instruct to move existing file (like docker-compose.yml generation)\n\n\nCommand \ninit\n hint fixed on linux.\n\n\nCommand \ninit\n advise to run \ngenerate\n if it finds a Profile\n\n\nCommand \ninit\n set PRIVATE_IP the same as PUBLIC_IP for boot2docker\n\n\nCommand \nmigrate\n is introduced for db migration see \nMigrate the databases\n section of README\n\n\nCommand \nstartdb\n starts the cbdb and pcdb database containers only\n\n\nDatabases are not deleted after boot2docker restart\n\n\nImport ULU_HOST_ADDRESS and ULU_SULTANS_ADDRESS from Profile\n\n\n\n\n[v0.1.0] - 2015-04-16\n\n\nFixed\n\n\n\n\nSelfupdate updates the actual running binary intead of the fixed /us/local/bin/cbd\n\n\nSMTP default port is 25, to fix number conversion exception\n\n\n\n\nAdded\n\n\n\n\nCommand \ninit\n creates Profile\n\n\nInstall cbd to a directory which is available on $PATH\n\n\nDocker based test for the one-liner install from README.md: \nmake install-test\n\n\n\n\nRemoved\n\n\n\n\nupdate-snap\n command removed, replaced by parametrized \nupdate\n\n\n\n\nChanged\n\n\n\n\nCloudbreak/Persicope/Uluwatu/Sultans Dcoker images upgraded to 0.4.x\n\n\nUse the built in 'checksum' function instead of the external 'shasum' to generate secrets\n\n\nCommand \nupdate\n by default updates from latest Github release, parameter can point to branch on CircleCI\n\n\nDOCKER_XXX env varibles are inherited, so they not needed in Profile\n\n\ngenerate\n and compose specific commands are only available when \nProfile\n exists\n\n\ngenerate\n command genertes docker-compose.yml \nand\n uaa.yml\n\n\nPRIVATE_IP\n env var defaults to bridge IP (only PUBLC_IP is required in Profile)\n\n\nuse \nsulans-bin\n docker image istead of sultans\n\n\n\n\n[v0.0.9] - 2015-04-14\n\n\nFixed\n\n\n\n\nBash 4.3 is included in the binary, extracted into .deps/bin upon start\n\n\n\n\nAdded\n\n\nRemoved\n\n\nChanged\n\n\n[v0.0.8] - 2015-04-13\n\n\nFixed\n\n\n\n\nFixing deps module, golang fn: checksum added\n\n\nCircleCI mdule defines required jq\n\n\nFixing PATH issue for binary deps\n\n\n\n\nAdded\n\n\n\n\nuaadb start added\n\n\nidentity server start added\n\n\nmake dev\n added to mac based development\n\n\npull\n command added\n\n\nlogs\n command added\n\n\n\n\nRemoved\n\n\nChanged\n\n\n\n\nDocker containers are managed by \ndocker-compose\n\n\n\n\n[v0.0.7] - 2015-03-26\n\n\nFixed\n\n\nAdded\n\n\n\n\nmake tests\n runs unit tests\n\n\ndocker unit tests are added\n\n\nstart command added: WIP consul, registrator starts\n\n\nkill command addd: stops and removes cloudbreak specific containers\n\n\nSKIP_XXX skips the container start\n\n\n\n\nRemoved\n\n\nChanged\n\n\n\n\nenv command namespace is always exported, not only in DEBUG mode\n\n\nenv export: machine friendly config list\n\n\nenv show: human readable config list\n\n\ncircle runs unit tests\n\n\nsnapshot binaries include branch name in version string\n\n\n\n\n[v0.0.6] - 2015-03-25\n\n\nFixed\n\n\n\n\nremoved dos2unix dependency for the update command\n\n\n\n\nAdded\n\n\n\n\ndoctor command added\n\n\ndocker-check-version command added\n\n\ncci-latest accepts branch as parameter, needed for PR testing\n\n\nexport fn command in DEBUG mode\n\n\nexport env command in DEBUG mode\n\n\ndoctor: add instruction about setting DOCKER_XXX env vars in Profile\n\n\ninfo() function added to print green text to STDOUT\n\n\n\n\nRemoved\n\n\nChanged\n\n\n\n\nHOME env var is also inherited (boot2docker version failed)\n\n\nrelease process fully automatized\n\n\n\n\n[v0.0.5] - 2015-03-23\n\n\n\n\nupdate\n command works without dos2unix\n\n\n\n\n[v0.0.4] - 2015-03-23\n\n\nFixed\n\n\n\n\ndebug function fixed\n\n\nDEBUG, TRACE and CBD_DEFAULT_PROFILE env vars are inherited\n\n\n\n\nAdded\n\n\n\n\nProfile handling added with docs\n\n\nOne-liner install added\n\n\nDocs: install and update process described\n\n\nDocs: release process described with sample git commands\n\n\nPrint version number in debug mode\n\n\nupdate-snap\n downloads binary from latest os specific CircleCI binary artifact.\n\n\n\n\nRemoved\n\n\nChanged\n\n\n\n\nTool specific library renamed from cloudbreak.bash to deployer.bash\n\n\n\n\n[v0.0.6] - 2015-03-25\n\n\n[v0.0.3] - 2015-03-19\n\n\nFixed\n\n\n\n\nmake release\n creates binary with X.X.X version when on release branch otherwise X.X.X-gitrev\n\n\n\n\nAdded\n\n\n\n\nDocs: release process described\n\n\n\n\nRemoved\n\n\nChanged\n\n\n[v0.0.2] - 2015-03-19\n\n\nAdded\n\n\nAdded\n- selfupdate command\n- gray debug to stderr\n\n\n[v0.0.1] - 2015-03-18\n\n\nAdded\n\n\n\n\nhelp command added\n\n\nversion command added\n\n\nAdded --version\n\n\nCircleCI build\n\n\nLinux/Darwin binary releases on github", 
            "title": "Changelog"
        }, 
        {
            "location": "/changelog/#unreleased", 
            "text": "Fixed   consul recursor now exculdes both docker ip and bridge ip to avoid recursive dns recursor chain  docs fixed about getting default credentials (cbd login)   Added   Command  cbd azure configure-arm  will create your arm application which can used by cloudbreak  Command  cbd azure deploy-dash  will deploy a dash application in your Azure account  Command  cbd start  will execute the migration by default. If SKIP_DB_MIGRATION_ON_START envvar set to true in Profile, the migration will be skipped  Using Dns SRV record in our services instead of ambassador  Using docker linking system in third party services instead of ambassador  Integration tests are added, where cbd binary is called, not only sourced functions  Docker based CentOS integration test make target added  Uaa db migration   Removed   Full removal of ambassador   Changed   cbd start  doesn\u2019t start if compose yaml regeneration is needed  cbd generate  is less verbose, diff doesnt shown  cbd doctor  shows diff if generate would change  cbd regenerate  creates backup files if changes detected  sequenceiq/uaadb:1.0.1 is used instead of postgres:9.4.1", 
            "title": "Unreleased"
        }, 
        {
            "location": "/changelog/#v103-2015-09-03", 
            "text": "Fixed   Authentication error with  cloudbreak-shell  and  cloudbreak-shell-quiet  is fixed  Command  cbd update  branch  checks for artifact   Added   binary version of gnu-sed 4.2.2 is now included, to solve lot of osx/busybox issues  consul recursor test are added   Removed  Changed    sequenceiq/cloudbreak image updated to 1.0.3    debug() function made multiline capable. Use \\n in messages   refactor bridge ip discovery to run helper docker command only once  consul recursor handling refactored to be more robust", 
            "title": "[v1.0.3] - 2015-09-03"
        }, 
        {
            "location": "/changelog/#v102-2015-08-25", 
            "text": "Fixed  Added   DOCKER_CONSUL_OPTIONS  config option to provide arbitrary consul option   Removed  Changed   Fixed docker version checker to be 1.8.1 compatible. (docker added --format option)  sequenceiq/cloudbreak image updated to 1.0.2  consul image changed from sequenceiq/consul to gliderlabs/consul  consul image updated to 0.5.2 (from 0.5.0)  consul discovers host dns settings, and uses the configured nameserver as recursor", 
            "title": "[v1.0.2] - 2015-08-25"
        }, 
        {
            "location": "/changelog/#v100-2015-08-15", 
            "text": "Fixed  Added  Removed  Changed", 
            "title": "[v1.0.0] - 2015-08-15"
        }, 
        {
            "location": "/changelog/#v100-2015-07-23", 
            "text": "Fixed   GA Release   Added  Removed  Changed", 
            "title": "[v1.0.0] - 2015-07-23"
        }, 
        {
            "location": "/changelog/#v058-2015-07-23", 
            "text": "Fixed   Fix CircleCI release. CircleCI doesn\u2019t allow --rm on docker run   Added  Removed  Changed", 
            "title": "[v0.5.8] - 2015-07-23"
        }, 
        {
            "location": "/changelog/#v057-2015-07-23", 
            "text": "Fixed   Fix make release dependency  Fix CHANGELOG generation at  make release-next-ver  avoid inserting extra -e   Added  Removed  Changed", 
            "title": "[v0.5.7] - 2015-07-23"
        }, 
        {
            "location": "/changelog/#v056-2015-07-23", 
            "text": "Fixed  Added   Release artifacts are published at public-repo-1.hortonworks.com/HDP/cloudbreak/   Removed  Changed", 
            "title": "[v0.5.6] - 2015-07-23"
        }, 
        {
            "location": "/changelog/#v055-2015-07-10", 
            "text": "Fixed  Added   Command  pull-parallel  added for quicker/simultaneous image pull  Release process includes upload to public-repo s3 bucket   Removed  Changed   License changed from MIT to Apache v2  release artifact includes additional files: license/readme/notes", 
            "title": "[v0.5.5] - 2015-07-10"
        }, 
        {
            "location": "/changelog/#v054-2015-07-03", 
            "text": "Fixed  Added   New  cbd-cleanup  command for removing old images or exited containers  Baywatch default parameters added:  CB_BAYWATCH_ENABLED  and CB_BAYWATCH_EXTERN_LOCATION  Logs are saved via lospout  TLS client certificate needed by Cloudbreak is generated with  cbd generate  Command  aws delete-role  added  Command  aws generate-role  added  Command  aws show-role  added  Command  cloudbreak-shell  added  Command  cloudbreak-shell-quiet  added  Command  local-dev  added  Command  token  added   Removed  Changed   AWS authentication env varibale is fixed to use the correct AWS_SECRET_ACCESS_KEY (instead the old AWS_SECRET_KEY)  Using sequenceiq/ambassadord:0.5.0 docker image instead of progrium/ambassadord:latest", 
            "title": "[v0.5.4] - 2015-07-03"
        }, 
        {
            "location": "/changelog/#v053-2015-06-03", 
            "text": "Fixed   One-liner installer fixed, to work if previous cbd exists on path.  cbd update  upstream changes on go-bahser broke the selfupdate functionality  In some environment cloudbreak starts really slow. See:  details , see:  commit   Added   New release proposal can be done by  make release-next-ver   Removed  Changed", 
            "title": "[v0.5.3] - 2015-06-03"
        }, 
        {
            "location": "/changelog/#v052-2015-05-21", 
            "text": "Fixed  Added  Removed  Changed   Command  doctor  hints to run boot2docker shellinit if env is unset  Command  init  in case of OSX, DOCKER_XXX envs are initialized in local profile (Profile)  Default docker images are updated to:  sequenceiq/cloudbreak:0.5.93  sequenceiq/cbdb:0.5.92  sequenceiq/uluwatu:0.5.28  sequenceiq/sultans:0.5.3  sequenceiq/periscope:0.5.5", 
            "title": "[v0.5.2] - 2015-05-21"
        }, 
        {
            "location": "/changelog/#v051-2015-05-18", 
            "text": "Fixed   Issue #55: Sed handles more robust the issue with: curl includes an extra CR char in header fields.   Added  Removed   deployer doesn\u2019t specify cloud specific image defaults. If left empty, they fall back\n  to defaults specified in  java code  CB_AZURE_IMAGE_URI  CB_AWS_AMI_MAP  CB_OPENSTACK_IMAGE  CB_GCP_SOURCE_IMAGE_PATH     Changed   Command  logs  got usage example for specifying servies as filter  Default docker images are updated to:  sequenceiq/cloudbreak:0.5.49  sequenceiq/uluwatu:0.5.16  sequenceiq/sutans:0.5.2", 
            "title": "[v0.5.1] - 2015-05-18"
        }, 
        {
            "location": "/changelog/#v050-2015-05-08", 
            "text": "Fixed   Command  pull  generates yaml files in case they are missing #31   Added   Command  login  Shows Uluwatu login url and credentials  Command  regenerate  deletes and generates docker-compose.yml and uaa.yml  Command  delete  added: deletes yamls and dbs  Command  cloudbreak-shell  added, right now it internale use DEBUG=1 fn fn-call  Command  version  does correct  Semantic Versioning  check to advise an upgrade  Command  generate  checks and shows if Profile change would result in yaml change.  Command  start : prints uluwatu url and credential hint  Command  doctor : fixes boot2docker date/time if not the same as on the host  Internal command:  browse  added to be able to automatically open a browser to a specified url.  Mini Getting Started guide added into README  make dev-debug  installs a special cbd on local OSX, which doesn\u2019t includes *.bash scrips, only refers them\n   by path. No need to  make dev  to test small changes in bash scripts.  Load AWS key and AWS id from Profile  Command  init  helps to guess the PUBLIC_IP in public clouds: google, amazon   Removed  Changed   Command  cbd env export  adds export to the begining of each line  cbd logs accepts optional [services] parameter  docker-compose uses  cbreak_  prefix for container naming instead of the directory name  Command  generate  prints out some more usefull info  uaa.yml generation wont overwrite, just instruct to move existing file (like docker-compose.yml generation)  Command  init  hint fixed on linux.  Command  init  advise to run  generate  if it finds a Profile  Command  init  set PRIVATE_IP the same as PUBLIC_IP for boot2docker  Command  migrate  is introduced for db migration see  Migrate the databases  section of README  Command  startdb  starts the cbdb and pcdb database containers only  Databases are not deleted after boot2docker restart  Import ULU_HOST_ADDRESS and ULU_SULTANS_ADDRESS from Profile", 
            "title": "[v0.5.0] - 2015-05-08"
        }, 
        {
            "location": "/changelog/#v010-2015-04-16", 
            "text": "Fixed   Selfupdate updates the actual running binary intead of the fixed /us/local/bin/cbd  SMTP default port is 25, to fix number conversion exception   Added   Command  init  creates Profile  Install cbd to a directory which is available on $PATH  Docker based test for the one-liner install from README.md:  make install-test   Removed   update-snap  command removed, replaced by parametrized  update   Changed   Cloudbreak/Persicope/Uluwatu/Sultans Dcoker images upgraded to 0.4.x  Use the built in 'checksum' function instead of the external 'shasum' to generate secrets  Command  update  by default updates from latest Github release, parameter can point to branch on CircleCI  DOCKER_XXX env varibles are inherited, so they not needed in Profile  generate  and compose specific commands are only available when  Profile  exists  generate  command genertes docker-compose.yml  and  uaa.yml  PRIVATE_IP  env var defaults to bridge IP (only PUBLC_IP is required in Profile)  use  sulans-bin  docker image istead of sultans", 
            "title": "[v0.1.0] - 2015-04-16"
        }, 
        {
            "location": "/changelog/#v009-2015-04-14", 
            "text": "Fixed   Bash 4.3 is included in the binary, extracted into .deps/bin upon start   Added  Removed  Changed", 
            "title": "[v0.0.9] - 2015-04-14"
        }, 
        {
            "location": "/changelog/#v008-2015-04-13", 
            "text": "Fixed   Fixing deps module, golang fn: checksum added  CircleCI mdule defines required jq  Fixing PATH issue for binary deps   Added   uaadb start added  identity server start added  make dev  added to mac based development  pull  command added  logs  command added   Removed  Changed   Docker containers are managed by  docker-compose", 
            "title": "[v0.0.8] - 2015-04-13"
        }, 
        {
            "location": "/changelog/#v007-2015-03-26", 
            "text": "Fixed  Added   make tests  runs unit tests  docker unit tests are added  start command added: WIP consul, registrator starts  kill command addd: stops and removes cloudbreak specific containers  SKIP_XXX skips the container start   Removed  Changed   env command namespace is always exported, not only in DEBUG mode  env export: machine friendly config list  env show: human readable config list  circle runs unit tests  snapshot binaries include branch name in version string", 
            "title": "[v0.0.7] - 2015-03-26"
        }, 
        {
            "location": "/changelog/#v006-2015-03-25", 
            "text": "Fixed   removed dos2unix dependency for the update command   Added   doctor command added  docker-check-version command added  cci-latest accepts branch as parameter, needed for PR testing  export fn command in DEBUG mode  export env command in DEBUG mode  doctor: add instruction about setting DOCKER_XXX env vars in Profile  info() function added to print green text to STDOUT   Removed  Changed   HOME env var is also inherited (boot2docker version failed)  release process fully automatized", 
            "title": "[v0.0.6] - 2015-03-25"
        }, 
        {
            "location": "/changelog/#v005-2015-03-23", 
            "text": "update  command works without dos2unix", 
            "title": "[v0.0.5] - 2015-03-23"
        }, 
        {
            "location": "/changelog/#v004-2015-03-23", 
            "text": "Fixed   debug function fixed  DEBUG, TRACE and CBD_DEFAULT_PROFILE env vars are inherited   Added   Profile handling added with docs  One-liner install added  Docs: install and update process described  Docs: release process described with sample git commands  Print version number in debug mode  update-snap  downloads binary from latest os specific CircleCI binary artifact.   Removed  Changed   Tool specific library renamed from cloudbreak.bash to deployer.bash", 
            "title": "[v0.0.4] - 2015-03-23"
        }, 
        {
            "location": "/changelog/#v006-2015-03-25_1", 
            "text": "", 
            "title": "[v0.0.6] - 2015-03-25"
        }, 
        {
            "location": "/changelog/#v003-2015-03-19", 
            "text": "Fixed   make release  creates binary with X.X.X version when on release branch otherwise X.X.X-gitrev   Added   Docs: release process described   Removed  Changed", 
            "title": "[v0.0.3] - 2015-03-19"
        }, 
        {
            "location": "/changelog/#v002-2015-03-19", 
            "text": "Added  Added\n- selfupdate command\n- gray debug to stderr", 
            "title": "[v0.0.2] - 2015-03-19"
        }, 
        {
            "location": "/changelog/#v001-2015-03-18", 
            "text": "", 
            "title": "[v0.0.1] - 2015-03-18"
        }, 
        {
            "location": "/changelog/#added_22", 
            "text": "help command added  version command added  Added --version  CircleCI build  Linux/Darwin binary releases on github", 
            "title": "Added"
        }
    ]
}